{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorFlow 2 프로젝트 워크플로우를 SageMaker에서 실행하기\n",
    "\n",
    "- **본 노트북은 SageMaker example 중 tf-2-workflow부분 한글 번역입니다.**\n",
    "- 원본소스 : https://github.com/aws-samples/amazon-sagemaker-script-mode/tree/master/tf-2-workflow\n",
    "\n",
    "### Data Preprocessing -> Code Prototyping -> Automatic Model Tuning -> Deployment\n",
    "\n",
    "1. [시작하기](#Introduction)\n",
    "2. [SageMaker Processing 을 이용한 데이터셋 변환](#SageMakerProcessing)\n",
    "3. [로컬모드 (Local Mode) 학습](#LocalModeTraining)\n",
    "4. [로컬모드 (Local Mode) 엔드포인트](#LocalModeEndpoint)\n",
    "5. [SageMaker 호스팅 환경에서 학습](#SageMakerHostedTraining)\n",
    "6. [자동 모델 튜닝 (하이퍼파라미터 튜닝)](#AutomaticModelTuning)\n",
    "7. [SageMaker 호스팅 엔드포인트](#SageMakerHostedEndpoint)\n",
    "8. [AWS Step Functions의 Data Science SDK를 이용한 워크플로우 자동화](#WorkflowAutomation)\n",
    "    1. [SageMaker Role에 IAM policy 추가하기](#IAMPolicy)\n",
    "    2. [Step Functions를 위한 실행 역할(execution role) 생성하기](#CreateExecutionRole)\n",
    "    3. [학습 파이프라인(TrainingPipeline)셋업](#TrainingPipeline)\n",
    "    4. [워크플로우 가시화](#VisualizingWorkflow)\n",
    "    5. [파이프라인의 생성과 실행 ](#CreatingExecutingPipeline)\n",
    "    6. [리소스 정리](#Cleanup)\n",
    "9. [확장](#Extensions)\n",
    "\n",
    "    \n",
    "## 시작하기 <a class=\"anchor\" id=\"Introduction\">\n",
    "\n",
    "TensorFlow 2를 사용하실 때, SageMaker가 아닌 환경에서 사용하던 학습(training) 스크립트를 SageMaker에서 제공하는 TensorFlow 2 컨테이너에서 실행하도록 할 수 있습니다. SageMaker에서는 이 기능을 스크립트 모드라고 부릅니다. 스크립트 모드를 사용하여 여러분은 Tensorflow 2 프로젝트의 워크플로우를 완성할 수 있습니다.   \n",
    "본 노트북은 그 워크플로우의 샘플을 제공합니다. 워크플로우는 SageMaker Processing을 이용한 전치리, SageMaker  로컬모드를 이용한 학습과 추론, 그리고 SageMaker에서 관리되는 학습과 추론환경을 이용하여 운영환경에 적용할 수 있는 모델을 학습하고 배포하는 과정을 포함합니다. 또, 모델의 하이퍼파라미터를 튜닝하기 위해 SageMaker의 Automatic Model Tuning을 이용할 수 있습니다. 추가로 [AWS Step Functions Data Science SDK](https://aws-step-functions-data-science-sdk.readthedocs.io/en/latest/readmelink.html)를 이용하여 노트북 외부 환경에서 메인 학습과 배포 단계를 자동화할 수 있습니다. \n",
    "\n",
    "본 노트북을 실행하는데 1시간 정도가 소요됩니다. 시간내에 실행하기 위해 유즈케이스는 잘 알려진 보스톤의 집값을 예측하는 regression 작업을 이용합니다. 이 데이터셋은 방 개수, 고속도로 접근성, Charles강과의 거리 등 13개의 특성(feature)를 가집니다.\n",
    "\n",
    "처음으로, 필요한 패키지를 임포트하고, local에서 학습과 테스트를 하기 위해 디렉토리를 세팅하는 작업을 시작합니다. 다양한 작업을 위해 SageMaker Session도 함께 셋업합니다. 입출력 데이터 저장을 위한 S3 버킷을 정의합니다. 본 예제에서는 SageMaker가 자동으로 생성하는 디폴트 버킷을 사용할 것입니다. 디폴트 버킷의 이름은 여러분의 Account ID와 리전을 포함하고 있습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/__init__.py:1467: The name tf.estimator.inputs is deprecated. Please use tf.compat.v1.estimator.inputs instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sagemaker\n",
    "import tensorflow as tf\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "bucket = sess.default_bucket() \n",
    "\n",
    "data_dir = os.path.join(os.getcwd(), 'data')\n",
    "os.makedirs(data_dir, exist_ok=True)\n",
    "\n",
    "train_dir = os.path.join(os.getcwd(), 'data/train')\n",
    "os.makedirs(train_dir, exist_ok=True)\n",
    "\n",
    "test_dir = os.path.join(os.getcwd(), 'data/test')\n",
    "os.makedirs(test_dir, exist_ok=True)\n",
    "\n",
    "raw_dir = os.path.join(os.getcwd(), 'data/raw')\n",
    "os.makedirs(raw_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SageMaker Processing을 이용한 데이터셋 변환 <a class=\"anchor\" id=\"SageMakerProcessing\">\n",
    "\n",
    "다음으로 필요한 데이터셋을 import하고 SageMaker Processing을 이용하여 변환하겠습니다. SageMaker Processing을 이용하면 SageMaker 노트북 서버와 분리된 독립적 환경에서 테라바이트 수준의 데이터를 변환처리할 수 있습니다. 전형적인 SageMaker 워크플로우에서 주로 프로토타이핑 작업에 사용되는 노트북은 고사양 인스턴스가 아닌 환경에서 주로 실행하고, 프로세싱, 학습, 모델 호스팅과 같은 실제 작업은 보다 강력한 사양의 인스턴스에서 실행합니다. SageMaker Processing은 Scikit-learn이 기본 탑재되어 있으며 Bring Your Own Container 옵션으로 다양한 데이터 변형기술과 작업을 별도로 독립된 환경에서 지원할 수 있습니다.\n",
    "\n",
    "먼저 보스턴 집값 데이터셋을 로드하고, 이 데이터셋을 그대로 S3로 업로드한 후 SageMaker Processing에서 변형하겠습니다. 그리고 학습과 테스트를 위해 레이블도 생성, 저장합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-us-east-1-308961792850/tf-2-workflow/data/raw\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.python.keras.datasets import boston_housing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = boston_housing.load_data()\n",
    "\n",
    "np.save(os.path.join(raw_dir, 'x_train.npy'), x_train)\n",
    "np.save(os.path.join(raw_dir, 'x_test.npy'), x_test)\n",
    "np.save(os.path.join(train_dir, 'y_train.npy'), y_train)\n",
    "np.save(os.path.join(test_dir, 'y_test.npy'), y_test)\n",
    "\n",
    "s3_prefix = 'tf-2-workflow'\n",
    "rawdata_s3_prefix = '{}/data/raw'.format(s3_prefix)\n",
    "raw_s3 = sess.upload_data(path='./data/raw/', key_prefix=rawdata_s3_prefix)\n",
    "print(raw_s3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SageMaker Processing을 사용하기 위해, 간단히 Python 데이터 프로세싱 스크립트를 만들어보겠습니다. 본 사례에서 우리는 SageMaker 에서 제공하는 Sckit-learn 컨테이너를 사용하겠습니다. 제공되는 컨테이너는 데이터 프로세싱을 위한 많은 함수들을 제공합니다. 여러분이 이 코드를 만들고 실행할 때에 약간의 제약사항이 있습니다. 입력과 출력 데이터는 분리된 디렉토리에 저장되어야 합니다. 이로부터 SageMaker Processing은 자동으로 입력 데이터를 S3로부터 로드하고 작업이 완료되면 변형이 완료된 데이터를 다시 S3로 업로드합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting preprocessing.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile preprocessing.py\n",
    "\n",
    "import glob\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "if __name__=='__main__':\n",
    "    \n",
    "    input_files = glob.glob('{}/*.npy'.format('/opt/ml/processing/input'))\n",
    "    print('\\nINPUT FILE LIST: \\n{}\\n'.format(input_files))\n",
    "    scaler = StandardScaler()\n",
    "    for file in input_files:\n",
    "        raw = np.load(file)\n",
    "        transformed = scaler.fit_transform(raw)\n",
    "        if 'train' in file:\n",
    "            output_path = os.path.join('/opt/ml/processing/train', 'x_train.npy')\n",
    "            np.save(output_path, transformed)\n",
    "            print('SAVED TRANSFORMED TRAINING DATA FILE\\n')\n",
    "        else:\n",
    "            output_path = os.path.join('/opt/ml/processing/test', 'x_test.npy')\n",
    "            np.save(output_path, transformed)\n",
    "            print('SAVED TRANSFORMED TEST DATA FILE\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SageMaker Processing 작업을 시작하기 전에, `SKLearnProcessor` 오브젝트를 만듭니다. 오브젝트 생성시 여러분은 작업에서 사용할 인스턴스 타입과 몇개의 인스턴스를 사용할 지 정의할 수 있습니다. 보스턴 집값 데이터셋은 매우 작은 데이터이지만 SageMaker Processing의 클러스터링 작업을 어떻게 샐행하는지 보기 위해 두 개의 인스턴스를 사용하겠습니다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker import get_execution_role\n",
    "from sagemaker.sklearn.processing import SKLearnProcessor\n",
    "\n",
    "sklearn_processor = SKLearnProcessor(framework_version='0.20.0',\n",
    "                                     role=get_execution_role(),\n",
    "                                     instance_type='ml.m5.xlarge',\n",
    "                                     instance_count=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 Processing 작업을 실행할 준비가 되었습니다. 데이터 파일을 인스턴스에 동일하게 분산하기 위해 우리는 `ProcessingInput` 오브젝트에 `SharedByS3Key` 분산타입을 지정하겠습니다. 이 경우 만약 여러분이 `n`개의 인스턴스를 선언했다면, 각 인스턴스는 `1/n` 파일을 S3로부터 받게 될 것입니다. 다음 셀의 작업을 실행하는 데는 3분 정도 소요되며 대부분의 시간은 클러스터를 구성하는 시간입니다. 이 작업이 끝나면 클러스터는 SageMaker에 의해 자동으로 삭제될 것입니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Job Name:  tf-2-workflow-03-00-25-14\n",
      "Inputs:  [{'InputName': 'input-1', 'S3Input': {'S3Uri': 's3://sagemaker-us-east-1-308961792850/tf-2-workflow/data/raw', 'LocalPath': '/opt/ml/processing/input', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'ShardedByS3Key', 'S3CompressionType': 'None'}}, {'InputName': 'code', 'S3Input': {'S3Uri': 's3://sagemaker-us-east-1-308961792850/tf-2-workflow-03-00-25-14/input/code/preprocessing.py', 'LocalPath': '/opt/ml/processing/input/code', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}]\n",
      "Outputs:  [{'OutputName': 'train', 'S3Output': {'S3Uri': 's3://sagemaker-us-east-1-308961792850/tf-2-workflow/data/train', 'LocalPath': '/opt/ml/processing/train', 'S3UploadMode': 'EndOfJob'}}, {'OutputName': 'test', 'S3Output': {'S3Uri': 's3://sagemaker-us-east-1-308961792850/tf-2-workflow/data/test', 'LocalPath': '/opt/ml/processing/test', 'S3UploadMode': 'EndOfJob'}}]\n",
      "......................\u001b[34m/miniconda3/lib/python3.7/site-packages/sklearn/externals/joblib/externals/cloudpickle/cloudpickle.py:47: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  import imp\n",
      "\u001b[0m\n",
      "\u001b[34mINPUT FILE LIST: \u001b[0m\n",
      "\u001b[34m['/opt/ml/processing/input/x_test.npy']\n",
      "\u001b[0m\n",
      "\u001b[34mSAVED TRANSFORMED TEST DATA FILE\n",
      "\u001b[0m\n",
      "\u001b[35m/miniconda3/lib/python3.7/site-packages/sklearn/externals/joblib/externals/cloudpickle/cloudpickle.py:47: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  import imp\n",
      "\u001b[0m\n",
      "\u001b[35mINPUT FILE LIST: \u001b[0m\n",
      "\u001b[35m['/opt/ml/processing/input/x_train.npy']\n",
      "\u001b[0m\n",
      "\u001b[35mSAVED TRANSFORMED TRAINING DATA FILE\n",
      "\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "from time import gmtime, strftime \n",
    "\n",
    "processing_job_name = \"tf-2-workflow-{}\".format(strftime(\"%d-%H-%M-%S\", gmtime()))\n",
    "output_destination = 's3://{}/{}/data'.format(bucket, s3_prefix)\n",
    "\n",
    "sklearn_processor.run(code='preprocessing.py',\n",
    "                      job_name=processing_job_name,\n",
    "                      inputs=[ProcessingInput(\n",
    "                        source=raw_s3,\n",
    "                        destination='/opt/ml/processing/input',\n",
    "                        s3_data_distribution_type='ShardedByS3Key')],\n",
    "                      outputs=[ProcessingOutput(output_name='train',\n",
    "                                                destination='{}/train'.format(output_destination),\n",
    "                                                source='/opt/ml/processing/train'),\n",
    "                               ProcessingOutput(output_name='test',\n",
    "                                                destination='{}/test'.format(output_destination),\n",
    "                                                source='/opt/ml/processing/test')])\n",
    "\n",
    "preprocessing_job_description = sklearn_processor.jobs[-1].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위 SageMaker Processing 작업의 출력 로그에서 여러분은 두 가지 다른 색상으로 두 개의 서로다른 인스턴스의 로그를 볼 수 있고 각 인스턴스는 서로 다른 파일을 받은 것을 확인할 수 있습니다. 만약 `ShardedByS3Key` 분산타입을 사용하지 않았다면 각 인스턴스는 **모든** 파일의 복사본을 받았을 것입니다. 대부분의 stateless 데이터변형에서는 `n`개의 인스턴스에 동일하게 파일을 분산함으로써 댜략 `n`만큼 작업속도를 더 빠르게 할 수 있습니다.  \n",
    "\n",
    "본 작업결과를 로컬에 저장한 후, 다음으로 로컬모드로 프로토타입 트레이닝과 추론코드를 작성하는 단계로 넘어가겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://sagemaker-us-east-1-308961792850/tf-2-workflow/data/train/x_train.npy to data/train/x_train.npy\n",
      "download: s3://sagemaker-us-east-1-308961792850/tf-2-workflow/data/test/x_test.npy to data/test/x_test.npy\n"
     ]
    }
   ],
   "source": [
    "train_in_s3 = '{}/train/x_train.npy'.format(output_destination)\n",
    "test_in_s3 = '{}/test/x_test.npy'.format(output_destination)\n",
    "!aws s3 cp {train_in_s3} ./data/train/x_train.npy\n",
    "!aws s3 cp {test_in_s3} ./data/test/x_test.npy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  로컬모드 (Local Mode) 학습 <a class=\"anchor\" id=\"LocalModeTraining\">\n",
    "\n",
    "SageMaker에서 로컬 모드는, 여러분이 작성한 코드를 SageMaker에서 관리되는 보다 강력한 클러스터에서 실행하기 전에, 여러분의 코드가 기대한 방식으로 동작하는 지 로컬에서 확인할 수 있는 편리한 방식입니다. 로컬모드 학습을 위해서는 docker-compose 또는 nvidia-docker-compose (GPU 인스턴스인 경우)의 설치가 필요합니다. 다음 셀의 명령은 본 노트북환경에 docker-compose 또는 nvidia-docker-compose를 설치하고 구성합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvidia-docker2 already installed. We are good to go!\n",
      "SageMaker instance route table setup is ok. We are good to go.\n",
      "SageMaker instance routing for Docker is ok. We are good to go!\n"
     ]
    }
   ],
   "source": [
    "!wget -q https://raw.githubusercontent.com/aws-samples/amazon-sagemaker-script-mode/master/local_mode_setup.sh\n",
    "!wget -q https://raw.githubusercontent.com/aws-samples/amazon-sagemaker-script-mode/master/daemon.json    \n",
    "!/bin/bash ./local_mode_setup.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다음으로 우리는 로컬모드 학습을 위해 Tensorflow Estimator를 구성할 것입니다. Estimator를 구성하는 주요 파라미터는 다음과 같습닏다.\n",
    "\n",
    "- `train_instance_type`: 학습이 실행될 하드웨어 종류. CPU환경의서의 로컬모드는 단순히 `local` 로 지정합니다. GPU가 필요한 경우에는 `local_gpu`로 지정합니다. \n",
    "- `git_config`:  학습 스크립트가 팀에의해 협업, 공유되어 관리되는 경우 Estimator는 로컬 디렉토리가 아닌 Git 리포지토리에서 코드를 가져올 수 있습니다.\n",
    "- Other parameters of note: Dictionary 형식으로 알고리즘의 하이퍼파리미터를 지정하고 Boolean 형식으로 Script Mode를 이용할 것인지를 지정합니다. \n",
    "\n",
    "여기서 우리는 주로 코드가 잘 동작하는지 확인하기 위해 로컬모드를 사용한다는 점을 기억하십시오. 우리는 불필요한 학습시간을 절약하기 위해, 전체 학습을 위한 큰 epoch 대신, 코드가 적절히 동작하는지 확인할 수 있는 정도의 작은 epoch으로 학습을 실행할 것입니다.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.tensorflow import TensorFlow\n",
    "\n",
    "git_config = {'repo': 'https://github.com/aws-samples/amazon-sagemaker-script-mode', \n",
    "              'branch': 'master'}\n",
    "\n",
    "model_dir = '/opt/ml/model'\n",
    "train_instance_type = 'local'\n",
    "hyperparameters = {'epochs': 5, 'batch_size': 128, 'learning_rate': 0.01}\n",
    "local_estimator = TensorFlow(git_config=git_config,\n",
    "                             source_dir='tf-2-workflow/train_model',\n",
    "                             entry_point='train.py',\n",
    "                             model_dir=model_dir,\n",
    "                             train_instance_type=train_instance_type,\n",
    "                             train_instance_count=1,\n",
    "                             hyperparameters=hyperparameters,\n",
    "                             role=sagemaker.get_execution_role(),\n",
    "                             base_job_name='tf-2-workflow',\n",
    "                             framework_version='2.1',\n",
    "                             py_version='py3',\n",
    "                             script_mode=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아래의 `fit` 함수는 로컬 모드에서 학습작업을 시작할 것입니다. 학습을 위한 지표(Metric)은 코드의 아래에 로그로 보일 것입니다. 다섯 번의 epoch이 실행되는 동안 오류가 발생하지 않고 검증 오류(validation loss)가 점점 줄어드는 것을 통해 여러분의 학습코드가 기대한 것과 같이 동작한다는 것을 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating tmph74mqhvi_algo-1-86mxc_1 ... \n",
      "\u001b[1BAttaching to tmph74mqhvi_algo-1-86mxc_12mdone\u001b[0m\n",
      "\u001b[36malgo-1-86mxc_1  |\u001b[0m 2020-06-03 00:30:16,855 sagemaker-containers INFO     Imported framework sagemaker_tensorflow_container.training\n",
      "\u001b[36malgo-1-86mxc_1  |\u001b[0m 2020-06-03 00:30:16,862 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36malgo-1-86mxc_1  |\u001b[0m 2020-06-03 00:30:17,010 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36malgo-1-86mxc_1  |\u001b[0m 2020-06-03 00:30:17,027 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36malgo-1-86mxc_1  |\u001b[0m 2020-06-03 00:30:17,045 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36malgo-1-86mxc_1  |\u001b[0m 2020-06-03 00:30:17,056 sagemaker-containers INFO     Invoking user script\n",
      "\u001b[36malgo-1-86mxc_1  |\u001b[0m \n",
      "\u001b[36malgo-1-86mxc_1  |\u001b[0m Training Env:\n",
      "\u001b[36malgo-1-86mxc_1  |\u001b[0m \n",
      "\u001b[36malgo-1-86mxc_1  |\u001b[0m {\n",
      "\u001b[36malgo-1-86mxc_1  |\u001b[0m     \"additional_framework_parameters\": {},\n",
      "\u001b[36malgo-1-86mxc_1  |\u001b[0m     \"channel_input_dirs\": {\n",
      "\u001b[36malgo-1-86mxc_1  |\u001b[0m         \"train\": \"/opt/ml/input/data/train\",\n",
      "\u001b[36malgo-1-86mxc_1  |\u001b[0m         \"test\": \"/opt/ml/input/data/test\"\n",
      "\u001b[36malgo-1-86mxc_1  |\u001b[0m     },\n",
      "\u001b[36malgo-1-86mxc_1  |\u001b[0m     \"current_host\": \"algo-1-86mxc\",\n",
      "\u001b[36malgo-1-86mxc_1  |\u001b[0m     \"framework_module\": \"sagemaker_tensorflow_container.training:main\",\n",
      "\u001b[36malgo-1-86mxc_1  |\u001b[0m     \"hosts\": [\n",
      "\u001b[36malgo-1-86mxc_1  |\u001b[0m         \"algo-1-86mxc\"\n",
      "\u001b[36malgo-1-86mxc_1  |\u001b[0m     ],\n",
      "\u001b[36malgo-1-86mxc_1  |\u001b[0m     \"hyperparameters\": {\n",
      "\u001b[36malgo-1-86mxc_1  |\u001b[0m         \"epochs\": 5,\n",
      "\u001b[36malgo-1-86mxc_1  |\u001b[0m         \"batch_size\": 128,\n",
      "\u001b[36malgo-1-86mxc_1  |\u001b[0m         \"learning_rate\": 0.01,\n",
      "\u001b[36malgo-1-86mxc_1  |\u001b[0m         \"model_dir\": \"/opt/ml/model\"\n",
      "\u001b[36malgo-1-86mxc_1  |\u001b[0m     },\n",
      "\u001b[36malgo-1-86mxc_1  |\u001b[0m     \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "\u001b[36malgo-1-86mxc_1  |\u001b[0m     \"input_data_config\": {\n",
      "\u001b[36malgo-1-86mxc_1  |\u001b[0m         \"train\": {\n",
      "\u001b[36malgo-1-86mxc_1  |\u001b[0m             \"TrainingInputMode\": \"File\"\n",
      "\u001b[36malgo-1-86mxc_1  |\u001b[0m         },\n",
      "\u001b[36malgo-1-86mxc_1  |\u001b[0m         \"test\": {\n",
      "\u001b[36malgo-1-86mxc_1  |\u001b[0m             \"TrainingInputMode\": \"File\"\n",
      "\u001b[36malgo-1-86mxc_1  |\u001b[0m         }\n",
      "\u001b[36malgo-1-86mxc_1  |\u001b[0m     },\n",
      "\u001b[36malgo-1-86mxc_1  |\u001b[0m     \"input_dir\": \"/opt/ml/input\",\n",
      "\u001b[36malgo-1-86mxc_1  |\u001b[0m     \"is_master\": true,\n",
      "\u001b[36malgo-1-86mxc_1  |\u001b[0m     \"job_name\": \"tf-2-workflow-2020-06-03-00-29-31-080\",\n",
      "\u001b[36malgo-1-86mxc_1  |\u001b[0m     \"log_level\": 20,\n",
      "\u001b[36malgo-1-86mxc_1  |\u001b[0m     \"master_hostname\": \"algo-1-86mxc\",\n",
      "\u001b[36malgo-1-86mxc_1  |\u001b[0m     \"model_dir\": \"/opt/ml/model\",\n",
      "\u001b[36malgo-1-86mxc_1  |\u001b[0m     \"module_dir\": \"s3://sagemaker-us-east-1-308961792850/tf-2-workflow-2020-06-03-00-29-31-080/source/sourcedir.tar.gz\",\n",
      "\u001b[36malgo-1-86mxc_1  |\u001b[0m     \"module_name\": \"train\",\n",
      "\u001b[36malgo-1-86mxc_1  |\u001b[0m     \"network_interface_name\": \"eth0\",\n",
      "\u001b[36malgo-1-86mxc_1  |\u001b[0m     \"num_cpus\": 8,\n",
      "\u001b[36malgo-1-86mxc_1  |\u001b[0m     \"num_gpus\": 0,\n",
      "\u001b[36malgo-1-86mxc_1  |\u001b[0m     \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "\u001b[36malgo-1-86mxc_1  |\u001b[0m     \"output_dir\": \"/opt/ml/output\",\n",
      "\u001b[36malgo-1-86mxc_1  |\u001b[0m     \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "\u001b[36malgo-1-86mxc_1  |\u001b[0m     \"resource_config\": {\n",
      "\u001b[36malgo-1-86mxc_1  |\u001b[0m         \"current_host\": \"algo-1-86mxc\",\n",
      "\u001b[36malgo-1-86mxc_1  |\u001b[0m         \"hosts\": [\n",
      "\u001b[36malgo-1-86mxc_1  |\u001b[0m             \"algo-1-86mxc\"\n",
      "\u001b[36malgo-1-86mxc_1  |\u001b[0m         ]\n",
      "\u001b[36malgo-1-86mxc_1  |\u001b[0m     },\n",
      "\u001b[36malgo-1-86mxc_1  |\u001b[0m     \"user_entry_point\": \"train.py\"\n",
      "\u001b[36malgo-1-86mxc_1  |\u001b[0m }\n",
      "\u001b[36malgo-1-86mxc_1  |\u001b[0m \n",
      "\u001b[36malgo-1-86mxc_1  |\u001b[0m Environment variables:\n",
      "\u001b[36malgo-1-86mxc_1  |\u001b[0m \n",
      "\u001b[36malgo-1-86mxc_1  |\u001b[0m SM_HOSTS=[\"algo-1-86mxc\"]\n",
      "\u001b[36malgo-1-86mxc_1  |\u001b[0m SM_NETWORK_INTERFACE_NAME=eth0\n",
      "\u001b[36malgo-1-86mxc_1  |\u001b[0m SM_HPS={\"batch_size\":128,\"epochs\":5,\"learning_rate\":0.01,\"model_dir\":\"/opt/ml/model\"}\n",
      "\u001b[36malgo-1-86mxc_1  |\u001b[0m SM_USER_ENTRY_POINT=train.py\n",
      "\u001b[36malgo-1-86mxc_1  |\u001b[0m SM_FRAMEWORK_PARAMS={}\n",
      "\u001b[36malgo-1-86mxc_1  |\u001b[0m SM_RESOURCE_CONFIG={\"current_host\":\"algo-1-86mxc\",\"hosts\":[\"algo-1-86mxc\"]}\n",
      "\u001b[36malgo-1-86mxc_1  |\u001b[0m SM_INPUT_DATA_CONFIG={\"test\":{\"TrainingInputMode\":\"File\"},\"train\":{\"TrainingInputMode\":\"File\"}}\n",
      "\u001b[36malgo-1-86mxc_1  |\u001b[0m SM_OUTPUT_DATA_DIR=/opt/ml/output/data\n",
      "\u001b[36malgo-1-86mxc_1  |\u001b[0m SM_CHANNELS=[\"test\",\"train\"]\n",
      "\u001b[36malgo-1-86mxc_1  |\u001b[0m SM_CURRENT_HOST=algo-1-86mxc\n",
      "\u001b[36malgo-1-86mxc_1  |\u001b[0m SM_MODULE_NAME=train\n",
      "\u001b[36malgo-1-86mxc_1  |\u001b[0m SM_LOG_LEVEL=20\n",
      "\u001b[36malgo-1-86mxc_1  |\u001b[0m SM_FRAMEWORK_MODULE=sagemaker_tensorflow_container.training:main\n",
      "\u001b[36malgo-1-86mxc_1  |\u001b[0m SM_INPUT_DIR=/opt/ml/input\n",
      "\u001b[36malgo-1-86mxc_1  |\u001b[0m SM_INPUT_CONFIG_DIR=/opt/ml/input/config\n",
      "\u001b[36malgo-1-86mxc_1  |\u001b[0m SM_OUTPUT_DIR=/opt/ml/output\n",
      "\u001b[36malgo-1-86mxc_1  |\u001b[0m SM_NUM_CPUS=8\n",
      "\u001b[36malgo-1-86mxc_1  |\u001b[0m SM_NUM_GPUS=0\n",
      "\u001b[36malgo-1-86mxc_1  |\u001b[0m SM_MODEL_DIR=/opt/ml/model\n",
      "\u001b[36malgo-1-86mxc_1  |\u001b[0m SM_MODULE_DIR=s3://sagemaker-us-east-1-308961792850/tf-2-workflow-2020-06-03-00-29-31-080/source/sourcedir.tar.gz\n",
      "\u001b[36malgo-1-86mxc_1  |\u001b[0m SM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"test\":\"/opt/ml/input/data/test\",\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1-86mxc\",\"framework_module\":\"sagemaker_tensorflow_container.training:main\",\"hosts\":[\"algo-1-86mxc\"],\"hyperparameters\":{\"batch_size\":128,\"epochs\":5,\"learning_rate\":0.01,\"model_dir\":\"/opt/ml/model\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"test\":{\"TrainingInputMode\":\"File\"},\"train\":{\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"tf-2-workflow-2020-06-03-00-29-31-080\",\"log_level\":20,\"master_hostname\":\"algo-1-86mxc\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-308961792850/tf-2-workflow-2020-06-03-00-29-31-080/source/sourcedir.tar.gz\",\"module_name\":\"train\",\"network_interface_name\":\"eth0\",\"num_cpus\":8,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1-86mxc\",\"hosts\":[\"algo-1-86mxc\"]},\"user_entry_point\":\"train.py\"}\n",
      "\u001b[36malgo-1-86mxc_1  |\u001b[0m SM_USER_ARGS=[\"--batch_size\",\"128\",\"--epochs\",\"5\",\"--learning_rate\",\"0.01\",\"--model_dir\",\"/opt/ml/model\"]\n",
      "\u001b[36malgo-1-86mxc_1  |\u001b[0m SM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\n",
      "\u001b[36malgo-1-86mxc_1  |\u001b[0m SM_CHANNEL_TRAIN=/opt/ml/input/data/train\n",
      "\u001b[36malgo-1-86mxc_1  |\u001b[0m SM_CHANNEL_TEST=/opt/ml/input/data/test\n",
      "\u001b[36malgo-1-86mxc_1  |\u001b[0m SM_HP_EPOCHS=5\n",
      "\u001b[36malgo-1-86mxc_1  |\u001b[0m SM_HP_BATCH_SIZE=128\n",
      "\u001b[36malgo-1-86mxc_1  |\u001b[0m SM_HP_LEARNING_RATE=0.01\n",
      "\u001b[36malgo-1-86mxc_1  |\u001b[0m SM_HP_MODEL_DIR=/opt/ml/model\n",
      "\u001b[36malgo-1-86mxc_1  |\u001b[0m PYTHONPATH=/opt/ml/code:/usr/local/bin:/usr/lib/python36.zip:/usr/lib/python3.6:/usr/lib/python3.6/lib-dynload:/usr/local/lib/python3.6/dist-packages:/usr/lib/python3/dist-packages\n",
      "\u001b[36malgo-1-86mxc_1  |\u001b[0m \n",
      "\u001b[36malgo-1-86mxc_1  |\u001b[0m Invoking script with the following command:\n",
      "\u001b[36malgo-1-86mxc_1  |\u001b[0m \n",
      "\u001b[36malgo-1-86mxc_1  |\u001b[0m /usr/bin/python3 train.py --batch_size 128 --epochs 5 --learning_rate 0.01 --model_dir /opt/ml/model\n",
      "\u001b[36malgo-1-86mxc_1  |\u001b[0m \n",
      "\u001b[36malgo-1-86mxc_1  |\u001b[0m \n",
      "\u001b[36malgo-1-86mxc_1  |\u001b[0m x train (404, 13) y train (404,)\n",
      "\u001b[36malgo-1-86mxc_1  |\u001b[0m x test (102, 13) y test (102,)\n",
      "\u001b[36malgo-1-86mxc_1  |\u001b[0m /cpu:0\n",
      "\u001b[36malgo-1-86mxc_1  |\u001b[0m batch_size = 128, epochs = 5, learning rate = 0.01\n",
      "\u001b[36malgo-1-86mxc_1  |\u001b[0m Train on 404 samples, validate on 102 samples\n",
      "\u001b[36malgo-1-86mxc_1  |\u001b[0m Epoch 1/5\n",
      "404/404 [==============================] - 0s 1ms/sample - loss: 479.0423 - val_loss: 368.7282\n",
      "\u001b[36malgo-1-86mxc_1  |\u001b[0m Epoch 2/5\n",
      "404/404 [==============================] - 0s 33us/sample - loss: 299.2585 - val_loss: 205.7037\n",
      "\u001b[36malgo-1-86mxc_1  |\u001b[0m Epoch 3/5\n",
      "404/404 [==============================] - 0s 33us/sample - loss: 162.4976 - val_loss: 112.9306\n",
      "\u001b[36malgo-1-86mxc_1  |\u001b[0m Epoch 4/5\n",
      "404/404 [==============================] - 0s 34us/sample - loss: 95.4312 - val_loss: 72.0470\n",
      "\u001b[36malgo-1-86mxc_1  |\u001b[0m Epoch 5/5\n",
      "404/404 [==============================] - 0s 28us/sample - loss: 68.4659 - val_loss: 61.4376\n",
      "\u001b[36malgo-1-86mxc_1  |\u001b[0m 102/102 - 0s - loss: 61.4376\n",
      "\u001b[36malgo-1-86mxc_1  |\u001b[0m \n",
      "\u001b[36malgo-1-86mxc_1  |\u001b[0m Test MSE : 61.43764877319336\n",
      "\u001b[36malgo-1-86mxc_1  |\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "\u001b[36malgo-1-86mxc_1  |\u001b[0m Instructions for updating:\n",
      "\u001b[36malgo-1-86mxc_1  |\u001b[0m If using Keras pass *_constraint arguments to layers.\n",
      "\u001b[36malgo-1-86mxc_1  |\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "\u001b[36malgo-1-86mxc_1  |\u001b[0m Instructions for updating:\n",
      "\u001b[36malgo-1-86mxc_1  |\u001b[0m If using Keras pass *_constraint arguments to layers.\n",
      "\u001b[36malgo-1-86mxc_1  |\u001b[0m INFO:tensorflow:Assets written to: /opt/ml/model/1/assets\n",
      "\u001b[36malgo-1-86mxc_1  |\u001b[0m INFO:tensorflow:Assets written to: /opt/ml/model/1/assets\n",
      "\u001b[36malgo-1-86mxc_1  |\u001b[0m 2020-06-03 00:30:20,425 sagemaker-containers INFO     Reporting training SUCCESS\n",
      "\u001b[36mtmph74mqhvi_algo-1-86mxc_1 exited with code 0\n",
      "\u001b[0mAborting on container exit...\n",
      "===== Job Complete =====\n"
     ]
    }
   ],
   "source": [
    "inputs = {'train': f'file://{train_dir}',\n",
    "          'test': f'file://{test_dir}'}\n",
    "\n",
    "local_estimator.fit(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 로컬모드 (Local Mode) 엔드포인트 <a class=\"anchor\" id=\"LocalModeEndpoint\">\n",
    "\n",
    "SageMaker에서 로컬모드 학습은 전체 데이터를 이용하여 학습을 하기 전에 학습코드를 확인하는 용도로 매우 유용한 것과 같이, 여러분의 모델을 고사양의 자원이 있는 실제 운영환경에 배포하여 추론을 실행하기 전에 로컬 환경에서 검증하는 것 또한 유용할 수 있습니다. 이를 위해 Tensorflow SaveModel 아티펙트(artifact) 또는 S3에 저장된 모델 체크포인트를 가져와서(fetch) 노트북환경에 로드하고 검증하는 방식을 사용할 수 있습니다. 하지만 이보다 편리한 방법은 SageMaker Python SDK를 이용하여 로컬모드 엔드포인트(Local Mode endpoint)를 구성하는 것입니다. \n",
    "    \n",
    "보다 구체적으로, 로컬모드 학습을 이용하여 만들어진 Estimator 오브젝트는 로컬환경에 모델을 배포(deploy)할 수 있습니다. 이를 위해 로컬모드 학습에서 처럼 여러분의 노트북이 GPU 인스턴스인지 CPU인스턴스인지에 따라 인스턴스 타입을 `local_gpu` 또는 `local` 로 지정하고 로컬 Estimator의 배포모델을 invoke합니다.\n",
    "    \n",
    "다음 한 줄의 코드로 SageMaker Tensorflow Serving 컨테이너를 로컬에 deploy할 수 있습니다.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attaching to tmpenb79xmn_algo-1-bmwmv_1\n",
      "\u001b[36malgo-1-bmwmv_1  |\u001b[0m INFO:__main__:starting services\n",
      "\u001b[36malgo-1-bmwmv_1  |\u001b[0m INFO:__main__:using default model name: model\n",
      "\u001b[36malgo-1-bmwmv_1  |\u001b[0m INFO:__main__:tensorflow serving model config: \n",
      "\u001b[36malgo-1-bmwmv_1  |\u001b[0m model_config_list: {\n",
      "\u001b[36malgo-1-bmwmv_1  |\u001b[0m   config: {\n",
      "\u001b[36malgo-1-bmwmv_1  |\u001b[0m     name: \"model\",\n",
      "\u001b[36malgo-1-bmwmv_1  |\u001b[0m     base_path: \"/opt/ml/model\",\n",
      "\u001b[36malgo-1-bmwmv_1  |\u001b[0m     model_platform: \"tensorflow\"\n",
      "\u001b[36malgo-1-bmwmv_1  |\u001b[0m   }\n",
      "\u001b[36malgo-1-bmwmv_1  |\u001b[0m }\n",
      "\u001b[36malgo-1-bmwmv_1  |\u001b[0m \n",
      "\u001b[36malgo-1-bmwmv_1  |\u001b[0m \n",
      "\u001b[36malgo-1-bmwmv_1  |\u001b[0m INFO:__main__:nginx config: \n",
      "\u001b[36malgo-1-bmwmv_1  |\u001b[0m load_module modules/ngx_http_js_module.so;\n",
      "\u001b[36malgo-1-bmwmv_1  |\u001b[0m \n",
      "\u001b[36malgo-1-bmwmv_1  |\u001b[0m worker_processes auto;\n",
      "\u001b[36malgo-1-bmwmv_1  |\u001b[0m daemon off;\n",
      "\u001b[36malgo-1-bmwmv_1  |\u001b[0m pid /tmp/nginx.pid;\n",
      "\u001b[36malgo-1-bmwmv_1  |\u001b[0m error_log  /dev/stderr info;\n",
      "\u001b[36malgo-1-bmwmv_1  |\u001b[0m \n",
      "\u001b[36malgo-1-bmwmv_1  |\u001b[0m worker_rlimit_nofile 4096;\n",
      "\u001b[36malgo-1-bmwmv_1  |\u001b[0m \n",
      "\u001b[36malgo-1-bmwmv_1  |\u001b[0m events {\n",
      "\u001b[36malgo-1-bmwmv_1  |\u001b[0m   worker_connections 2048;\n",
      "\u001b[36malgo-1-bmwmv_1  |\u001b[0m }\n",
      "\u001b[36malgo-1-bmwmv_1  |\u001b[0m \n",
      "\u001b[36malgo-1-bmwmv_1  |\u001b[0m http {\n",
      "\u001b[36malgo-1-bmwmv_1  |\u001b[0m   include /etc/nginx/mime.types;\n",
      "\u001b[36malgo-1-bmwmv_1  |\u001b[0m   default_type application/json;\n",
      "\u001b[36malgo-1-bmwmv_1  |\u001b[0m   access_log /dev/stdout combined;\n",
      "\u001b[36malgo-1-bmwmv_1  |\u001b[0m   js_include tensorflow-serving.js;\n",
      "\u001b[36malgo-1-bmwmv_1  |\u001b[0m \n",
      "\u001b[36malgo-1-bmwmv_1  |\u001b[0m   upstream tfs_upstream {\n",
      "\u001b[36malgo-1-bmwmv_1  |\u001b[0m     server localhost:8501;\n",
      "\u001b[36malgo-1-bmwmv_1  |\u001b[0m   }\n",
      "\u001b[36malgo-1-bmwmv_1  |\u001b[0m \n",
      "\u001b[36malgo-1-bmwmv_1  |\u001b[0m   upstream gunicorn_upstream {\n",
      "\u001b[36malgo-1-bmwmv_1  |\u001b[0m     server unix:/tmp/gunicorn.sock fail_timeout=1;\n",
      "\u001b[36malgo-1-bmwmv_1  |\u001b[0m   }\n",
      "\u001b[36malgo-1-bmwmv_1  |\u001b[0m \n",
      "\u001b[36malgo-1-bmwmv_1  |\u001b[0m   server {\n",
      "\u001b[36malgo-1-bmwmv_1  |\u001b[0m     listen 8080 deferred;\n",
      "\u001b[36malgo-1-bmwmv_1  |\u001b[0m     client_max_body_size 0;\n",
      "\u001b[36malgo-1-bmwmv_1  |\u001b[0m     client_body_buffer_size 100m;\n",
      "\u001b[36malgo-1-bmwmv_1  |\u001b[0m     subrequest_output_buffer_size 100m;\n",
      "\u001b[36malgo-1-bmwmv_1  |\u001b[0m \n",
      "\u001b[36malgo-1-bmwmv_1  |\u001b[0m     set $tfs_version 2.1;\n",
      "\u001b[36malgo-1-bmwmv_1  |\u001b[0m     set $default_tfs_model model;\n",
      "\u001b[36malgo-1-bmwmv_1  |\u001b[0m \n",
      "\u001b[36malgo-1-bmwmv_1  |\u001b[0m     location /tfs {\n",
      "\u001b[36malgo-1-bmwmv_1  |\u001b[0m         rewrite ^/tfs/(.*) /$1  break;\n",
      "\u001b[36malgo-1-bmwmv_1  |\u001b[0m         proxy_redirect off;\n",
      "\u001b[36malgo-1-bmwmv_1  |\u001b[0m         proxy_pass_request_headers off;\n",
      "\u001b[36malgo-1-bmwmv_1  |\u001b[0m         proxy_set_header Content-Type 'application/json';\n",
      "\u001b[36malgo-1-bmwmv_1  |\u001b[0m         proxy_set_header Accept 'application/json';\n",
      "\u001b[36malgo-1-bmwmv_1  |\u001b[0m         proxy_pass http://tfs_upstream;\n",
      "\u001b[36malgo-1-bmwmv_1  |\u001b[0m     }\n",
      "\u001b[36malgo-1-bmwmv_1  |\u001b[0m \n",
      "\u001b[36malgo-1-bmwmv_1  |\u001b[0m     location /ping {\n",
      "\u001b[36malgo-1-bmwmv_1  |\u001b[0m         js_content ping_without_model;\n",
      "\u001b[36malgo-1-bmwmv_1  |\u001b[0m     }\n",
      "\u001b[36malgo-1-bmwmv_1  |\u001b[0m \n",
      "\u001b[36malgo-1-bmwmv_1  |\u001b[0m     location /invocations {\n",
      "\u001b[36malgo-1-bmwmv_1  |\u001b[0m         js_content invocations;\n",
      "\u001b[36malgo-1-bmwmv_1  |\u001b[0m     }\n",
      "\u001b[36malgo-1-bmwmv_1  |\u001b[0m \n",
      "\u001b[36malgo-1-bmwmv_1  |\u001b[0m     location ~ ^/models/(.*)/invoke {\n",
      "\u001b[36malgo-1-bmwmv_1  |\u001b[0m         js_content invocations;\n",
      "\u001b[36malgo-1-bmwmv_1  |\u001b[0m     }\n",
      "\u001b[36malgo-1-bmwmv_1  |\u001b[0m \n",
      "\u001b[36malgo-1-bmwmv_1  |\u001b[0m     location /models {\n",
      "\u001b[36malgo-1-bmwmv_1  |\u001b[0m         proxy_pass http://gunicorn_upstream/models;\n",
      "\u001b[36malgo-1-bmwmv_1  |\u001b[0m     }\n",
      "\u001b[36malgo-1-bmwmv_1  |\u001b[0m \n",
      "\u001b[36malgo-1-bmwmv_1  |\u001b[0m     location / {\n",
      "\u001b[36malgo-1-bmwmv_1  |\u001b[0m         return 404 '{\"error\": \"Not Found\"}';\n",
      "\u001b[36malgo-1-bmwmv_1  |\u001b[0m     }\n",
      "\u001b[36malgo-1-bmwmv_1  |\u001b[0m \n",
      "\u001b[36malgo-1-bmwmv_1  |\u001b[0m     keepalive_timeout 3;\n",
      "\u001b[36malgo-1-bmwmv_1  |\u001b[0m   }\n",
      "\u001b[36malgo-1-bmwmv_1  |\u001b[0m }\n",
      "\u001b[36malgo-1-bmwmv_1  |\u001b[0m \n",
      "\u001b[36malgo-1-bmwmv_1  |\u001b[0m \n",
      "\u001b[36malgo-1-bmwmv_1  |\u001b[0m INFO:__main__:tensorflow version info:\n",
      "\u001b[36malgo-1-bmwmv_1  |\u001b[0m TensorFlow ModelServer: 2.1.0-rc1+dev.sha.075ffcf\n",
      "\u001b[36malgo-1-bmwmv_1  |\u001b[0m TensorFlow Library: 2.1.0\n",
      "\u001b[36malgo-1-bmwmv_1  |\u001b[0m INFO:__main__:tensorflow serving command: tensorflow_model_server --port=9000 --rest_api_port=8501 --model_config_file=/sagemaker/model-config.cfg --max_num_load_retries=0 \n",
      "\u001b[36malgo-1-bmwmv_1  |\u001b[0m INFO:__main__:started tensorflow serving (pid: 11)\n",
      "\u001b[36malgo-1-bmwmv_1  |\u001b[0m INFO:__main__:nginx version info:\n",
      "\u001b[36malgo-1-bmwmv_1  |\u001b[0m nginx version: nginx/1.18.0\n",
      "\u001b[36malgo-1-bmwmv_1  |\u001b[0m built by gcc 7.4.0 (Ubuntu 7.4.0-1ubuntu1~18.04.1) \n",
      "\u001b[36malgo-1-bmwmv_1  |\u001b[0m built with OpenSSL 1.1.1  11 Sep 2018\n",
      "\u001b[36malgo-1-bmwmv_1  |\u001b[0m TLS SNI support enabled\n",
      "\u001b[36malgo-1-bmwmv_1  |\u001b[0m configure arguments: --prefix=/etc/nginx --sbin-path=/usr/sbin/nginx --modules-path=/usr/lib/nginx/modules --conf-path=/etc/nginx/nginx.conf --error-log-path=/var/log/nginx/error.log --http-log-path=/var/log/nginx/access.log --pid-path=/var/run/nginx.pid --lock-path=/var/run/nginx.lock --http-client-body-temp-path=/var/cache/nginx/client_temp --http-proxy-temp-path=/var/cache/nginx/proxy_temp --http-fastcgi-temp-path=/var/cache/nginx/fastcgi_temp --http-uwsgi-temp-path=/var/cache/nginx/uwsgi_temp --http-scgi-temp-path=/var/cache/nginx/scgi_temp --user=nginx --group=nginx --with-compat --with-file-aio --with-threads --with-http_addition_module --with-http_auth_request_module --with-http_dav_module --with-http_flv_module --with-http_gunzip_module --with-http_gzip_static_module --with-http_mp4_module --with-http_random_index_module --with-http_realip_module --with-http_secure_link_module --with-http_slice_module --with-http_ssl_module --with-http_stub_status_module --with-http_sub_module --with-http_v2_module --with-mail --with-mail_ssl_module --with-stream --with-stream_realip_module --with-stream_ssl_module --with-stream_ssl_preread_module --with-cc-opt='-g -O2 -fdebug-prefix-map=/data/builder/debuild/nginx-1.18.0/debian/debuild-base/nginx-1.18.0=. -fstack-protector-strong -Wformat -Werror=format-security -Wp,-D_FORTIFY_SOURCE=2 -fPIC' --with-ld-opt='-Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-z,now -Wl,--as-needed -pie'\n",
      "\u001b[36malgo-1-bmwmv_1  |\u001b[0m INFO:__main__:started nginx (pid: 13)\n",
      "\u001b[36malgo-1-bmwmv_1  |\u001b[0m 2020/06/03 00:30:40 [notice] 13#13: using the \"epoll\" event method\n",
      "\u001b[36malgo-1-bmwmv_1  |\u001b[0m 2020/06/03 00:30:40 [notice] 13#13: nginx/1.18.0\n",
      "\u001b[36malgo-1-bmwmv_1  |\u001b[0m 2020/06/03 00:30:40 [notice] 13#13: built by gcc 7.4.0 (Ubuntu 7.4.0-1ubuntu1~18.04.1) \n",
      "\u001b[36malgo-1-bmwmv_1  |\u001b[0m 2020/06/03 00:30:40 [notice] 13#13: OS: Linux 4.14.171-105.231.amzn1.x86_64\n",
      "\u001b[36malgo-1-bmwmv_1  |\u001b[0m 2020/06/03 00:30:40 [notice] 13#13: getrlimit(RLIMIT_NOFILE): 1024:4096\n",
      "\u001b[36malgo-1-bmwmv_1  |\u001b[0m 2020/06/03 00:30:40 [notice] 13#13: start worker processes\n",
      "\u001b[36malgo-1-bmwmv_1  |\u001b[0m 2020/06/03 00:30:40 [notice] 13#13: start worker process 14\n",
      "\u001b[36malgo-1-bmwmv_1  |\u001b[0m 2020/06/03 00:30:40 [notice] 13#13: start worker process 15\n",
      "\u001b[36malgo-1-bmwmv_1  |\u001b[0m 2020/06/03 00:30:40 [notice] 13#13: start worker process 16\n",
      "\u001b[36malgo-1-bmwmv_1  |\u001b[0m 2020/06/03 00:30:40 [notice] 13#13: start worker process 17\n",
      "\u001b[36malgo-1-bmwmv_1  |\u001b[0m 2020/06/03 00:30:40 [notice] 13#13: start worker process 18\n",
      "\u001b[36malgo-1-bmwmv_1  |\u001b[0m 2020/06/03 00:30:40 [notice] 13#13: start worker process 19\n",
      "\u001b[36malgo-1-bmwmv_1  |\u001b[0m 2020/06/03 00:30:40 [notice] 13#13: start worker process 20\n",
      "\u001b[36malgo-1-bmwmv_1  |\u001b[0m 2020/06/03 00:30:40 [notice] 13#13: start worker process 21\n",
      "\u001b[36malgo-1-bmwmv_1  |\u001b[0m 2020-06-03 00:30:40.737707: I tensorflow_serving/model_servers/server_core.cc:462] Adding/updating models.\n",
      "\u001b[36malgo-1-bmwmv_1  |\u001b[0m 2020-06-03 00:30:40.737754: I tensorflow_serving/model_servers/server_core.cc:573]  (Re-)adding model: model\n",
      "\u001b[36malgo-1-bmwmv_1  |\u001b[0m 2020-06-03 00:30:40.838135: I tensorflow_serving/util/retrier.cc:46] Retrying of Reserving resources for servable: {name: model version: 1} exhausted max_num_retries: 0\n",
      "\u001b[36malgo-1-bmwmv_1  |\u001b[0m 2020-06-03 00:30:40.838187: I tensorflow_serving/core/basic_manager.cc:739] Successfully reserved resources to load servable {name: model version: 1}\n",
      "\u001b[36malgo-1-bmwmv_1  |\u001b[0m 2020-06-03 00:30:40.838205: I tensorflow_serving/core/loader_harness.cc:66] Approving load for servable version {name: model version: 1}\n",
      "\u001b[36malgo-1-bmwmv_1  |\u001b[0m 2020-06-03 00:30:40.838223: I tensorflow_serving/core/loader_harness.cc:74] Loading servable version {name: model version: 1}\n",
      "\u001b[36malgo-1-bmwmv_1  |\u001b[0m 2020-06-03 00:30:40.838271: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:31] Reading SavedModel from: /opt/ml/model/1\n",
      "\u001b[36malgo-1-bmwmv_1  |\u001b[0m 2020-06-03 00:30:40.840740: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:54] Reading meta graph with tags { serve }\n",
      "\u001b[36malgo-1-bmwmv_1  |\u001b[0m 2020-06-03 00:30:40.840778: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:264] Reading SavedModel debug info (if present) from: /opt/ml/model/1\n",
      "\u001b[36malgo-1-bmwmv_1  |\u001b[0m 2020-06-03 00:30:40.842247: I external/org_tensorflow/tensorflow/core/common_runtime/process_util.cc:147] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
      "\u001b[36malgo-1-bmwmv_1  |\u001b[0m 2020-06-03 00:30:40.880988: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:203] Restoring SavedModel bundle.\n",
      "\u001b[36malgo-1-bmwmv_1  |\u001b[0m 2020-06-03 00:30:40.914540: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:152] Running initialization op on SavedModel bundle at path: /opt/ml/model/1\n",
      "\u001b[36malgo-1-bmwmv_1  |\u001b[0m 2020-06-03 00:30:40.919730: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:333] SavedModel load for tags { serve }; Status: success: OK. Took 81462 microseconds.\n",
      "\u001b[36malgo-1-bmwmv_1  |\u001b[0m 2020-06-03 00:30:40.920278: I tensorflow_serving/servables/tensorflow/saved_model_warmup.cc:105] No warmup data file found at /opt/ml/model/1/assets.extra/tf_serving_warmup_requests\n",
      "\u001b[36malgo-1-bmwmv_1  |\u001b[0m 2020-06-03 00:30:40.920652: I tensorflow_serving/util/retrier.cc:46] Retrying of Loading servable: {name: model version: 1} exhausted max_num_retries: 0\n",
      "\u001b[36malgo-1-bmwmv_1  |\u001b[0m 2020-06-03 00:30:40.920674: I tensorflow_serving/core/loader_harness.cc:87] Successfully loaded servable version {name: model version: 1}\n",
      "\u001b[36malgo-1-bmwmv_1  |\u001b[0m 2020-06-03 00:30:40.924494: I tensorflow_serving/model_servers/server.cc:362] Running gRPC ModelServer at 0.0.0.0:9000 ...\n",
      "\u001b[36malgo-1-bmwmv_1  |\u001b[0m [warn] getaddrinfo: address family for nodename not supported\n",
      "\u001b[36malgo-1-bmwmv_1  |\u001b[0m 2020-06-03 00:30:40.926255: I tensorflow_serving/model_servers/server.cc:382] Exporting HTTP/REST API at:localhost:8501 ...\n",
      "\u001b[36malgo-1-bmwmv_1  |\u001b[0m [evhttp_server.cc : 238] NET_LOG: Entering the event loop ...\n",
      "!\u001b[36malgo-1-bmwmv_1  |\u001b[0m 172.18.0.1 - - [03/Jun/2020:00:30:43 +0000] \"GET /ping HTTP/1.1\" 200 0 \"-\" \"-\"\n",
      "\u001b[36malgo-1-bmwmv_1  |\u001b[0m 2020/06/03 00:30:43 [info] 14#14: *1 client 172.18.0.1 closed keepalive connection\n"
     ]
    }
   ],
   "source": [
    "local_predictor = local_estimator.deploy(initial_instance_count=1, instance_type='local')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "로컬모드 엔드포인트에서 예측을 실행하기 위해, 앞 단계에서 생성된 Predictor의 predict 함수를 호출합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36malgo-1-bmwmv_1  |\u001b[0m 172.18.0.1 - - [03/Jun/2020:00:30:43 +0000] \"POST /invocations HTTP/1.1\" 200 164 \"-\" \"-\"\n"
     ]
    }
   ],
   "source": [
    "local_results = local_predictor.predict(x_test[:10])['predictions']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "예측결과(predictions)를 실제 값(target values)과 비교합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions: \t[11.7 15.7 21.7 17.2 21.5 17.2 17.3 20.8 21.7 18.6]\n",
      "target values: \t[ 7.2 18.8 19.  27.  22.2 24.5 31.2 22.9 20.5 23.2]\n"
     ]
    }
   ],
   "source": [
    "local_preds_flat_list = [float('%.1f'%(item)) for sublist in local_results for item in sublist]\n",
    "print('predictions: \\t{}'.format(np.array(local_preds_flat_list)))\n",
    "print('target values: \\t{}'.format(y_test[:10].round(decimals=1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "현재까지는 적은 epoch으로 학습을 실행했기 때문에 개선이 필요합니다. 하지만 예측값은 어느정도 합리적인 범위에서 리턴되어야 합니다.\n",
    "\n",
    "SageMaker Tensorflow Serving 컨테이너가 로컬에서 무한정 실행되는 것을 막기 위해, delete_endpoint()를 호출하여 중지시킵니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gracefully stopping... (press Ctrl+C again to force)\n"
     ]
    }
   ],
   "source": [
    "local_predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  SageMaker 호스팅 환경에서 학습 <a class=\"anchor\" id=\"SageMakerHostedTraining\">\n",
    "\n",
    "지금까지 로컬에서 코드가 실행되는 것을 확인했습니다. 이제 SageMaker가 호스팅하는 학습기능을 사용해보겠습니다. SageMaker가 호스팅하는 학습환경은 데이터의 사이즈가 크고, 분산학습이 필요한 등 보다 실제적인 학습에서 선호하는 환경일 것입니다. SageMaker가 호스팅하는 환경에서는 로컬 모드에서 처럼 노트북 인스턴스에서 학습이 실행되는 것이 아니라 SageMaker가 관리하는 별도의 클러스터에서 실행됩니다. 학습을 시작하기 전에 데이터는 S3 또는 EFS, FSx for Lustre 파일시스템에 저장되어 있어야 합니다. 본 예제에서는 S3를 사용할 것이므로 S3에 데이터를 업로드하고 작업이 잘 되었는지 확인합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_prefix = 'tf-2-workflow'\n",
    "\n",
    "traindata_s3_prefix = '{}/data/train'.format(s3_prefix)\n",
    "testdata_s3_prefix = '{}/data/test'.format(s3_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train': 's3://sagemaker-us-east-1-308961792850/tf-2-workflow/data/train', 'test': 's3://sagemaker-us-east-1-308961792850/tf-2-workflow/data/test'}\n"
     ]
    }
   ],
   "source": [
    "train_s3 = sess.upload_data(path='./data/train/', key_prefix=traindata_s3_prefix)\n",
    "test_s3 = sess.upload_data(path='./data/test/', key_prefix=testdata_s3_prefix)\n",
    "\n",
    "inputs = {'train':train_s3, 'test': test_s3}\n",
    "\n",
    "print(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 SageMaker 호스팅 환경에서 학습을 위해 Estimator를 셋업합니다. 이것은 로컬모드의 Estimator와 유사합니다만, 한가지 차이는 `train_instance_type` 항목이 `local`이 아닌 SageMaker ML 인스턴스 타입이 들어간다는 점입니다. 그리고, 우리는 우리의 코드가 잘 작동하는 것을 검증했으므로, 이번에는 보다 개선된 성능(보다 적은 validation loss)을 얻을 수 있도록 많은 epoch으로 작업을 실행하겠습니다. \n",
    "\n",
    "이 두 가지를 변경한 후 단순히 `fit`명령을 호출합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_instance_type = 'ml.c5.xlarge'\n",
    "hyperparameters = {'epochs': 30, 'batch_size': 128, 'learning_rate': 0.01}\n",
    "\n",
    "estimator = TensorFlow(git_config=git_config,\n",
    "                       source_dir='tf-2-workflow/train_model',\n",
    "                       entry_point='train.py',\n",
    "                       model_dir=model_dir,\n",
    "                       train_instance_type=train_instance_type,\n",
    "                       train_instance_count=1,\n",
    "                       hyperparameters=hyperparameters,\n",
    "                       role=sagemaker.get_execution_role(),\n",
    "                       base_job_name='tf-2-workflow',\n",
    "                       framework_version='2.1',\n",
    "                       py_version='py3',\n",
    "                       script_mode=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아래의 `fit`명령을 실행하여 SageMaker 호스팅환경에서의 학습을 시작한 후, epoch이 진행되면서 학습작업이 수렴하는지 관찰합니다. 로컬모드에서의 학습에 비해 검증 오류(validation loss)가 현저히 줄어드는지 확인합니다. 이보다 개선된 성능튜닝은 이후 **Automatic Model Tuning** 파트에서 다시 다루게 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-06-03 00:49:35 Starting - Starting the training job...\n",
      "2020-06-03 00:49:38 Starting - Launching requested ML instances......\n",
      "2020-06-03 00:51:02 Starting - Preparing the instances for training......\n",
      "2020-06-03 00:51:53 Downloading - Downloading input data\n",
      "2020-06-03 00:51:53 Training - Downloading the training image..\u001b[34m2020-06-03 00:52:14,167 sagemaker-containers INFO     Imported framework sagemaker_tensorflow_container.training\u001b[0m\n",
      "\u001b[34m2020-06-03 00:52:14,174 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2020-06-03 00:52:14,448 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2020-06-03 00:52:14,462 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2020-06-03 00:52:14,475 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2020-06-03 00:52:14,484 sagemaker-containers INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"test\": \"/opt/ml/input/data/test\",\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_tensorflow_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"batch_size\": 128,\n",
      "        \"model_dir\": \"/opt/ml/model\",\n",
      "        \"epochs\": 30,\n",
      "        \"learning_rate\": 0.01\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"test\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"tf-2-workflow-2020-06-03-00-49-34-678\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-1-308961792850/tf-2-workflow-2020-06-03-00-49-34-678/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"train\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"train.py\"\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"batch_size\":128,\"epochs\":30,\"learning_rate\":0.01,\"model_dir\":\"/opt/ml/model\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=train.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"test\",\"train\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=train\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_tensorflow_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-1-308961792850/tf-2-workflow-2020-06-03-00-49-34-678/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"test\":\"/opt/ml/input/data/test\",\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_tensorflow_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"batch_size\":128,\"epochs\":30,\"learning_rate\":0.01,\"model_dir\":\"/opt/ml/model\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"tf-2-workflow-2020-06-03-00-49-34-678\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-308961792850/tf-2-workflow-2020-06-03-00-49-34-678/source/sourcedir.tar.gz\",\"module_name\":\"train\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--batch_size\",\"128\",\"--epochs\",\"30\",\"--learning_rate\",\"0.01\",\"--model_dir\",\"/opt/ml/model\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TEST=/opt/ml/input/data/test\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mSM_HP_BATCH_SIZE=128\u001b[0m\n",
      "\u001b[34mSM_HP_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCHS=30\u001b[0m\n",
      "\u001b[34mSM_HP_LEARNING_RATE=0.01\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/usr/local/bin:/usr/lib/python36.zip:/usr/lib/python3.6:/usr/lib/python3.6/lib-dynload:/usr/local/lib/python3.6/dist-packages:/usr/lib/python3/dist-packages\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34m/usr/bin/python3 train.py --batch_size 128 --epochs 30 --learning_rate 0.01 --model_dir /opt/ml/model\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34mx train (404, 13) y train (404,)\u001b[0m\n",
      "\u001b[34mx test (102, 13) y test (102,)\u001b[0m\n",
      "\u001b[34m/cpu:0\u001b[0m\n",
      "\u001b[34mbatch_size = 128, epochs = 30, learning rate = 0.01\u001b[0m\n",
      "\u001b[34m[2020-06-03 00:52:16.328 ip-10-0-126-133.ec2.internal:23 INFO json_config.py:90] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[2020-06-03 00:52:16.329 ip-10-0-126-133.ec2.internal:23 INFO hook.py:183] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[2020-06-03 00:52:16.329 ip-10-0-126-133.ec2.internal:23 INFO hook.py:228] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34mTrain on 404 samples, validate on 102 samples\u001b[0m\n",
      "\u001b[34m[2020-06-03 00:52:16.405 ip-10-0-126-133.ec2.internal:23 INFO keras.py:68] Executing in TF2.x eager mode.TF 2.x eager doesn't provide gradient and optimizer variable values.SageMaker Debugger will not be saving gradients and optimizer variables in this case\u001b[0m\n",
      "\u001b[34mEpoch 1/30\u001b[0m\n",
      "\u001b[34m[2020-06-03 00:52:16.414 ip-10-0-126-133.ec2.internal:23 INFO hook.py:364] Monitoring the collections: metrics, losses, sm_metrics\u001b[0m\n",
      "\u001b[34mERROR:root:'NoneType' object has no attribute 'write'\u001b[0m\n",
      "\u001b[34m#015128/404 [========>.....................] - ETA: 0s - loss: 566.5953#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015404/404 [==============================] - 0s 1ms/sample - loss: 525.4131 - val_loss: 404.2368\u001b[0m\n",
      "\u001b[34mEpoch 2/30\u001b[0m\n",
      "\u001b[34m#015128/404 [========>.....................] - ETA: 0s - loss: 392.2990#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015404/404 [==============================] - 0s 33us/sample - loss: 332.4638 - val_loss: 230.5357\u001b[0m\n",
      "\u001b[34mEpoch 3/30\u001b[0m\n",
      "\u001b[34m#015128/404 [========>.....................] - ETA: 0s - loss: 205.1005#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015404/404 [==============================] - 0s 32us/sample - loss: 183.2768 - val_loss: 127.1644\u001b[0m\n",
      "\u001b[34mEpoch 4/30\u001b[0m\n",
      "\u001b[34m#015128/404 [========>.....................] - ETA: 0s - loss: 116.8198#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015404/404 [==============================] - 0s 32us/sample - loss: 106.1608 - val_loss: 85.0269\u001b[0m\n",
      "\u001b[34mEpoch 5/30\u001b[0m\n",
      "\u001b[34m#015128/404 [========>.....................] - ETA: 0s - loss: 64.1984#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015404/404 [==============================] - 0s 31us/sample - loss: 76.4080 - val_loss: 66.8034\u001b[0m\n",
      "\u001b[34mEpoch 6/30\u001b[0m\n",
      "\u001b[34m#015128/404 [========>.....................] - ETA: 0s - loss: 50.7902#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015404/404 [==============================] - 0s 31us/sample - loss: 63.5422 - val_loss: 57.9938\u001b[0m\n",
      "\u001b[34mEpoch 7/30\u001b[0m\n",
      "\u001b[34m#015128/404 [========>.....................] - ETA: 0s - loss: 74.5479#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015404/404 [==============================] - 0s 41us/sample - loss: 57.0571 - val_loss: 53.3447\u001b[0m\n",
      "\u001b[34mEpoch 8/30\u001b[0m\n",
      "\u001b[34m#015128/404 [========>.....................] - ETA: 0s - loss: 50.6853#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015404/404 [==============================] - 0s 37us/sample - loss: 53.3360 - val_loss: 48.6545\u001b[0m\n",
      "\u001b[34mEpoch 9/30\u001b[0m\n",
      "\u001b[34m#015128/404 [========>.....................] - ETA: 0s - loss: 66.2240#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015404/404 [==============================] - 0s 84us/sample - loss: 50.2132 - val_loss: 49.4234\u001b[0m\n",
      "\u001b[34mEpoch 10/30\u001b[0m\n",
      "\u001b[34m#015128/404 [========>.....................] - ETA: 0s - loss: 36.6890#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015404/404 [==============================] - 0s 74us/sample - loss: 48.1241 - val_loss: 45.1336\u001b[0m\n",
      "\u001b[34mEpoch 11/30\u001b[0m\n",
      "\u001b[34m#015128/404 [========>.....................] - ETA: 0s - loss: 43.4041#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015404/404 [==============================] - 0s 35us/sample - loss: 45.8875 - val_loss: 43.9102\u001b[0m\n",
      "\u001b[34mEpoch 12/30\u001b[0m\n",
      "\u001b[34m#015128/404 [========>.....................] - ETA: 0s - loss: 52.5707#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015404/404 [==============================] - 0s 30us/sample - loss: 44.1628 - val_loss: 39.5213\u001b[0m\n",
      "\u001b[34mEpoch 13/30\u001b[0m\n",
      "\u001b[34m#015128/404 [========>.....................] - ETA: 0s - loss: 23.8488#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015404/404 [==============================] - 0s 30us/sample - loss: 41.7843 - val_loss: 39.1151\u001b[0m\n",
      "\u001b[34mEpoch 14/30\u001b[0m\n",
      "\u001b[34m#015128/404 [========>.....................] - ETA: 0s - loss: 39.3185#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015404/404 [==============================] - 0s 31us/sample - loss: 39.9287 - val_loss: 36.8263\u001b[0m\n",
      "\u001b[34mEpoch 15/30\u001b[0m\n",
      "\u001b[34m#015128/404 [========>.....................] - ETA: 0s - loss: 51.0875#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015404/404 [==============================] - 0s 30us/sample - loss: 37.8709 - val_loss: 35.5959\u001b[0m\n",
      "\u001b[34mEpoch 16/30\u001b[0m\n",
      "\u001b[34m#015128/404 [========>.....................] - ETA: 0s - loss: 46.2503#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015404/404 [==============================] - 0s 37us/sample - loss: 36.2890 - val_loss: 34.4012\u001b[0m\n",
      "\u001b[34mEpoch 17/30\u001b[0m\n",
      "\u001b[34m#015128/404 [========>.....................] - ETA: 0s - loss: 23.1044#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015404/404 [==============================] - 0s 31us/sample - loss: 34.8649 - val_loss: 32.8372\u001b[0m\n",
      "\u001b[34mEpoch 18/30\u001b[0m\n",
      "\u001b[34m#015128/404 [========>.....................] - ETA: 0s - loss: 32.4262#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015404/404 [==============================] - 0s 32us/sample - loss: 33.5509 - val_loss: 34.3292\u001b[0m\n",
      "\u001b[34mEpoch 19/30\u001b[0m\n",
      "\u001b[34m#015128/404 [========>.....................] - ETA: 0s - loss: 29.1845#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015404/404 [==============================] - 0s 37us/sample - loss: 32.2470 - val_loss: 34.0586\u001b[0m\n",
      "\u001b[34mEpoch 20/30\u001b[0m\n",
      "\u001b[34m#015128/404 [========>.....................] - ETA: 0s - loss: 42.1897#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015404/404 [==============================] - 0s 39us/sample - loss: 33.0704 - val_loss: 30.3384\u001b[0m\n",
      "\u001b[34mEpoch 21/30\u001b[0m\n",
      "\u001b[34m#015128/404 [========>.....................] - ETA: 0s - loss: 33.7128#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015404/404 [==============================] - 0s 41us/sample - loss: 31.1187 - val_loss: 31.2218\u001b[0m\n",
      "\u001b[34mEpoch 22/30\u001b[0m\n",
      "\u001b[34m#015128/404 [========>.....................] - ETA: 0s - loss: 27.7013#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015404/404 [==============================] - 0s 34us/sample - loss: 28.5956 - val_loss: 28.9663\u001b[0m\n",
      "\u001b[34mEpoch 23/30\u001b[0m\n",
      "\u001b[34m#015128/404 [========>.....................] - ETA: 0s - loss: 35.3875#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015404/404 [==============================] - 0s 32us/sample - loss: 27.5244 - val_loss: 28.9585\u001b[0m\n",
      "\u001b[34mEpoch 24/30\u001b[0m\n",
      "\u001b[34m#015128/404 [========>.....................] - ETA: 0s - loss: 33.4631#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015404/404 [==============================] - 0s 31us/sample - loss: 26.4113 - val_loss: 27.0602\u001b[0m\n",
      "\u001b[34mEpoch 25/30\u001b[0m\n",
      "\u001b[34m#015128/404 [========>.....................] - ETA: 0s - loss: 33.0084#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015404/404 [==============================] - 0s 38us/sample - loss: 25.2845 - val_loss: 27.6666\u001b[0m\n",
      "\u001b[34mEpoch 26/30\u001b[0m\n",
      "\u001b[34m#015128/404 [========>.....................] - ETA: 0s - loss: 22.2605#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015404/404 [==============================] - 0s 37us/sample - loss: 24.3816 - val_loss: 26.1760\u001b[0m\n",
      "\u001b[34mEpoch 27/30\u001b[0m\n",
      "\u001b[34m#015128/404 [========>.....................] - ETA: 0s - loss: 24.8547#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015404/404 [==============================] - 0s 33us/sample - loss: 24.4276 - val_loss: 26.7643\u001b[0m\n",
      "\u001b[34mEpoch 28/30\u001b[0m\n",
      "\u001b[34m#015128/404 [========>.....................] - ETA: 0s - loss: 24.9014#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015404/404 [==============================] - 0s 30us/sample - loss: 23.8544 - val_loss: 26.0869\u001b[0m\n",
      "\u001b[34mEpoch 29/30\u001b[0m\n",
      "\u001b[34m#015128/404 [========>.....................] - ETA: 0s - loss: 19.0648#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015404/404 [==============================] - 0s 35us/sample - loss: 21.9309 - val_loss: 24.8085\u001b[0m\n",
      "\u001b[34mEpoch 30/30\u001b[0m\n",
      "\u001b[34m#015128/404 [========>.....................] - ETA: 0s - loss: 20.2760#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015404/404 [==============================] - 0s 33us/sample - loss: 21.0724 - val_loss: 27.4660\u001b[0m\n",
      "\u001b[34m102/102 - 0s - loss: 27.4660\n",
      "\u001b[0m\n",
      "\u001b[34mTest MSE : 27.46596908569336\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mIf using Keras pass *_constraint arguments to layers.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mIf using Keras pass *_constraint arguments to layers.\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Assets written to: /opt/ml/model/1/assets\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Assets written to: /opt/ml/model/1/assets\u001b[0m\n",
      "\u001b[34m[2020-06-03 00:52:17.602 ip-10-0-126-133.ec2.internal:23 INFO utils.py:25] The end of training job file will not be written for jobs running under SageMaker.\u001b[0m\n",
      "\u001b[34m2020-06-03 00:52:17,846 sagemaker-containers INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2020-06-03 00:52:28 Uploading - Uploading generated training model\n",
      "2020-06-03 00:52:28 Completed - Training job completed\n",
      "Training seconds: 48\n",
      "Billable seconds: 48\n"
     ]
    }
   ],
   "source": [
    "estimator.fit(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "로컬모드에서의 학습처럼 호스팅 환경에서의 학습 또한 결과 모델을 생성하고 S3에 저장하여 사용자가 쉽게 꺼내올 수 있습니다. SageMaker의 기능들은 모듈화 되어 있어서 SageMaker에서 학습한 모델을 가져와서 다른 환경에서 실행할 수도 있고 SageMaker 호스팅 환경에서 실행하 수도 있습니다. SageMaker 호스팅 환경에서 실행하는 방법은 본 노트북의 **SageMaker hosted endpoint** 파트에서 보실수 있습니다.\n",
    "\n",
    "S3로부터 모델을 가져올 때에는, 학습에 사용한 estimator에서 결과모델의 경로를 저장하고 있기 때문에 이를 참조하면 됩니다. estimator의 `model_data`속성에 저장된 S3 경로로부터 모델을 가져와서 압축을 해제하는 간단한 절차로 바로 내용 확인이 가능합니다. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://sagemaker-us-east-1-308961792850/tf-2-workflow-2020-06-03-00-49-34-678/output/model.tar.gz to model/model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp {estimator.model_data} ./model/model.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아카이빙된 모델 파일에는 .pb파일 등 Tensorflow Serving에서 추론을 실행하기 위한 필요한 리소스들이 포함되어 있습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/\n",
      "1/saved_model.pb\n",
      "1/assets/\n",
      "1/variables/\n",
      "1/variables/variables.index\n",
      "1/variables/variables.data-00000-of-00001\n"
     ]
    }
   ],
   "source": [
    "!tar -xvzf ./model/model.tar.gz -C ./model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 자동 모델 튜닝 (하이퍼파라미터 튜닝) <a class=\"anchor\" id=\"AutomaticModelTuning\">\n",
    "    \n",
    "지금까지 로컬모드에서 학습과 호스팅환경에서의 학습을 진행했습니다. 이 과정에서 epoch을 늘리는 것 이외에는 아직 더 나은 모델을 위한 하이퍼파라미터 튜닝은 진행하지 않았습니다. 적절한 하이퍼파라미터 값을 선택하는 것을 수작업으로 진행할 때에는 일반적으로 많은 시간이 필요하고 쉽지 않은 작업이 됩니다. 적절한 하이퍼파라미터의 조합은 데이터와 알고리즘에 따라 다릅니다. 어떤 알고리즘은 매우 다양한 하이퍼파라미터를 가지기도 하고, 어떤 알고리즘은 선택되는 하이퍼파라미티에 의해 매우 민감하게 동작하기도 합니다. 그리고 대부분의 경우 모델의 학습과 하이퍼파리미터 값의 관계는 비선형적입니다. SageMaker 자동 모델 튜닝(Automatic Model Tuning)은 이런 하이퍼파라미터 튜닝을 자동화하는 것을 도와줍니다. 자동 모델 튜닝 기능을 통해 하이퍼파라미터의 조합에 따라 여러개의 학습작업을 병렬로 실행하고 최고의 성능을 내는 하이퍼파라미터의 조합을 찾을 수 있습니다. \n",
    "\n",
    "그럼 튜닝하고자하는 하이퍼파라미터를 선택하고 가각 값의 범위를 지정하는 것부터 시작하겠습니다. 그다음 최적화를 위한 목표 지표(metric)을 지정합니다. 본 예제에서는 검증오류(validation loss)를 최소화하도록 설정하겠습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.tuner import IntegerParameter, CategoricalParameter, ContinuousParameter, HyperparameterTuner\n",
    "\n",
    "hyperparameter_ranges = {\n",
    "  'learning_rate': ContinuousParameter(0.001, 0.2, scaling_type=\"Logarithmic\"),\n",
    "  'epochs': IntegerParameter(10, 50),\n",
    "  'batch_size': IntegerParameter(64, 256),\n",
    "}\n",
    "\n",
    "metric_definitions = [{'Name': 'loss',\n",
    "                       'Regex': ' loss: ([0-9\\\\.]+)'},\n",
    "                     {'Name': 'val_loss',\n",
    "                       'Regex': ' val_loss: ([0-9\\\\.]+)'}]\n",
    "\n",
    "objective_metric_name = 'val_loss'\n",
    "objective_type = 'Minimize'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다음은 앞서 지정한 파라미터를 처리할 HyperparameterTuner 오브젝트를 선언합니다. 튜닝작업 설정시 최대로 실행할 학습작업의 수를 지정하게 됩니다. 하이퍼파라미터 튜닝 작업은 해당 숫자만큼 실행된 후 완료될 것입니다. \n",
    "\n",
    "동시에 병렬처리할 작업수도 함께 지정합니다. 본 예제에서는 5개로 설정하였습니다. 이렇게 세팅(max_job=15, max_parallel_jobs=5)할 경우, 하이퍼파라미터 튜닝 작업은 5개의 병렬작업을 가지는 3개의 시리즈로 튜닝작업을 실행하게 됩니다. 튜닝 전략은 디폴트로 베이지안 최적화(Bayesian Optimization)를 사용하며, 다음 학습작업은 이전 학습작업 그룹의 결과에 따라 적절한 하이퍼파리미터값을 찾게 됩니다. 때문에 모든 작업을 병렬로 실행하는 것보다 적절한 그룹으로 나누는 것이 좋습니다. 병렬작업수의 지정은 장단점이 있습니다. 보다 많은 병렬작업을 지정하면 전체 작업은 빨리 종료될 것이지만 이전 튜닝작업에서 찾은 정확도를 희생하게 됩니다.\n",
    "\n",
    "\n",
    "이제 HyperparameterTuner 오브젝트의 `fit`명령을 통해 하이퍼파라미터 튜닝작업을 실행합니다. 튜닝작업은 10분 정도 걸릴 것입니다. 작업결과를 기다리는 동안 SageMaker 콘솔의 **Hyperparameter tuning jobs** 항목을 통해 개별 학습작업의 메타데이터와 그 실행결과 등 튜닝 작업의 상태를 확인할 수 있습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..............................................................................................................................................!\n"
     ]
    }
   ],
   "source": [
    "tuner = HyperparameterTuner(estimator,\n",
    "                            objective_metric_name,\n",
    "                            hyperparameter_ranges,\n",
    "                            metric_definitions,\n",
    "                            max_jobs=15,\n",
    "                            max_parallel_jobs=5,\n",
    "                            objective_type=objective_type)\n",
    "\n",
    "tuning_job_name = \"tf-2-workflow-{}\".format(strftime(\"%d-%H-%M-%S\", gmtime()))\n",
    "tuner.fit(inputs, job_name=tuning_job_name)\n",
    "tuner.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "튜닝작업이 완료된 후에는 SageMaker Python SDK의 `HyperparameterTuningJobAnalytics` 오브젝트를 통해 성능 순서로 튜닝작업을 리스트업해 봅니다. 다양한 튜닝작업 결과 중 최고의 검증 오류(validation loss)를 가지는 top 5 작업을 조회합니다. 그리고 FinalObjectiveValue 컬럼을 참고하십시오. 튜닝작업마다 작업결과는 다양하지만 최고로 선정된 튜닝작업의 검증오류는 호스팅 환경에서 실행했던 (단순히 epoch값만 조정했던) 학습작업에 비해 현저히 낮은 것을 확인할 수 있습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FinalObjectiveValue</th>\n",
       "      <th>TrainingElapsedTimeSeconds</th>\n",
       "      <th>TrainingEndTime</th>\n",
       "      <th>TrainingJobName</th>\n",
       "      <th>TrainingJobStatus</th>\n",
       "      <th>TrainingStartTime</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>epochs</th>\n",
       "      <th>learning_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>20.085699</td>\n",
       "      <td>63.0</td>\n",
       "      <td>2020-06-03 23:36:46+00:00</td>\n",
       "      <td>tf-2-workflow-03-23-30-05-007-16c3fb40</td>\n",
       "      <td>Completed</td>\n",
       "      <td>2020-06-03 23:35:43+00:00</td>\n",
       "      <td>68.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.020228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.193600</td>\n",
       "      <td>46.0</td>\n",
       "      <td>2020-06-03 23:40:47+00:00</td>\n",
       "      <td>tf-2-workflow-03-23-30-05-015-879798b2</td>\n",
       "      <td>Completed</td>\n",
       "      <td>2020-06-03 23:40:01+00:00</td>\n",
       "      <td>73.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.083724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22.755600</td>\n",
       "      <td>45.0</td>\n",
       "      <td>2020-06-03 23:39:54+00:00</td>\n",
       "      <td>tf-2-workflow-03-23-30-05-012-716b5591</td>\n",
       "      <td>Completed</td>\n",
       "      <td>2020-06-03 23:39:09+00:00</td>\n",
       "      <td>153.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0.190668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>23.132999</td>\n",
       "      <td>58.0</td>\n",
       "      <td>2020-06-03 23:36:48+00:00</td>\n",
       "      <td>tf-2-workflow-03-23-30-05-009-ca9d32de</td>\n",
       "      <td>Completed</td>\n",
       "      <td>2020-06-03 23:35:50+00:00</td>\n",
       "      <td>65.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.024545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>23.411600</td>\n",
       "      <td>38.0</td>\n",
       "      <td>2020-06-03 23:33:15+00:00</td>\n",
       "      <td>tf-2-workflow-03-23-30-05-004-a8f0f5ff</td>\n",
       "      <td>Completed</td>\n",
       "      <td>2020-06-03 23:32:37+00:00</td>\n",
       "      <td>99.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.018695</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    FinalObjectiveValue  TrainingElapsedTimeSeconds           TrainingEndTime  \\\n",
       "8             20.085699                        63.0 2020-06-03 23:36:46+00:00   \n",
       "0             22.193600                        46.0 2020-06-03 23:40:47+00:00   \n",
       "3             22.755600                        45.0 2020-06-03 23:39:54+00:00   \n",
       "6             23.132999                        58.0 2020-06-03 23:36:48+00:00   \n",
       "11            23.411600                        38.0 2020-06-03 23:33:15+00:00   \n",
       "\n",
       "                           TrainingJobName TrainingJobStatus  \\\n",
       "8   tf-2-workflow-03-23-30-05-007-16c3fb40         Completed   \n",
       "0   tf-2-workflow-03-23-30-05-015-879798b2         Completed   \n",
       "3   tf-2-workflow-03-23-30-05-012-716b5591         Completed   \n",
       "6   tf-2-workflow-03-23-30-05-009-ca9d32de         Completed   \n",
       "11  tf-2-workflow-03-23-30-05-004-a8f0f5ff         Completed   \n",
       "\n",
       "           TrainingStartTime  batch_size  epochs  learning_rate  \n",
       "8  2020-06-03 23:35:43+00:00        68.0    45.0       0.020228  \n",
       "0  2020-06-03 23:40:01+00:00        73.0    50.0       0.083724  \n",
       "3  2020-06-03 23:39:09+00:00       153.0    49.0       0.190668  \n",
       "6  2020-06-03 23:35:50+00:00        65.0    17.0       0.024545  \n",
       "11 2020-06-03 23:32:37+00:00        99.0    30.0       0.018695  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuner_metrics = sagemaker.HyperparameterTuningJobAnalytics(tuning_job_name)\n",
    "tuner_metrics.dataframe().sort_values(['FinalObjectiveValue'], ascending=True).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "전체 학습시간과 학습작업 상태는 다음 라인의 코드로 확인할 수 있습니다. 자동 조기종료(early stopping) 여부의 디폴트 설정이 off 이기 때문에, 학습작업은 모두 완전하게 실행되었을 것입니다. 자세한 튜닝작업의 예제는 다음 [HPO_Analyze_TuningJob_Results.ipynb](https://github.com/awslabs/amazon-sagemaker-examples/blob/master/hyperparameter_tuning/analyze_results/HPO_Analyze_TuningJob_Results.ipynb) 노트북을 참조합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total training time is 0.24 hours\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Completed    15\n",
       "Name: TrainingJobStatus, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_time = tuner_metrics.dataframe()['TrainingElapsedTimeSeconds'].sum() / 3600\n",
    "print(\"The total training time is {:.2f} hours\".format(total_time))\n",
    "tuner_metrics.dataframe()['TrainingJobStatus'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SageMaker 호스팅 엔드포인트 <a class=\"anchor\" id=\"SageMakerHostedEndpoint\">\n",
    "\n",
    "자동 모델 튜닝작업에서 학습된 결과는 간단한 과정으로 운영환경에 배포할 수 있습니다. 가장 간편한 방식은 SageMaker 호스팅 엔드포인트를 사용하여 학습모델로부터 실시간 예측서비스를 구현하는 것입니다. (배치 변환 작업(Batch Transform jobs) 또한 비동기방식으로 대량 데이터에 대해 오프라인 예측을 실행할 수 있는 좋은 방식입니다.) 엔드포인트는 학습작업에서 생성한 Tensorflow 저장모델을 가져와서 Tensorflow 서빙 컨테이너에 배포할 것입니다. 이 작업은 다음 한 줄의 코드로 가능합니다.\n",
    "     \n",
    "보다 구체적으로, HyperparameterTuner 오브젝트의 `deploy` 명령을 호출하면 해당 튜닝 작업에서 최고로 선택된 모델을 SageMaker 호스팅 엔드포인트에 배포하게 됩니다. 호스팅환경으로의 배포 작업은 로컬모드 엔드포인트의 작업에 비하여 수분이상 더 소요될 수 있습니다. (추론코드 프로토타이핑이 목적일 때에는 로컬모드도 좋은 옵션일 수 있습니다.)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-06-03 23:36:46 Starting - Preparing the instances for training\n",
      "2020-06-03 23:36:46 Downloading - Downloading input data\n",
      "2020-06-03 23:36:46 Training - Training image download completed. Training in progress.\n",
      "2020-06-03 23:36:46 Uploading - Uploading generated training model\n",
      "2020-06-03 23:36:46 Completed - Training job completed\u001b[34m2020-06-03 23:36:17,786 sagemaker-containers INFO     Imported framework sagemaker_tensorflow_container.training\u001b[0m\n",
      "\u001b[34m2020-06-03 23:36:17,786 sagemaker-containers INFO     Failed to parse hyperparameter _tuning_objective_metric value val_loss to Json.\u001b[0m\n",
      "\u001b[34mReturning the value itself\u001b[0m\n",
      "\u001b[34m2020-06-03 23:36:17,792 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2020-06-03 23:36:17,800 sagemaker_tensorflow_container.training INFO     Appending the training job name to model_dir: /opt/ml/model\u001b[0m\n",
      "\u001b[34m2020-06-03 23:36:33,432 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2020-06-03 23:36:33,432 sagemaker-containers INFO     Failed to parse hyperparameter _tuning_objective_metric value val_loss to Json.\u001b[0m\n",
      "\u001b[34mReturning the value itself\u001b[0m\n",
      "\u001b[34m2020-06-03 23:36:33,441 sagemaker-containers INFO     Failed to parse hyperparameter _tuning_objective_metric value val_loss to Json.\u001b[0m\n",
      "\u001b[34mReturning the value itself\u001b[0m\n",
      "\u001b[34m2020-06-03 23:36:33,445 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2020-06-03 23:36:33,454 sagemaker-containers INFO     Failed to parse hyperparameter _tuning_objective_metric value val_loss to Json.\u001b[0m\n",
      "\u001b[34mReturning the value itself\u001b[0m\n",
      "\u001b[34m2020-06-03 23:36:33,458 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2020-06-03 23:36:33,466 sagemaker-containers INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {\n",
      "        \"sagemaker_estimator_module\": \"sagemaker.tensorflow.estimator\",\n",
      "        \"sagemaker_estimator_class_name\": \"TensorFlow\"\n",
      "    },\n",
      "    \"channel_input_dirs\": {\n",
      "        \"test\": \"/opt/ml/input/data/test\",\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_tensorflow_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"batch_size\": 68,\n",
      "        \"model_dir\": \"/opt/ml/model\",\n",
      "        \"epochs\": 45,\n",
      "        \"learning_rate\": 0.020227787325024327\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"test\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"tf-2-workflow-03-23-30-05-007-16c3fb40\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-1-308961792850/tf-2-workflow-03-23-30-05/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"train\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"train.py\"\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"batch_size\":68,\"epochs\":45,\"learning_rate\":0.020227787325024327,\"model_dir\":\"/opt/ml/model\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=train.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={\"sagemaker_estimator_class_name\":\"TensorFlow\",\"sagemaker_estimator_module\":\"sagemaker.tensorflow.estimator\"}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"test\",\"train\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=train\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_tensorflow_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-1-308961792850/tf-2-workflow-03-23-30-05/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{\"sagemaker_estimator_class_name\":\"TensorFlow\",\"sagemaker_estimator_module\":\"sagemaker.tensorflow.estimator\"},\"channel_input_dirs\":{\"test\":\"/opt/ml/input/data/test\",\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_tensorflow_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"batch_size\":68,\"epochs\":45,\"learning_rate\":0.020227787325024327,\"model_dir\":\"/opt/ml/model\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"tf-2-workflow-03-23-30-05-007-16c3fb40\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-308961792850/tf-2-workflow-03-23-30-05/source/sourcedir.tar.gz\",\"module_name\":\"train\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--batch_size\",\"68\",\"--epochs\",\"45\",\"--learning_rate\",\"0.020227787325024327\",\"--model_dir\",\"/opt/ml/model\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TEST=/opt/ml/input/data/test\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mSM_HP_BATCH_SIZE=68\u001b[0m\n",
      "\u001b[34mSM_HP_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCHS=45\u001b[0m\n",
      "\u001b[34mSM_HP_LEARNING_RATE=0.020227787325024327\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/usr/local/bin:/usr/lib/python36.zip:/usr/lib/python3.6:/usr/lib/python3.6/lib-dynload:/usr/local/lib/python3.6/dist-packages:/usr/lib/python3/dist-packages\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34m/usr/bin/python3 train.py --batch_size 68 --epochs 45 --learning_rate 0.020227787325024327 --model_dir /opt/ml/model\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34mx train (404, 13) y train (404,)\u001b[0m\n",
      "\u001b[34mx test (102, 13) y test (102,)\u001b[0m\n",
      "\u001b[34m/cpu:0\u001b[0m\n",
      "\u001b[34mbatch_size = 68, epochs = 45, learning rate = 0.020227787325024327\u001b[0m\n",
      "\u001b[34mTrain on 404 samples, validate on 102 samples\u001b[0m\n",
      "\u001b[34mEpoch 1/45\u001b[0m\n",
      "\u001b[34m#015 68/404 [====>.........................] - ETA: 1s - loss: 601.5820#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015404/404 [==============================] - 0s 1ms/sample - loss: 369.2633 - val_loss: 132.3639\u001b[0m\n",
      "\u001b[34mEpoch 2/45\u001b[0m\n",
      "\u001b[34m#015 68/404 [====>.........................] - ETA: 0s - loss: 103.5348#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015404/404 [==============================] - 0s 39us/sample - loss: 80.8494 - val_loss: 52.1826\u001b[0m\n",
      "\u001b[34mEpoch 3/45\u001b[0m\n",
      "\u001b[34m#015 68/404 [====>.........................] - ETA: 0s - loss: 57.9994#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015404/404 [==============================] - 0s 39us/sample - loss: 51.6857 - val_loss: 43.6181\u001b[0m\n",
      "\u001b[34mEpoch 4/45\u001b[0m\n",
      "\u001b[34m#015 68/404 [====>.........................] - ETA: 0s - loss: 60.9541#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015404/404 [==============================] - 0s 36us/sample - loss: 45.4753 - val_loss: 39.6945\u001b[0m\n",
      "\u001b[34mEpoch 5/45\u001b[0m\n",
      "\u001b[34m#015 68/404 [====>.........................] - ETA: 0s - loss: 57.0012#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015404/404 [==============================] - 0s 36us/sample - loss: 43.8287 - val_loss: 37.4812\u001b[0m\n",
      "\u001b[34mEpoch 6/45\u001b[0m\n",
      "\u001b[34m#015 68/404 [====>.........................] - ETA: 0s - loss: 31.1185#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015404/404 [==============================] - 0s 35us/sample - loss: 37.7717 - val_loss: 36.0169\u001b[0m\n",
      "\u001b[34mEpoch 7/45\u001b[0m\n",
      "\u001b[34m#015 68/404 [====>.........................] - ETA: 0s - loss: 45.7995#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015404/404 [==============================] - 0s 35us/sample - loss: 35.1546 - val_loss: 32.0143\u001b[0m\n",
      "\u001b[34mEpoch 8/45\u001b[0m\n",
      "\u001b[34m#015 68/404 [====>.........................] - ETA: 0s - loss: 28.1842#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015404/404 [==============================] - 0s 36us/sample - loss: 31.5458 - val_loss: 35.9129\u001b[0m\n",
      "\u001b[34mEpoch 9/45\u001b[0m\n",
      "\u001b[34m#015 68/404 [====>.........................] - ETA: 0s - loss: 30.0648#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015404/404 [==============================] - 0s 34us/sample - loss: 28.6710 - val_loss: 27.1032\u001b[0m\n",
      "\u001b[34mEpoch 10/45\u001b[0m\n",
      "\u001b[34m#015 68/404 [====>.........................] - ETA: 0s - loss: 29.2993#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015404/404 [==============================] - 0s 36us/sample - loss: 27.2745 - val_loss: 27.9515\u001b[0m\n",
      "\u001b[34mEpoch 11/45\u001b[0m\n",
      "\u001b[34m#015 68/404 [====>.........................] - ETA: 0s - loss: 20.1237#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015404/404 [==============================] - 0s 37us/sample - loss: 22.6281 - val_loss: 25.2305\u001b[0m\n",
      "\u001b[34mEpoch 12/45\u001b[0m\n",
      "\u001b[34m#015 68/404 [====>.........................] - ETA: 0s - loss: 17.4332#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015404/404 [==============================] - 0s 37us/sample - loss: 23.0605 - val_loss: 25.0327\u001b[0m\n",
      "\u001b[34mEpoch 13/45\u001b[0m\n",
      "\u001b[34m#015 68/404 [====>.........................] - ETA: 0s - loss: 15.9224#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015404/404 [==============================] - 0s 34us/sample - loss: 18.9216 - val_loss: 23.6970\u001b[0m\n",
      "\u001b[34mEpoch 14/45\u001b[0m\n",
      "\u001b[34m#015 68/404 [====>.........................] - ETA: 0s - loss: 23.3457#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015404/404 [==============================] - 0s 34us/sample - loss: 18.8464 - val_loss: 29.2822\u001b[0m\n",
      "\u001b[34mEpoch 15/45\u001b[0m\n",
      "\u001b[34m#015 68/404 [====>.........................] - ETA: 0s - loss: 17.2944#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015404/404 [==============================] - 0s 35us/sample - loss: 16.6753 - val_loss: 23.3455\u001b[0m\n",
      "\u001b[34mEpoch 16/45\u001b[0m\n",
      "\u001b[34m#015 68/404 [====>.........................] - ETA: 0s - loss: 8.5616#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015404/404 [==============================] - 0s 35us/sample - loss: 16.1573 - val_loss: 23.7502\u001b[0m\n",
      "\u001b[34mEpoch 17/45\u001b[0m\n",
      "\u001b[34m#015 68/404 [====>.........................] - ETA: 0s - loss: 10.7521#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015404/404 [==============================] - 0s 36us/sample - loss: 14.2132 - val_loss: 23.6101\u001b[0m\n",
      "\u001b[34mEpoch 18/45\u001b[0m\n",
      "\u001b[34m#015 68/404 [====>.........................] - ETA: 0s - loss: 14.0409#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015404/404 [==============================] - 0s 39us/sample - loss: 20.7607 - val_loss: 23.5560\u001b[0m\n",
      "\u001b[34mEpoch 19/45\u001b[0m\n",
      "\u001b[34m#015 68/404 [====>.........................] - ETA: 0s - loss: 18.7725#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015404/404 [==============================] - 0s 36us/sample - loss: 16.1966 - val_loss: 22.1746\u001b[0m\n",
      "\u001b[34mEpoch 20/45\u001b[0m\n",
      "\u001b[34m#015 68/404 [====>.........................] - ETA: 0s - loss: 19.5349#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015404/404 [==============================] - 0s 35us/sample - loss: 16.1177 - val_loss: 23.2074\u001b[0m\n",
      "\u001b[34mEpoch 21/45\u001b[0m\n",
      "\u001b[34m#015 68/404 [====>.........................] - ETA: 0s - loss: 15.9119#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015404/404 [==============================] - 0s 42us/sample - loss: 13.6038 - val_loss: 24.3323\u001b[0m\n",
      "\u001b[34mEpoch 22/45\u001b[0m\n",
      "\u001b[34m#015 68/404 [====>.........................] - ETA: 0s - loss: 11.6596#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015404/404 [==============================] - 0s 37us/sample - loss: 12.7966 - val_loss: 25.1803\u001b[0m\n",
      "\u001b[34mEpoch 23/45\u001b[0m\n",
      "\u001b[34m#015 68/404 [====>.........................] - ETA: 0s - loss: 11.2734#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015404/404 [==============================] - 0s 33us/sample - loss: 12.3712 - val_loss: 24.2761\u001b[0m\n",
      "\u001b[34mEpoch 24/45\u001b[0m\n",
      "\u001b[34m#015 68/404 [====>.........................] - ETA: 0s - loss: 9.3930#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015404/404 [==============================] - 0s 34us/sample - loss: 11.7985 - val_loss: 22.9775\u001b[0m\n",
      "\u001b[34mEpoch 25/45\u001b[0m\n",
      "\u001b[34m#015 68/404 [====>.........................] - ETA: 0s - loss: 16.8713#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015404/404 [==============================] - 0s 35us/sample - loss: 10.8498 - val_loss: 21.3897\u001b[0m\n",
      "\u001b[34mEpoch 26/45\u001b[0m\n",
      "\u001b[34m#015 68/404 [====>.........................] - ETA: 0s - loss: 8.5607#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015404/404 [==============================] - 0s 35us/sample - loss: 9.9338 - val_loss: 22.2777\u001b[0m\n",
      "\u001b[34mEpoch 27/45\u001b[0m\n",
      "\u001b[34m#015 68/404 [====>.........................] - ETA: 0s - loss: 8.1045#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015404/404 [==============================] - 0s 35us/sample - loss: 9.4774 - val_loss: 22.1335\u001b[0m\n",
      "\u001b[34mEpoch 28/45\u001b[0m\n",
      "\u001b[34m#015 68/404 [====>.........................] - ETA: 0s - loss: 4.0381#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015404/404 [==============================] - 0s 35us/sample - loss: 8.7327 - val_loss: 20.8026\u001b[0m\n",
      "\u001b[34mEpoch 29/45\u001b[0m\n",
      "\u001b[34m#015 68/404 [====>.........................] - ETA: 0s - loss: 7.2199#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015404/404 [==============================] - 0s 34us/sample - loss: 10.8081 - val_loss: 21.1867\u001b[0m\n",
      "\u001b[34mEpoch 30/45\u001b[0m\n",
      "\u001b[34m#015 68/404 [====>.........................] - ETA: 0s - loss: 7.2112#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015404/404 [==============================] - 0s 35us/sample - loss: 8.9321 - val_loss: 23.2635\u001b[0m\n",
      "\u001b[34mEpoch 31/45\u001b[0m\n",
      "\u001b[34m#015 68/404 [====>.........................] - ETA: 0s - loss: 9.6506#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015404/404 [==============================] - 0s 36us/sample - loss: 8.1851 - val_loss: 20.9778\u001b[0m\n",
      "\u001b[34mEpoch 32/45\u001b[0m\n",
      "\u001b[34m#015 68/404 [====>.........................] - ETA: 0s - loss: 9.1833#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015404/404 [==============================] - 0s 35us/sample - loss: 11.0883 - val_loss: 28.4861\u001b[0m\n",
      "\u001b[34mEpoch 33/45\u001b[0m\n",
      "\u001b[34m#015 68/404 [====>.........................] - ETA: 0s - loss: 9.8500#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015404/404 [==============================] - 0s 35us/sample - loss: 9.0606 - val_loss: 21.9751\u001b[0m\n",
      "\u001b[34mEpoch 34/45\u001b[0m\n",
      "\u001b[34m#015 68/404 [====>.........................] - ETA: 0s - loss: 9.5578#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015404/404 [==============================] - 0s 34us/sample - loss: 9.3089 - val_loss: 20.3879\u001b[0m\n",
      "\u001b[34mEpoch 35/45\u001b[0m\n",
      "\u001b[34m#015 68/404 [====>.........................] - ETA: 0s - loss: 8.3324#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015404/404 [==============================] - 0s 34us/sample - loss: 8.3098 - val_loss: 21.1799\u001b[0m\n",
      "\u001b[34mEpoch 36/45\u001b[0m\n",
      "\u001b[34m#015 68/404 [====>.........................] - ETA: 0s - loss: 9.6112#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015404/404 [==============================] - 0s 37us/sample - loss: 7.5008 - val_loss: 21.2883\u001b[0m\n",
      "\u001b[34mEpoch 37/45\u001b[0m\n",
      "\u001b[34m#015 68/404 [====>.........................] - ETA: 0s - loss: 7.0930#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015404/404 [==============================] - 0s 37us/sample - loss: 7.5008 - val_loss: 20.4365\u001b[0m\n",
      "\u001b[34mEpoch 38/45\u001b[0m\n",
      "\u001b[34m#015 68/404 [====>.........................] - ETA: 0s - loss: 6.9828#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015404/404 [==============================] - 0s 35us/sample - loss: 7.2361 - val_loss: 22.1599\u001b[0m\n",
      "\u001b[34mEpoch 39/45\u001b[0m\n",
      "\u001b[34m#015 68/404 [====>.........................] - ETA: 0s - loss: 5.9679#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015404/404 [==============================] - 0s 36us/sample - loss: 7.9853 - val_loss: 22.4506\u001b[0m\n",
      "\u001b[34mEpoch 40/45\u001b[0m\n",
      "\u001b[34m#015 68/404 [====>.........................] - ETA: 0s - loss: 7.9765#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015404/404 [==============================] - 0s 35us/sample - loss: 7.8614 - val_loss: 21.2309\u001b[0m\n",
      "\u001b[34mEpoch 41/45\u001b[0m\n",
      "\u001b[34m#015 68/404 [====>.........................] - ETA: 0s - loss: 4.0190#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015404/404 [==============================] - 0s 34us/sample - loss: 6.4769 - val_loss: 20.6703\u001b[0m\n",
      "\u001b[34mEpoch 42/45\u001b[0m\n",
      "\u001b[34m#015 68/404 [====>.........................] - ETA: 0s - loss: 5.1825#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015404/404 [==============================] - 0s 34us/sample - loss: 6.4535 - val_loss: 21.3595\u001b[0m\n",
      "\u001b[34mEpoch 43/45\u001b[0m\n",
      "\u001b[34m#015 68/404 [====>.........................] - ETA: 0s - loss: 8.5751#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015404/404 [==============================] - 0s 34us/sample - loss: 7.1296 - val_loss: 27.0793\u001b[0m\n",
      "\u001b[34mEpoch 44/45\u001b[0m\n",
      "\u001b[34m#015 68/404 [====>.........................] - ETA: 0s - loss: 12.7886#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015404/404 [==============================] - 0s 34us/sample - loss: 8.2684 - val_loss: 21.9378\u001b[0m\n",
      "\u001b[34mEpoch 45/45\u001b[0m\n",
      "\u001b[34m#015 68/404 [====>.........................] - ETA: 0s - loss: 5.8240#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015404/404 [==============================] - 0s 35us/sample - loss: 6.3533 - val_loss: 20.0857\u001b[0m\n",
      "\u001b[34m102/102 - 0s - loss: 20.0857\n",
      "\u001b[0m\n",
      "\u001b[34mTest MSE : 20.08568509419759\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mIf using Keras pass *_constraint arguments to layers.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mIf using Keras pass *_constraint arguments to layers.\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Assets written to: /opt/ml/model/1/assets\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Assets written to: /opt/ml/model/1/assets\u001b[0m\n",
      "\u001b[34m2020-06-03 23:36:36,846 sagemaker-containers INFO     Reporting training SUCCESS\u001b[0m\n",
      "Training seconds: 63\n",
      "Billable seconds: 63\n",
      "-----------!"
     ]
    }
   ],
   "source": [
    "tuning_predictor = tuner.deploy(initial_instance_count=1, instance_type='ml.m5.xlarge')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "방금 배포한 엔드포인트에서 예측을 실행해 봅니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions: \t[30.8 29.3 22.1 29.3 22.1 21.4 41.5 40.  36.9 39.1]\n",
      "target values: \t[ 7.2 18.8 19.  27.  22.2 24.5 31.2 22.9 20.5 23.2]\n"
     ]
    }
   ],
   "source": [
    "results = tuning_predictor.predict(x_test[:10])['predictions'] \n",
    "flat_list = [float('%.1f'%(item)) for sublist in results for item in sublist]\n",
    "print('predictions: \\t{}'.format(np.array(flat_list)))\n",
    "print('target values: \\t{}'.format(y_test[:10].round(decimals=1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "추가 요금이 청구되지 않도록 엔드포인트를 삭제합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.delete_endpoint(tuning_predictor.endpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AWS Step Functions의 Data Science SDK를 이용한 워크플로우 자동화 <a class=\"anchor\" id=\"WorkflowAutomation\">\n",
    "\n",
    "지금까지 Tensorflow 프로젝트의 다양한 단계들을 프로토타입의 형태로 살펴보았습니다. 노트북은 프로토타입 작업에는 매우 훌륭한 도구이지만 일반적으로 운영환경의 머신러닝 파이프라인에서는 잘 사용되지 않습니다. 예를 들어 SageMaker에서 간단한 파이프라인을 만든다면 다음 단계들을 포함할 것입니다:\n",
    "\n",
    "1. 모델을 학습한다. \n",
    "2. 서빙을 위한 모델 아티팩트를 담고 있는 SageMaker 모델 오브젝트를 생성한다. \n",
    "3. 모델이 서빙될 때 필요한 설정(하드웨어 타입과 수량 등)을 담고 있는 SageMaker 엔드포인트 구성(Endpoint Configuration)을 생성한다.\n",
    "4. 해당 구성을 이용하여 학습된 모델을 SageMaker Endpoint에 배포한다. \n",
    "    \n",
    "AWS Step Functions 에서 제공하는 Data Science SDK는 이런 워크플로우를 생성하는 것을 자동화해 줍니다. 간단한 파이썬 스크립트 작성으로 워크플로우의 각 단계와 이들의 연결을 정의하여 구현하는 방식입니다. 모든 워크플로우 단계는 Step Functions에서 처리되며, 관리형 서비스이므로 인프라에 대한 설치나 운영은 고민하지 않아도 됩니다. \n",
    "\n",
    "워크플로우 생성을 위해 Step Functions Data Science SDK를 설치합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: You are using pip version 19.3.1; however, version 20.1.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "!{sys.executable} -m pip install --quiet --upgrade stepfunctions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SageMaker Role에 IAM policy 추가하기 <a class=\"anchor\" id=\"IAMPolicy\">\n",
    "\n",
    "**SagrMaker 노트북 인스턴스에서 본 단계를 실행할 때에는** 해당 노트북 인스턴스에서 Step Functions의 워크플로우를 생성하고 실행하는 권한부여 위해 IAM 역할(Role) 설정이 필요합니다.\n",
    "    \n",
    "1. [SageMaker console](https://console.aws.amazon.com/sagemaker/)을 오픈합니다.\n",
    "2. **노트북 인스턴스(Notebook instances)**를 선택하고 사용중인 노트북 인스턴스의 이름을 클릭합니다.\n",
    "3. **권한 및 암호화** 에서 IAM 역할 ARN을 선택하여 IAM 콘솔의 역할 화면으로 이동합니다.\n",
    "4. **정책 연결** 을 클릭하고 `AWSStepFunctionsFullAccess` 정책을 검색합니다.\n",
    "5. `AWSStepFunctionsFullAccess`옆의 체크박스틀 체크하고 **Attach policy**를 클릭합니다.\n",
    "    \n",
    "현재 실행중인 노트북이 (SageMaker 인스턴스가 아닌) 다른 환경이라면, SDK는 AWS CLI 구성을 사용할 것입니다. 보다 자세한 내용은 [Configuring the AWS CLI](https://docs.aws.amazon.com/cli/latest/userguide/cli-chap-configure.html)를 참고합니다.\n",
    "\n",
    "### Step Functions를 위한 실행 역할(execution role) 생성하기 <a class=\"anchor\" id=\"CreateExecutionRole\">\n",
    "\n",
    "다음단계로 Step Functions에서 SageMaker와 다른 서비스 기능에 접근할 수 있도록 실행 역할(execution role)을 생성합니다.\n",
    "    \n",
    "1. [IAM 콘솔](https://console.aws.amazon.com/iam/)로 이동합니다.\n",
    "2. **역할(Roles)**와 **역할 생성(Create role)**을 클릭합니다.\n",
    "3. **또는 서비스를 선택하여 해당 서비스의 사용 사례 확인(Choose the service that will use this role)**에서 **Step Functions**를 선택합니다.\n",
    "4. **역할 이름(Role name)**을 선택하는 화면이 나올 때까지 **다음(Next)**을 클릭합니다.\n",
    "5. 역할이름을 `StepFunctionsWorkflowExecutionRole`와 같이 입력하고 **역할 생성(Create role)**을 클릭합니다.\n",
    "    \n",
    "새롭게 생성된 역할을 선택하고 정책을 연결합니다. 다음 단계는 Step Functions에 접근하기 위한 전체 권한을 부여하지만 실제 업무환경에서 베스트 프랙티스는 필요한 리소스에만 권한을 연결하는 것입니다. \n",
    "\n",
    "Select your newly create role and attach a policy to it. The following steps attach a policy that provides full access to Step Functions, however as a good practice you should only provide access to the resources you need.  \n",
    "\n",
    "1. **권한(Permissions)** 탭에서 **인라인 정책 추가(Add inline policy)**를 클릭합니다.\n",
    "2. **JSON** 탭에 다음 코드를 붙여넣습니다.\n",
    "\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"Version\": \"2012-10-17\",\n",
    "    \"Statement\": [\n",
    "        {\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Action\": [\n",
    "                \"sagemaker:CreateTransformJob\",\n",
    "                \"sagemaker:DescribeTransformJob\",\n",
    "                \"sagemaker:StopTransformJob\",\n",
    "                \"sagemaker:CreateTrainingJob\",\n",
    "                \"sagemaker:DescribeTrainingJob\",\n",
    "                \"sagemaker:StopTrainingJob\",\n",
    "                \"sagemaker:CreateHyperParameterTuningJob\",\n",
    "                \"sagemaker:DescribeHyperParameterTuningJob\",\n",
    "                \"sagemaker:StopHyperParameterTuningJob\",\n",
    "                \"sagemaker:CreateModel\",\n",
    "                \"sagemaker:CreateEndpointConfig\",\n",
    "                \"sagemaker:CreateEndpoint\",\n",
    "                \"sagemaker:DeleteEndpointConfig\",\n",
    "                \"sagemaker:DeleteEndpoint\",\n",
    "                \"sagemaker:UpdateEndpoint\",\n",
    "                \"sagemaker:ListTags\",\n",
    "                \"lambda:InvokeFunction\",\n",
    "                \"sqs:SendMessage\",\n",
    "                \"sns:Publish\",\n",
    "                \"ecs:RunTask\",\n",
    "                \"ecs:StopTask\",\n",
    "                \"ecs:DescribeTasks\",\n",
    "                \"dynamodb:GetItem\",\n",
    "                \"dynamodb:PutItem\",\n",
    "                \"dynamodb:UpdateItem\",\n",
    "                \"dynamodb:DeleteItem\",\n",
    "                \"batch:SubmitJob\",\n",
    "                \"batch:DescribeJobs\",\n",
    "                \"batch:TerminateJob\",\n",
    "                \"glue:StartJobRun\",\n",
    "                \"glue:GetJobRun\",\n",
    "                \"glue:GetJobRuns\",\n",
    "                \"glue:BatchStopJobRun\"\n",
    "            ],\n",
    "            \"Resource\": \"*\"\n",
    "        },\n",
    "        {\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Action\": [\n",
    "                \"iam:PassRole\"\n",
    "            ],\n",
    "            \"Resource\": \"*\",\n",
    "            \"Condition\": {\n",
    "                \"StringEquals\": {\n",
    "                    \"iam:PassedToService\": \"sagemaker.amazonaws.com\"\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Action\": [\n",
    "                \"events:PutTargets\",\n",
    "                \"events:PutRule\",\n",
    "                \"events:DescribeRule\"\n",
    "            ],\n",
    "            \"Resource\": [\n",
    "                \"arn:aws:events:*:*:rule/StepFunctionsGetEventsForSageMakerTrainingJobsRule\",\n",
    "                \"arn:aws:events:*:*:rule/StepFunctionsGetEventsForSageMakerTransformJobsRule\",\n",
    "                \"arn:aws:events:*:*:rule/StepFunctionsGetEventsForSageMakerTuningJobsRule\",\n",
    "                \"arn:aws:events:*:*:rule/StepFunctionsGetEventsForECSTaskRule\",\n",
    "                \"arn:aws:events:*:*:rule/StepFunctionsGetEventsForBatchJobsRule\"\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "```\n",
    "\n",
    "3. **정책 검토(Review policy)**를 선택하고 정책이름을 `StepFunctionsWorkflowExecutionPolicy`등으로 부여합니다.\n",
    "4. **정책 생성(Create policy)**을 클릭하고 역할 상세 페이지로 이동합니다.\n",
    "5. **요약(Summary)** 아래의 내용에서 **역할(Role) ARN**을 복사합니다.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 학습 파이프라인(TrainingPipeline)셋업 <a class=\"anchor\" id=\"TrainingPipeline\">\n",
    "\n",
    "AWS Step Functions의 Data Science SDK 이용시 다양한 명령을 제공하여 파이프라인을 처음부터 만들수도 있고, 또는 보편적인 워크플로우를 위해 미리 제공되는 템플릿 방식을 이용할 수도 있습니다. 예를 들어 [TrainingPipeline](https://aws-step-functions-data-science-sdk.readthedocs.io/en/latest/pipelines.html#stepfunctions.template.pipeline.train.TrainingPipeline) 오브젝트는 학습과 배포를 포함하는 기본 파이프라인의 생성을 도와줍니다.\n",
    "    \n",
    "다음 셀의 코드는 이 기본 파이프라인을 위한 `pipeline`오브젝트를 생성하며 이를 위한 필수 파라미터를 설정하고 있습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import stepfunctions\n",
    "\n",
    "from stepfunctions.template.pipeline import TrainingPipeline\n",
    "\n",
    "# paste the StepFunctionsWorkflowExecutionRole ARN from above\n",
    "workflow_execution_role = \"<execution-role-arn>\"\n",
    "\n",
    "pipeline = TrainingPipeline(\n",
    "    estimator=estimator,\n",
    "    role=workflow_execution_role,\n",
    "    inputs=inputs,\n",
    "    s3_bucket=bucket\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 워크플로우 가시화 <a class=\"anchor\" id=\"VisualizingWorkflow\">\n",
    "\n",
    "이제 워크플로우 정의를 그래프의 형태로 가시화하여 확인할 수 있습니다. 이 워크플로우는 학습의 시작부터 배포까지의 과정을 파이프라인으로 연결하고 있습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"StartAt\": \"Training\",\n",
      "    \"States\": {\n",
      "        \"Training\": {\n",
      "            \"Resource\": \"arn:aws:states:::sagemaker:createTrainingJob.sync\",\n",
      "            \"Parameters\": {\n",
      "                \"AlgorithmSpecification.$\": \"$$.Execution.Input['Training'].AlgorithmSpecification\",\n",
      "                \"OutputDataConfig.$\": \"$$.Execution.Input['Training'].OutputDataConfig\",\n",
      "                \"StoppingCondition.$\": \"$$.Execution.Input['Training'].StoppingCondition\",\n",
      "                \"ResourceConfig.$\": \"$$.Execution.Input['Training'].ResourceConfig\",\n",
      "                \"RoleArn.$\": \"$$.Execution.Input['Training'].RoleArn\",\n",
      "                \"InputDataConfig.$\": \"$$.Execution.Input['Training'].InputDataConfig\",\n",
      "                \"HyperParameters.$\": \"$$.Execution.Input['Training'].HyperParameters\",\n",
      "                \"TrainingJobName.$\": \"$$.Execution.Input['Training'].TrainingJobName\",\n",
      "                \"DebugHookConfig.$\": \"$$.Execution.Input['Training'].DebugHookConfig\"\n",
      "            },\n",
      "            \"Type\": \"Task\",\n",
      "            \"Next\": \"Create Model\"\n",
      "        },\n",
      "        \"Create Model\": {\n",
      "            \"Parameters\": {\n",
      "                \"ModelName.$\": \"$$.Execution.Input['Create Model'].ModelName\",\n",
      "                \"PrimaryContainer.$\": \"$$.Execution.Input['Create Model'].PrimaryContainer\",\n",
      "                \"ExecutionRoleArn.$\": \"$$.Execution.Input['Create Model'].ExecutionRoleArn\"\n",
      "            },\n",
      "            \"Resource\": \"arn:aws:states:::sagemaker:createModel\",\n",
      "            \"Type\": \"Task\",\n",
      "            \"Next\": \"Configure Endpoint\"\n",
      "        },\n",
      "        \"Configure Endpoint\": {\n",
      "            \"Resource\": \"arn:aws:states:::sagemaker:createEndpointConfig\",\n",
      "            \"Parameters\": {\n",
      "                \"EndpointConfigName.$\": \"$$.Execution.Input['Configure Endpoint'].EndpointConfigName\",\n",
      "                \"ProductionVariants.$\": \"$$.Execution.Input['Configure Endpoint'].ProductionVariants\"\n",
      "            },\n",
      "            \"Type\": \"Task\",\n",
      "            \"Next\": \"Deploy\"\n",
      "        },\n",
      "        \"Deploy\": {\n",
      "            \"Resource\": \"arn:aws:states:::sagemaker:createEndpoint\",\n",
      "            \"Parameters\": {\n",
      "                \"EndpointConfigName.$\": \"$$.Execution.Input['Deploy'].EndpointConfigName\",\n",
      "                \"EndpointName.$\": \"$$.Execution.Input['Deploy'].EndpointName\"\n",
      "            },\n",
      "            \"Type\": \"Task\",\n",
      "            \"End\": true\n",
      "        }\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(pipeline.workflow.definition.to_json(pretty=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://do0of8uwbahzz.cloudfront.net/graph.css\">\n",
       "<div id=\"graph-71\" class=\"workflowgraph\">\n",
       "    \n",
       "    <svg></svg>\n",
       "    \n",
       "</div>\n",
       "\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "require.config({\n",
       "    paths: {\n",
       "        sfn: \"https://do0of8uwbahzz.cloudfront.net/sfn\",\n",
       "    }\n",
       "});\n",
       "\n",
       "require(['sfn'], function(sfn) {\n",
       "    var element = document.getElementById('graph-71')\n",
       "\n",
       "    var options = {\n",
       "        width: parseFloat(getComputedStyle(element, null).width.replace(\"px\", \"\")),\n",
       "        height: 600,\n",
       "        layout: 'LR',\n",
       "        resizeHeight: true\n",
       "    };\n",
       "\n",
       "    var definition = {\"StartAt\": \"Training\", \"States\": {\"Training\": {\"Resource\": \"arn:aws:states:::sagemaker:createTrainingJob.sync\", \"Parameters\": {\"AlgorithmSpecification.$\": \"$$.Execution.Input['Training'].AlgorithmSpecification\", \"OutputDataConfig.$\": \"$$.Execution.Input['Training'].OutputDataConfig\", \"StoppingCondition.$\": \"$$.Execution.Input['Training'].StoppingCondition\", \"ResourceConfig.$\": \"$$.Execution.Input['Training'].ResourceConfig\", \"RoleArn.$\": \"$$.Execution.Input['Training'].RoleArn\", \"InputDataConfig.$\": \"$$.Execution.Input['Training'].InputDataConfig\", \"HyperParameters.$\": \"$$.Execution.Input['Training'].HyperParameters\", \"TrainingJobName.$\": \"$$.Execution.Input['Training'].TrainingJobName\", \"DebugHookConfig.$\": \"$$.Execution.Input['Training'].DebugHookConfig\"}, \"Type\": \"Task\", \"Next\": \"Create Model\"}, \"Create Model\": {\"Parameters\": {\"ModelName.$\": \"$$.Execution.Input['Create Model'].ModelName\", \"PrimaryContainer.$\": \"$$.Execution.Input['Create Model'].PrimaryContainer\", \"ExecutionRoleArn.$\": \"$$.Execution.Input['Create Model'].ExecutionRoleArn\"}, \"Resource\": \"arn:aws:states:::sagemaker:createModel\", \"Type\": \"Task\", \"Next\": \"Configure Endpoint\"}, \"Configure Endpoint\": {\"Resource\": \"arn:aws:states:::sagemaker:createEndpointConfig\", \"Parameters\": {\"EndpointConfigName.$\": \"$$.Execution.Input['Configure Endpoint'].EndpointConfigName\", \"ProductionVariants.$\": \"$$.Execution.Input['Configure Endpoint'].ProductionVariants\"}, \"Type\": \"Task\", \"Next\": \"Deploy\"}, \"Deploy\": {\"Resource\": \"arn:aws:states:::sagemaker:createEndpoint\", \"Parameters\": {\"EndpointConfigName.$\": \"$$.Execution.Input['Deploy'].EndpointConfigName\", \"EndpointName.$\": \"$$.Execution.Input['Deploy'].EndpointName\"}, \"Type\": \"Task\", \"End\": true}}};\n",
       "    var elementId = '#graph-71';\n",
       "\n",
       "    var graph = new sfn.StateMachineGraph(definition, elementId, options);\n",
       "    graph.render();\n",
       "});\n",
       "\n",
       "</script>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.render_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 파이프라인의 생성과 실행 <a class=\"anchor\" id=\"CreatingExecutingPipeline\">\n",
    "\n",
    "워크플로우를 실행하기 위해 `create`명령을 이용하여 파이프라인을 클라우드 환경에 생성합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'arn:aws:states:us-east-1:308961792850:stateMachine:training-pipeline-2020-06-06-01-22-32'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.create()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "워크프로우를 시작하기 위해 `execute`명령을 실행합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "execution = pipeline.execute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`list_executions`명령을 사용하여 워크플로우의 모든 실행을 리스트업할 수 있습니다. 생성된 파이프라인은 새로운 데이터에 대한 재학습 등 필요한 만큼 반복적으로 실행 가능합니다. (본 노트북은 한번만 실행합니다.) 작업의 결과는 AWS Step Functions 콘솔에서 접근할 수 있습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "        \n",
       "    .table-widget {\n",
       "        width: 100%;\n",
       "        font-size: 14px;\n",
       "        line-height: 28px;\n",
       "        color: #545b64;\n",
       "        border-spacing: 0;\n",
       "        background-color: #fff;\n",
       "        border-color: grey;\n",
       "        background: #fafafa;\n",
       "    }\n",
       "\n",
       "    .table-widget thead th {\n",
       "        text-align: left !important;\n",
       "        color: #879596;\n",
       "        padding: 0.3em 2em;\n",
       "        border-bottom: 1px solid #eaeded;\n",
       "        min-height: 4rem;\n",
       "        line-height: 28px;\n",
       "    }\n",
       "\n",
       "    .table-widget thead th:first-of-type {\n",
       "    }\n",
       "\n",
       "    .table-widget td {\n",
       "        overflow-wrap: break-word;\n",
       "        padding: 0.4em 2em;\n",
       "        line-height: 28px;\n",
       "        text-align: left !important;\n",
       "        background: #fff;\n",
       "        border-bottom: 1px solid #eaeded;\n",
       "        border-top: 1px solid transparent;\n",
       "    }\n",
       "\n",
       "    .table-widget td:before {\n",
       "        content: \"\";\n",
       "        height: 3rem;\n",
       "    }\n",
       "\n",
       "    a {\n",
       "        cursor: pointer;\n",
       "        text-decoration: none !important;\n",
       "        color: #007dbc;\n",
       "    }\n",
       "\n",
       "    a:hover {\n",
       "        text-decoration: underline !important;\n",
       "    }\n",
       "\n",
       "    a.disabled {\n",
       "        color: black;\n",
       "        cursor: default;\n",
       "        pointer-events: none;\n",
       "    }\n",
       "\n",
       "    .hide {\n",
       "        display: none;\n",
       "    }\n",
       "\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "\n",
       "        \n",
       "    * {\n",
       "        box-sizing: border-box;\n",
       "    }\n",
       "\n",
       "    .table-widget {\n",
       "        min-width: 100%;\n",
       "        font-size: 14px;\n",
       "        line-height: 28px;\n",
       "        color: #545b64;\n",
       "        border-spacing: 0;\n",
       "        background-color: #fff;\n",
       "        border-color: grey;\n",
       "        background: #fafafa;\n",
       "    }\n",
       "\n",
       "    .table-widget thead th {\n",
       "        text-align: left !important;\n",
       "        color: #879596;\n",
       "        padding: 0.3em 2em;\n",
       "        border-bottom: 1px solid #eaeded;\n",
       "        min-height: 4rem;\n",
       "        line-height: 28px;\n",
       "    }\n",
       "\n",
       "    .table-widget td {\n",
       "        /* padding: 24px 18px; */\n",
       "        padding: 0.4em 2em;\n",
       "        line-height: 28px;\n",
       "        text-align: left !important;\n",
       "        background: #fff;\n",
       "        border-bottom: 1px solid #eaeded;\n",
       "        border-top: 1px solid transparent;\n",
       "    }\n",
       "\n",
       "    .table-widget td:before {\n",
       "        content: \"\";\n",
       "        height: 3rem;\n",
       "    }\n",
       "\n",
       "    .table-widget .clickable-cell {\n",
       "        cursor: pointer;\n",
       "    }\n",
       "\n",
       "    .hide {\n",
       "        display: none;\n",
       "    }\n",
       "\n",
       "    .triangle-right {\n",
       "        width: 0;\n",
       "        height: 0;\n",
       "        border-top: 5px solid transparent;\n",
       "        border-left: 8px solid #545b64;\n",
       "        border-bottom: 5px solid transparent;\n",
       "        margin-right: 5px;\n",
       "    }\n",
       "\n",
       "    a.awsui {\n",
       "        text-decoration: none !important;\n",
       "        color: #007dbc;\n",
       "    }\n",
       "\n",
       "    a.awsui:hover {\n",
       "        text-decoration: underline !important;\n",
       "    }\n",
       "\n",
       "    </style>\n",
       "    <table class=\"table-widget\">\n",
       "        <thead>\n",
       "            <tr>\n",
       "                <th>Name</th>\n",
       "                <th>Status</th>\n",
       "                <th>Started</th>\n",
       "                <th>End Time</th>\n",
       "            </tr>\n",
       "        </thead>\n",
       "        <tbody>\n",
       "            \n",
       "    <tr class=\"awsui-table-row\">\n",
       "        <td>\n",
       "            <a href=\"https://console.aws.amazon.com/states/home?region=us-east-1#/executions/details/arn:aws:states:us-east-1:308961792850:execution:training-pipeline-2020-06-06-01-22-32:training-pipeline-2020-06-06-01-26-48\" target=\"_blank\" class=\"awsui\">training-pipeline-2020-06-06-01-26-48</a>\n",
       "        </td>\n",
       "        <td>RUNNING</td>\n",
       "        <td>Jun 06, 2020 01:26:48.125 AM</td>\n",
       "        <td>-</td>\n",
       "    </tr>\n",
       "\n",
       "        </tbody>\n",
       "    </table>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.workflow.list_executions(html=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "워크플로우가 실행되는 동안 `render_progress`명령을 통해 진행상태를 체크할 수 있습니다. 이 명령은 워크플로우 현재 상태에 대한 정적 이미지 스냅샷을 생성합니다. 워크플로우가 실행되는 동안 다음 셀을 반복적으로 실행해 봅니다. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://do0of8uwbahzz.cloudfront.net/graph.css\">\n",
       "<div id=\"graph-417\" class=\"workflowgraph\">\n",
       "    \n",
       "    <style>\n",
       "        .graph-legend ul {\n",
       "            list-style-type: none;\n",
       "            padding: 10px;\n",
       "            padding-left: 0;\n",
       "            margin: 0;\n",
       "            position: absolute;\n",
       "            top: 0;\n",
       "            background: transparent;\n",
       "        }\n",
       "\n",
       "        .graph-legend li {\n",
       "            margin-left: 10px;\n",
       "            display: inline-block;\n",
       "        }\n",
       "\n",
       "        .graph-legend li > div {\n",
       "            width: 10px;\n",
       "            height: 10px;\n",
       "            display: inline-block;\n",
       "        }\n",
       "\n",
       "        .graph-legend .success { background-color: #2BD62E }\n",
       "        .graph-legend .failed { background-color: #DE322F }\n",
       "        .graph-legend .cancelled { background-color: #DDDDDD }\n",
       "        .graph-legend .in-progress { background-color: #53C9ED }\n",
       "        .graph-legend .caught-error { background-color: #FFA500 }\n",
       "    </style>\n",
       "    <div class=\"graph-legend\">\n",
       "        <ul>\n",
       "            <li>\n",
       "                <div class=\"success\"></div>\n",
       "                <span>Success</span>\n",
       "            </li>\n",
       "            <li>\n",
       "                <div class=\"failed\"></div>\n",
       "                <span>Failed</span>\n",
       "            </li>\n",
       "            <li>\n",
       "                <div class=\"cancelled\"></div>\n",
       "                <span>Cancelled</span>\n",
       "            </li>\n",
       "            <li>\n",
       "                <div class=\"in-progress\"></div>\n",
       "                <span>In Progress</span>\n",
       "            </li>\n",
       "            <li>\n",
       "                <div class=\"caught-error\"></div>\n",
       "                <span>Caught Error</span>\n",
       "            </li>\n",
       "        </ul>\n",
       "    </div>\n",
       "\n",
       "    <svg></svg>\n",
       "    <a href=\"https://console.aws.amazon.com/states/home?region=us-east-1#/executions/details/arn:aws:states:us-east-1:308961792850:execution:training-pipeline-2020-06-06-01-22-32:training-pipeline-2020-06-06-01-26-48\" target=\"_blank\"> Inspect in AWS Step Functions </a>\n",
       "</div>\n",
       "\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "require.config({\n",
       "    paths: {\n",
       "        sfn: \"https://do0of8uwbahzz.cloudfront.net/sfn\",\n",
       "    }\n",
       "});\n",
       "\n",
       "require(['sfn'], function(sfn) {\n",
       "    var element = document.getElementById('graph-417')\n",
       "\n",
       "    var options = {\n",
       "        width: parseFloat(getComputedStyle(element, null).width.replace(\"px\", \"\")),\n",
       "        height: 1000,\n",
       "        layout: 'LR',\n",
       "        resizeHeight: true\n",
       "    };\n",
       "\n",
       "    var definition = {\"StartAt\": \"Training\", \"States\": {\"Training\": {\"Resource\": \"arn:aws:states:::sagemaker:createTrainingJob.sync\", \"Parameters\": {\"AlgorithmSpecification.$\": \"$$.Execution.Input['Training'].AlgorithmSpecification\", \"OutputDataConfig.$\": \"$$.Execution.Input['Training'].OutputDataConfig\", \"StoppingCondition.$\": \"$$.Execution.Input['Training'].StoppingCondition\", \"ResourceConfig.$\": \"$$.Execution.Input['Training'].ResourceConfig\", \"RoleArn.$\": \"$$.Execution.Input['Training'].RoleArn\", \"InputDataConfig.$\": \"$$.Execution.Input['Training'].InputDataConfig\", \"HyperParameters.$\": \"$$.Execution.Input['Training'].HyperParameters\", \"TrainingJobName.$\": \"$$.Execution.Input['Training'].TrainingJobName\", \"DebugHookConfig.$\": \"$$.Execution.Input['Training'].DebugHookConfig\"}, \"Type\": \"Task\", \"Next\": \"Create Model\"}, \"Create Model\": {\"Parameters\": {\"ModelName.$\": \"$$.Execution.Input['Create Model'].ModelName\", \"PrimaryContainer.$\": \"$$.Execution.Input['Create Model'].PrimaryContainer\", \"ExecutionRoleArn.$\": \"$$.Execution.Input['Create Model'].ExecutionRoleArn\"}, \"Resource\": \"arn:aws:states:::sagemaker:createModel\", \"Type\": \"Task\", \"Next\": \"Configure Endpoint\"}, \"Configure Endpoint\": {\"Resource\": \"arn:aws:states:::sagemaker:createEndpointConfig\", \"Parameters\": {\"EndpointConfigName.$\": \"$$.Execution.Input['Configure Endpoint'].EndpointConfigName\", \"ProductionVariants.$\": \"$$.Execution.Input['Configure Endpoint'].ProductionVariants\"}, \"Type\": \"Task\", \"Next\": \"Deploy\"}, \"Deploy\": {\"Resource\": \"arn:aws:states:::sagemaker:createEndpoint\", \"Parameters\": {\"EndpointConfigName.$\": \"$$.Execution.Input['Deploy'].EndpointConfigName\", \"EndpointName.$\": \"$$.Execution.Input['Deploy'].EndpointName\"}, \"Type\": \"Task\", \"End\": true}}};\n",
       "    var elementId = '#graph-417';\n",
       "    var events = { 'events': [{\"timestamp\": 1591406808.125, \"type\": \"ExecutionStarted\", \"id\": 1, \"previousEventId\": 0, \"executionStartedEventDetails\": {\"input\": \"{\\n    \\\"Training\\\": {\\n        \\\"AlgorithmSpecification\\\": {\\n            \\\"TrainingImage\\\": \\\"763104351884.dkr.ecr.us-east-1.amazonaws.com/tensorflow-training:2.1-cpu-py3\\\",\\n            \\\"TrainingInputMode\\\": \\\"File\\\"\\n        },\\n        \\\"OutputDataConfig\\\": {\\n            \\\"S3OutputPath\\\": \\\"s3://sagemaker-us-east-1-308961792850/training-pipeline-2020-06-06-01-22-32/models\\\"\\n        },\\n        \\\"StoppingCondition\\\": {\\n            \\\"MaxRuntimeInSeconds\\\": 86400\\n        },\\n        \\\"ResourceConfig\\\": {\\n            \\\"InstanceCount\\\": 1,\\n            \\\"InstanceType\\\": \\\"ml.c5.xlarge\\\",\\n            \\\"VolumeSizeInGB\\\": 30\\n        },\\n        \\\"RoleArn\\\": \\\"arn:aws:iam::308961792850:role/service-role/AmazonSageMaker-ExecutionRole-20200220T105738\\\",\\n        \\\"InputDataConfig\\\": [\\n            {\\n                \\\"DataSource\\\": {\\n                    \\\"S3DataSource\\\": {\\n                        \\\"S3DataType\\\": \\\"S3Prefix\\\",\\n                        \\\"S3Uri\\\": \\\"s3://sagemaker-us-east-1-308961792850/tf-2-workflow/data/train\\\",\\n                        \\\"S3DataDistributionType\\\": \\\"FullyReplicated\\\"\\n                    }\\n                },\\n                \\\"ChannelName\\\": \\\"train\\\"\\n            },\\n            {\\n                \\\"DataSource\\\": {\\n                    \\\"S3DataSource\\\": {\\n                        \\\"S3DataType\\\": \\\"S3Prefix\\\",\\n                        \\\"S3Uri\\\": \\\"s3://sagemaker-us-east-1-308961792850/tf-2-workflow/data/test\\\",\\n                        \\\"S3DataDistributionType\\\": \\\"FullyReplicated\\\"\\n                    }\\n                },\\n                \\\"ChannelName\\\": \\\"test\\\"\\n            }\\n        ],\\n        \\\"HyperParameters\\\": {\\n            \\\"epochs\\\": \\\"30\\\",\\n            \\\"batch_size\\\": \\\"128\\\",\\n            \\\"learning_rate\\\": \\\"0.01\\\",\\n            \\\"sagemaker_submit_directory\\\": \\\"\\\\\\\"s3://sagemaker-us-east-1-308961792850/training-pipeline-2020-06-06-01-22-32/estimator-source/source/sourcedir.tar.gz\\\\\\\"\\\",\\n            \\\"sagemaker_program\\\": \\\"\\\\\\\"train.py\\\\\\\"\\\",\\n            \\\"sagemaker_enable_cloudwatch_metrics\\\": \\\"false\\\",\\n            \\\"sagemaker_container_log_level\\\": \\\"20\\\",\\n            \\\"sagemaker_job_name\\\": \\\"\\\\\\\"training-pipeline-2020-06-06-01-22-32/estimator-source\\\\\\\"\\\",\\n            \\\"sagemaker_region\\\": \\\"\\\\\\\"us-east-1\\\\\\\"\\\",\\n            \\\"model_dir\\\": \\\"\\\\\\\"/opt/ml/model\\\\\\\"\\\"\\n        },\\n        \\\"TrainingJobName\\\": \\\"estimator-training-pipeline-2020-06-06-01-26-48\\\",\\n        \\\"DebugHookConfig\\\": {\\n            \\\"S3OutputPath\\\": \\\"s3://sagemaker-us-east-1-308961792850/\\\",\\n            \\\"CollectionConfigurations\\\": []\\n        }\\n    },\\n    \\\"Create Model\\\": {\\n        \\\"ModelName\\\": \\\"training-pipeline-2020-06-06-01-26-48\\\",\\n        \\\"PrimaryContainer\\\": {\\n            \\\"Image\\\": \\\"763104351884.dkr.ecr.us-east-1.amazonaws.com/tensorflow-inference:2.1-cpu\\\",\\n            \\\"Environment\\\": {\\n                \\\"SAGEMAKER_PROGRAM\\\": null,\\n                \\\"SAGEMAKER_SUBMIT_DIRECTORY\\\": null,\\n                \\\"SAGEMAKER_ENABLE_CLOUDWATCH_METRICS\\\": \\\"false\\\",\\n                \\\"SAGEMAKER_CONTAINER_LOG_LEVEL\\\": \\\"20\\\",\\n                \\\"SAGEMAKER_REGION\\\": \\\"us-east-1\\\"\\n            },\\n            \\\"ModelDataUrl\\\": \\\"s3://sagemaker-us-east-1-308961792850/training-pipeline-2020-06-06-01-22-32/models/estimator-training-pipeline-2020-06-06-01-26-48/output/model.tar.gz\\\"\\n        },\\n        \\\"ExecutionRoleArn\\\": \\\"arn:aws:iam::308961792850:role/service-role/AmazonSageMaker-ExecutionRole-20200220T105738\\\"\\n    },\\n    \\\"Configure Endpoint\\\": {\\n        \\\"EndpointConfigName\\\": \\\"training-pipeline-2020-06-06-01-26-48\\\",\\n        \\\"ProductionVariants\\\": [\\n            {\\n                \\\"InitialInstanceCount\\\": 1,\\n                \\\"InstanceType\\\": \\\"ml.c5.xlarge\\\",\\n                \\\"ModelName\\\": \\\"training-pipeline-2020-06-06-01-26-48\\\",\\n                \\\"VariantName\\\": \\\"AllTraffic\\\"\\n            }\\n        ]\\n    },\\n    \\\"Deploy\\\": {\\n        \\\"EndpointConfigName\\\": \\\"training-pipeline-2020-06-06-01-26-48\\\",\\n        \\\"EndpointName\\\": \\\"training-pipeline-2020-06-06-01-26-48\\\"\\n    }\\n}\", \"roleArn\": \"arn:aws:iam::308961792850:role/StepFunctionsWorkflowExecutionRole\"}}, {\"timestamp\": 1591406808.164, \"type\": \"TaskStateEntered\", \"id\": 2, \"previousEventId\": 0, \"stateEnteredEventDetails\": {\"name\": \"Training\", \"input\": \"{\\n    \\\"Training\\\": {\\n        \\\"AlgorithmSpecification\\\": {\\n            \\\"TrainingImage\\\": \\\"763104351884.dkr.ecr.us-east-1.amazonaws.com/tensorflow-training:2.1-cpu-py3\\\",\\n            \\\"TrainingInputMode\\\": \\\"File\\\"\\n        },\\n        \\\"OutputDataConfig\\\": {\\n            \\\"S3OutputPath\\\": \\\"s3://sagemaker-us-east-1-308961792850/training-pipeline-2020-06-06-01-22-32/models\\\"\\n        },\\n        \\\"StoppingCondition\\\": {\\n            \\\"MaxRuntimeInSeconds\\\": 86400\\n        },\\n        \\\"ResourceConfig\\\": {\\n            \\\"InstanceCount\\\": 1,\\n            \\\"InstanceType\\\": \\\"ml.c5.xlarge\\\",\\n            \\\"VolumeSizeInGB\\\": 30\\n        },\\n        \\\"RoleArn\\\": \\\"arn:aws:iam::308961792850:role/service-role/AmazonSageMaker-ExecutionRole-20200220T105738\\\",\\n        \\\"InputDataConfig\\\": [\\n            {\\n                \\\"DataSource\\\": {\\n                    \\\"S3DataSource\\\": {\\n                        \\\"S3DataType\\\": \\\"S3Prefix\\\",\\n                        \\\"S3Uri\\\": \\\"s3://sagemaker-us-east-1-308961792850/tf-2-workflow/data/train\\\",\\n                        \\\"S3DataDistributionType\\\": \\\"FullyReplicated\\\"\\n                    }\\n                },\\n                \\\"ChannelName\\\": \\\"train\\\"\\n            },\\n            {\\n                \\\"DataSource\\\": {\\n                    \\\"S3DataSource\\\": {\\n                        \\\"S3DataType\\\": \\\"S3Prefix\\\",\\n                        \\\"S3Uri\\\": \\\"s3://sagemaker-us-east-1-308961792850/tf-2-workflow/data/test\\\",\\n                        \\\"S3DataDistributionType\\\": \\\"FullyReplicated\\\"\\n                    }\\n                },\\n                \\\"ChannelName\\\": \\\"test\\\"\\n            }\\n        ],\\n        \\\"HyperParameters\\\": {\\n            \\\"epochs\\\": \\\"30\\\",\\n            \\\"batch_size\\\": \\\"128\\\",\\n            \\\"learning_rate\\\": \\\"0.01\\\",\\n            \\\"sagemaker_submit_directory\\\": \\\"\\\\\\\"s3://sagemaker-us-east-1-308961792850/training-pipeline-2020-06-06-01-22-32/estimator-source/source/sourcedir.tar.gz\\\\\\\"\\\",\\n            \\\"sagemaker_program\\\": \\\"\\\\\\\"train.py\\\\\\\"\\\",\\n            \\\"sagemaker_enable_cloudwatch_metrics\\\": \\\"false\\\",\\n            \\\"sagemaker_container_log_level\\\": \\\"20\\\",\\n            \\\"sagemaker_job_name\\\": \\\"\\\\\\\"training-pipeline-2020-06-06-01-22-32/estimator-source\\\\\\\"\\\",\\n            \\\"sagemaker_region\\\": \\\"\\\\\\\"us-east-1\\\\\\\"\\\",\\n            \\\"model_dir\\\": \\\"\\\\\\\"/opt/ml/model\\\\\\\"\\\"\\n        },\\n        \\\"TrainingJobName\\\": \\\"estimator-training-pipeline-2020-06-06-01-26-48\\\",\\n        \\\"DebugHookConfig\\\": {\\n            \\\"S3OutputPath\\\": \\\"s3://sagemaker-us-east-1-308961792850/\\\",\\n            \\\"CollectionConfigurations\\\": []\\n        }\\n    },\\n    \\\"Create Model\\\": {\\n        \\\"ModelName\\\": \\\"training-pipeline-2020-06-06-01-26-48\\\",\\n        \\\"PrimaryContainer\\\": {\\n            \\\"Image\\\": \\\"763104351884.dkr.ecr.us-east-1.amazonaws.com/tensorflow-inference:2.1-cpu\\\",\\n            \\\"Environment\\\": {\\n                \\\"SAGEMAKER_PROGRAM\\\": null,\\n                \\\"SAGEMAKER_SUBMIT_DIRECTORY\\\": null,\\n                \\\"SAGEMAKER_ENABLE_CLOUDWATCH_METRICS\\\": \\\"false\\\",\\n                \\\"SAGEMAKER_CONTAINER_LOG_LEVEL\\\": \\\"20\\\",\\n                \\\"SAGEMAKER_REGION\\\": \\\"us-east-1\\\"\\n            },\\n            \\\"ModelDataUrl\\\": \\\"s3://sagemaker-us-east-1-308961792850/training-pipeline-2020-06-06-01-22-32/models/estimator-training-pipeline-2020-06-06-01-26-48/output/model.tar.gz\\\"\\n        },\\n        \\\"ExecutionRoleArn\\\": \\\"arn:aws:iam::308961792850:role/service-role/AmazonSageMaker-ExecutionRole-20200220T105738\\\"\\n    },\\n    \\\"Configure Endpoint\\\": {\\n        \\\"EndpointConfigName\\\": \\\"training-pipeline-2020-06-06-01-26-48\\\",\\n        \\\"ProductionVariants\\\": [\\n            {\\n                \\\"InitialInstanceCount\\\": 1,\\n                \\\"InstanceType\\\": \\\"ml.c5.xlarge\\\",\\n                \\\"ModelName\\\": \\\"training-pipeline-2020-06-06-01-26-48\\\",\\n                \\\"VariantName\\\": \\\"AllTraffic\\\"\\n            }\\n        ]\\n    },\\n    \\\"Deploy\\\": {\\n        \\\"EndpointConfigName\\\": \\\"training-pipeline-2020-06-06-01-26-48\\\",\\n        \\\"EndpointName\\\": \\\"training-pipeline-2020-06-06-01-26-48\\\"\\n    }\\n}\"}}, {\"timestamp\": 1591406808.164, \"type\": \"TaskScheduled\", \"id\": 3, \"previousEventId\": 2, \"taskScheduledEventDetails\": {\"resourceType\": \"sagemaker\", \"resource\": \"createTrainingJob.sync\", \"region\": \"us-east-1\", \"parameters\": \"{\\\"HyperParameters\\\":{\\\"epochs\\\":\\\"30\\\",\\\"batch_size\\\":\\\"128\\\",\\\"learning_rate\\\":\\\"0.01\\\",\\\"sagemaker_submit_directory\\\":\\\"\\\\\\\"s3://sagemaker-us-east-1-308961792850/training-pipeline-2020-06-06-01-22-32/estimator-source/source/sourcedir.tar.gz\\\\\\\"\\\",\\\"sagemaker_program\\\":\\\"\\\\\\\"train.py\\\\\\\"\\\",\\\"sagemaker_enable_cloudwatch_metrics\\\":\\\"false\\\",\\\"sagemaker_container_log_level\\\":\\\"20\\\",\\\"sagemaker_job_name\\\":\\\"\\\\\\\"training-pipeline-2020-06-06-01-22-32/estimator-source\\\\\\\"\\\",\\\"sagemaker_region\\\":\\\"\\\\\\\"us-east-1\\\\\\\"\\\",\\\"model_dir\\\":\\\"\\\\\\\"/opt/ml/model\\\\\\\"\\\"},\\\"DebugHookConfig\\\":{\\\"S3OutputPath\\\":\\\"s3://sagemaker-us-east-1-308961792850/\\\",\\\"CollectionConfigurations\\\":[]},\\\"AlgorithmSpecification\\\":{\\\"TrainingImage\\\":\\\"763104351884.dkr.ecr.us-east-1.amazonaws.com/tensorflow-training:2.1-cpu-py3\\\",\\\"TrainingInputMode\\\":\\\"File\\\"},\\\"StoppingCondition\\\":{\\\"MaxRuntimeInSeconds\\\":86400},\\\"TrainingJobName\\\":\\\"estimator-training-pipeline-2020-06-06-01-26-48\\\",\\\"OutputDataConfig\\\":{\\\"S3OutputPath\\\":\\\"s3://sagemaker-us-east-1-308961792850/training-pipeline-2020-06-06-01-22-32/models\\\"},\\\"ResourceConfig\\\":{\\\"InstanceCount\\\":1,\\\"InstanceType\\\":\\\"ml.c5.xlarge\\\",\\\"VolumeSizeInGB\\\":30},\\\"InputDataConfig\\\":[{\\\"DataSource\\\":{\\\"S3DataSource\\\":{\\\"S3DataType\\\":\\\"S3Prefix\\\",\\\"S3Uri\\\":\\\"s3://sagemaker-us-east-1-308961792850/tf-2-workflow/data/train\\\",\\\"S3DataDistributionType\\\":\\\"FullyReplicated\\\"}},\\\"ChannelName\\\":\\\"train\\\"},{\\\"DataSource\\\":{\\\"S3DataSource\\\":{\\\"S3DataType\\\":\\\"S3Prefix\\\",\\\"S3Uri\\\":\\\"s3://sagemaker-us-east-1-308961792850/tf-2-workflow/data/test\\\",\\\"S3DataDistributionType\\\":\\\"FullyReplicated\\\"}},\\\"ChannelName\\\":\\\"test\\\"}],\\\"RoleArn\\\":\\\"arn:aws:iam::308961792850:role/service-role/AmazonSageMaker-ExecutionRole-20200220T105738\\\",\\\"Tags\\\":[{\\\"Key\\\":\\\"MANAGED_BY_AWS\\\",\\\"Value\\\":\\\"STARTED_BY_STEP_FUNCTIONS\\\"}]}\"}}, {\"timestamp\": 1591406808.225, \"type\": \"TaskStarted\", \"id\": 4, \"previousEventId\": 3, \"taskStartedEventDetails\": {\"resourceType\": \"sagemaker\", \"resource\": \"createTrainingJob.sync\"}}, {\"timestamp\": 1591406808.491, \"type\": \"TaskSubmitted\", \"id\": 5, \"previousEventId\": 4, \"taskSubmittedEventDetails\": {\"resourceType\": \"sagemaker\", \"resource\": \"createTrainingJob.sync\", \"output\": \"{\\\"SdkHttpMetadata\\\":{\\\"HttpHeaders\\\":{\\\"Content-Length\\\":\\\"122\\\",\\\"Content-Type\\\":\\\"application/x-amz-json-1.1\\\",\\\"Date\\\":\\\"Sat, 06 Jun 2020 01:26:48 GMT\\\",\\\"x-amzn-RequestId\\\":\\\"bb7fcadf-625a-48fc-a4d5-4fbaf8538e61\\\"},\\\"HttpStatusCode\\\":200},\\\"SdkResponseMetadata\\\":{\\\"RequestId\\\":\\\"bb7fcadf-625a-48fc-a4d5-4fbaf8538e61\\\"},\\\"TrainingJobArn\\\":\\\"arn:aws:sagemaker:us-east-1:308961792850:training-job/estimator-training-pipeline-2020-06-06-01-26-48\\\"}\"}}, {\"timestamp\": 1591407024.519, \"type\": \"TaskSucceeded\", \"id\": 6, \"previousEventId\": 5, \"taskSucceededEventDetails\": {\"resourceType\": \"sagemaker\", \"resource\": \"createTrainingJob.sync\", \"output\": \"{\\\"TrainingJobName\\\":\\\"estimator-training-pipeline-2020-06-06-01-26-48\\\",\\\"TrainingJobArn\\\":\\\"arn:aws:sagemaker:us-east-1:308961792850:training-job/estimator-training-pipeline-2020-06-06-01-26-48\\\",\\\"ModelArtifacts\\\":{\\\"S3ModelArtifacts\\\":\\\"s3://sagemaker-us-east-1-308961792850/training-pipeline-2020-06-06-01-22-32/models/estimator-training-pipeline-2020-06-06-01-26-48/output/model.tar.gz\\\"},\\\"TrainingJobStatus\\\":\\\"Completed\\\",\\\"SecondaryStatus\\\":\\\"Completed\\\",\\\"HyperParameters\\\":{\\\"sagemaker_container_log_level\\\":\\\"20\\\",\\\"batch_size\\\":\\\"128\\\",\\\"sagemaker_program\\\":\\\"\\\\\\\"train.py\\\\\\\"\\\",\\\"sagemaker_enable_cloudwatch_metrics\\\":\\\"false\\\",\\\"sagemaker_region\\\":\\\"\\\\\\\"us-east-1\\\\\\\"\\\",\\\"model_dir\\\":\\\"\\\\\\\"/opt/ml/model\\\\\\\"\\\",\\\"sagemaker_job_name\\\":\\\"\\\\\\\"training-pipeline-2020-06-06-01-22-32/estimator-source\\\\\\\"\\\",\\\"epochs\\\":\\\"30\\\",\\\"learning_rate\\\":\\\"0.01\\\",\\\"sagemaker_submit_directory\\\":\\\"\\\\\\\"s3://sagemaker-us-east-1-308961792850/training-pipeline-2020-06-06-01-22-32/estimator-source/source/sourcedir.tar.gz\\\\\\\"\\\"},\\\"AlgorithmSpecification\\\":{\\\"TrainingImage\\\":\\\"763104351884.dkr.ecr.us-east-1.amazonaws.com/tensorflow-training:2.1-cpu-py3\\\",\\\"TrainingInputMode\\\":\\\"FILE\\\"},\\\"RoleArn\\\":\\\"arn:aws:iam::308961792850:role/service-role/AmazonSageMaker-ExecutionRole-20200220T105738\\\",\\\"InputDataConfig\\\":[{\\\"ChannelName\\\":\\\"train\\\",\\\"DataSource\\\":{\\\"S3DataSource\\\":{\\\"S3DataType\\\":\\\"S3_PREFIX\\\",\\\"S3Uri\\\":\\\"s3://sagemaker-us-east-1-308961792850/tf-2-workflow/data/train\\\",\\\"S3DataDistributionType\\\":\\\"FULLY_REPLICATED\\\"}},\\\"CompressionType\\\":\\\"NONE\\\",\\\"RecordWrapperType\\\":\\\"NONE\\\"},{\\\"ChannelName\\\":\\\"test\\\",\\\"DataSource\\\":{\\\"S3DataSource\\\":{\\\"S3DataType\\\":\\\"S3_PREFIX\\\",\\\"S3Uri\\\":\\\"s3://sagemaker-us-east-1-308961792850/tf-2-workflow/data/test\\\",\\\"S3DataDistributionType\\\":\\\"FULLY_REPLICATED\\\"}},\\\"CompressionType\\\":\\\"NONE\\\",\\\"RecordWrapperType\\\":\\\"NONE\\\"}],\\\"OutputDataConfig\\\":{\\\"S3OutputPath\\\":\\\"s3://sagemaker-us-east-1-308961792850/training-pipeline-2020-06-06-01-22-32/models\\\"},\\\"ResourceConfig\\\":{\\\"InstanceType\\\":\\\"ml.c5.xlarge\\\",\\\"InstanceCount\\\":1.0,\\\"VolumeSizeInGB\\\":30.0},\\\"StoppingCondition\\\":{\\\"MaxRuntimeInSeconds\\\":86400.0},\\\"CreationTime\\\":1.591406808463E12,\\\"TrainingStartTime\\\":1.591406945358E12,\\\"TrainingEndTime\\\":1.591407020053E12,\\\"LastModifiedTime\\\":1.591407020053E12,\\\"SecondaryStatusTransitions\\\":[{\\\"Status\\\":\\\"Starting\\\",\\\"StartTime\\\":1.591406808463E12,\\\"EndTime\\\":1.591406945358E12,\\\"StatusMessage\\\":\\\"Preparing the instances for training\\\"},{\\\"Status\\\":\\\"Downloading\\\",\\\"StartTime\\\":1.591406945358E12,\\\"EndTime\\\":1.591406968518E12,\\\"StatusMessage\\\":\\\"Downloading input data\\\"},{\\\"Status\\\":\\\"Training\\\",\\\"StartTime\\\":1.591406968518E12,\\\"EndTime\\\":1.591407013214E12,\\\"StatusMessage\\\":\\\"Training image download completed. Training in progress.\\\"},{\\\"Status\\\":\\\"Uploading\\\",\\\"StartTime\\\":1.591407013214E12,\\\"EndTime\\\":1.591407020053E12,\\\"StatusMessage\\\":\\\"Uploading generated training model\\\"},{\\\"Status\\\":\\\"Completed\\\",\\\"StartTime\\\":1.591407020053E12,\\\"EndTime\\\":1.591407020053E12,\\\"StatusMessage\\\":\\\"Training job completed\\\"}],\\\"DebugHookConfig\\\":{\\\"S3OutputPath\\\":\\\"s3://sagemaker-us-east-1-308961792850/\\\",\\\"CollectionConfigurations\\\":[]},\\\"Tags\\\":{\\\"AWS_STEP_FUNCTIONS_EXECUTION_ARN\\\":\\\"arn:aws:states:us-east-1:308961792850:execution:training-pipeline-2020-06-06-01-22-32:training-pipeline-2020-06-06-01-26-48\\\",\\\"MANAGED_BY_AWS\\\":\\\"STARTED_BY_STEP_FUNCTIONS\\\"}}\"}}, {\"timestamp\": 1591407024.519, \"type\": \"TaskStateExited\", \"id\": 7, \"previousEventId\": 6, \"stateExitedEventDetails\": {\"name\": \"Training\", \"output\": \"{\\\"TrainingJobName\\\":\\\"estimator-training-pipeline-2020-06-06-01-26-48\\\",\\\"TrainingJobArn\\\":\\\"arn:aws:sagemaker:us-east-1:308961792850:training-job/estimator-training-pipeline-2020-06-06-01-26-48\\\",\\\"ModelArtifacts\\\":{\\\"S3ModelArtifacts\\\":\\\"s3://sagemaker-us-east-1-308961792850/training-pipeline-2020-06-06-01-22-32/models/estimator-training-pipeline-2020-06-06-01-26-48/output/model.tar.gz\\\"},\\\"TrainingJobStatus\\\":\\\"Completed\\\",\\\"SecondaryStatus\\\":\\\"Completed\\\",\\\"HyperParameters\\\":{\\\"sagemaker_container_log_level\\\":\\\"20\\\",\\\"batch_size\\\":\\\"128\\\",\\\"sagemaker_program\\\":\\\"\\\\\\\"train.py\\\\\\\"\\\",\\\"sagemaker_enable_cloudwatch_metrics\\\":\\\"false\\\",\\\"sagemaker_region\\\":\\\"\\\\\\\"us-east-1\\\\\\\"\\\",\\\"model_dir\\\":\\\"\\\\\\\"/opt/ml/model\\\\\\\"\\\",\\\"sagemaker_job_name\\\":\\\"\\\\\\\"training-pipeline-2020-06-06-01-22-32/estimator-source\\\\\\\"\\\",\\\"epochs\\\":\\\"30\\\",\\\"learning_rate\\\":\\\"0.01\\\",\\\"sagemaker_submit_directory\\\":\\\"\\\\\\\"s3://sagemaker-us-east-1-308961792850/training-pipeline-2020-06-06-01-22-32/estimator-source/source/sourcedir.tar.gz\\\\\\\"\\\"},\\\"AlgorithmSpecification\\\":{\\\"TrainingImage\\\":\\\"763104351884.dkr.ecr.us-east-1.amazonaws.com/tensorflow-training:2.1-cpu-py3\\\",\\\"TrainingInputMode\\\":\\\"FILE\\\"},\\\"RoleArn\\\":\\\"arn:aws:iam::308961792850:role/service-role/AmazonSageMaker-ExecutionRole-20200220T105738\\\",\\\"InputDataConfig\\\":[{\\\"ChannelName\\\":\\\"train\\\",\\\"DataSource\\\":{\\\"S3DataSource\\\":{\\\"S3DataType\\\":\\\"S3_PREFIX\\\",\\\"S3Uri\\\":\\\"s3://sagemaker-us-east-1-308961792850/tf-2-workflow/data/train\\\",\\\"S3DataDistributionType\\\":\\\"FULLY_REPLICATED\\\"}},\\\"CompressionType\\\":\\\"NONE\\\",\\\"RecordWrapperType\\\":\\\"NONE\\\"},{\\\"ChannelName\\\":\\\"test\\\",\\\"DataSource\\\":{\\\"S3DataSource\\\":{\\\"S3DataType\\\":\\\"S3_PREFIX\\\",\\\"S3Uri\\\":\\\"s3://sagemaker-us-east-1-308961792850/tf-2-workflow/data/test\\\",\\\"S3DataDistributionType\\\":\\\"FULLY_REPLICATED\\\"}},\\\"CompressionType\\\":\\\"NONE\\\",\\\"RecordWrapperType\\\":\\\"NONE\\\"}],\\\"OutputDataConfig\\\":{\\\"S3OutputPath\\\":\\\"s3://sagemaker-us-east-1-308961792850/training-pipeline-2020-06-06-01-22-32/models\\\"},\\\"ResourceConfig\\\":{\\\"InstanceType\\\":\\\"ml.c5.xlarge\\\",\\\"InstanceCount\\\":1.0,\\\"VolumeSizeInGB\\\":30.0},\\\"StoppingCondition\\\":{\\\"MaxRuntimeInSeconds\\\":86400.0},\\\"CreationTime\\\":1.591406808463E12,\\\"TrainingStartTime\\\":1.591406945358E12,\\\"TrainingEndTime\\\":1.591407020053E12,\\\"LastModifiedTime\\\":1.591407020053E12,\\\"SecondaryStatusTransitions\\\":[{\\\"Status\\\":\\\"Starting\\\",\\\"StartTime\\\":1.591406808463E12,\\\"EndTime\\\":1.591406945358E12,\\\"StatusMessage\\\":\\\"Preparing the instances for training\\\"},{\\\"Status\\\":\\\"Downloading\\\",\\\"StartTime\\\":1.591406945358E12,\\\"EndTime\\\":1.591406968518E12,\\\"StatusMessage\\\":\\\"Downloading input data\\\"},{\\\"Status\\\":\\\"Training\\\",\\\"StartTime\\\":1.591406968518E12,\\\"EndTime\\\":1.591407013214E12,\\\"StatusMessage\\\":\\\"Training image download completed. Training in progress.\\\"},{\\\"Status\\\":\\\"Uploading\\\",\\\"StartTime\\\":1.591407013214E12,\\\"EndTime\\\":1.591407020053E12,\\\"StatusMessage\\\":\\\"Uploading generated training model\\\"},{\\\"Status\\\":\\\"Completed\\\",\\\"StartTime\\\":1.591407020053E12,\\\"EndTime\\\":1.591407020053E12,\\\"StatusMessage\\\":\\\"Training job completed\\\"}],\\\"DebugHookConfig\\\":{\\\"S3OutputPath\\\":\\\"s3://sagemaker-us-east-1-308961792850/\\\",\\\"CollectionConfigurations\\\":[]},\\\"Tags\\\":{\\\"AWS_STEP_FUNCTIONS_EXECUTION_ARN\\\":\\\"arn:aws:states:us-east-1:308961792850:execution:training-pipeline-2020-06-06-01-22-32:training-pipeline-2020-06-06-01-26-48\\\",\\\"MANAGED_BY_AWS\\\":\\\"STARTED_BY_STEP_FUNCTIONS\\\"}}\"}}, {\"timestamp\": 1591407024.53, \"type\": \"TaskStateEntered\", \"id\": 8, \"previousEventId\": 7, \"stateEnteredEventDetails\": {\"name\": \"Create Model\", \"input\": \"{\\\"TrainingJobName\\\":\\\"estimator-training-pipeline-2020-06-06-01-26-48\\\",\\\"TrainingJobArn\\\":\\\"arn:aws:sagemaker:us-east-1:308961792850:training-job/estimator-training-pipeline-2020-06-06-01-26-48\\\",\\\"ModelArtifacts\\\":{\\\"S3ModelArtifacts\\\":\\\"s3://sagemaker-us-east-1-308961792850/training-pipeline-2020-06-06-01-22-32/models/estimator-training-pipeline-2020-06-06-01-26-48/output/model.tar.gz\\\"},\\\"TrainingJobStatus\\\":\\\"Completed\\\",\\\"SecondaryStatus\\\":\\\"Completed\\\",\\\"HyperParameters\\\":{\\\"sagemaker_container_log_level\\\":\\\"20\\\",\\\"batch_size\\\":\\\"128\\\",\\\"sagemaker_program\\\":\\\"\\\\\\\"train.py\\\\\\\"\\\",\\\"sagemaker_enable_cloudwatch_metrics\\\":\\\"false\\\",\\\"sagemaker_region\\\":\\\"\\\\\\\"us-east-1\\\\\\\"\\\",\\\"model_dir\\\":\\\"\\\\\\\"/opt/ml/model\\\\\\\"\\\",\\\"sagemaker_job_name\\\":\\\"\\\\\\\"training-pipeline-2020-06-06-01-22-32/estimator-source\\\\\\\"\\\",\\\"epochs\\\":\\\"30\\\",\\\"learning_rate\\\":\\\"0.01\\\",\\\"sagemaker_submit_directory\\\":\\\"\\\\\\\"s3://sagemaker-us-east-1-308961792850/training-pipeline-2020-06-06-01-22-32/estimator-source/source/sourcedir.tar.gz\\\\\\\"\\\"},\\\"AlgorithmSpecification\\\":{\\\"TrainingImage\\\":\\\"763104351884.dkr.ecr.us-east-1.amazonaws.com/tensorflow-training:2.1-cpu-py3\\\",\\\"TrainingInputMode\\\":\\\"FILE\\\"},\\\"RoleArn\\\":\\\"arn:aws:iam::308961792850:role/service-role/AmazonSageMaker-ExecutionRole-20200220T105738\\\",\\\"InputDataConfig\\\":[{\\\"ChannelName\\\":\\\"train\\\",\\\"DataSource\\\":{\\\"S3DataSource\\\":{\\\"S3DataType\\\":\\\"S3_PREFIX\\\",\\\"S3Uri\\\":\\\"s3://sagemaker-us-east-1-308961792850/tf-2-workflow/data/train\\\",\\\"S3DataDistributionType\\\":\\\"FULLY_REPLICATED\\\"}},\\\"CompressionType\\\":\\\"NONE\\\",\\\"RecordWrapperType\\\":\\\"NONE\\\"},{\\\"ChannelName\\\":\\\"test\\\",\\\"DataSource\\\":{\\\"S3DataSource\\\":{\\\"S3DataType\\\":\\\"S3_PREFIX\\\",\\\"S3Uri\\\":\\\"s3://sagemaker-us-east-1-308961792850/tf-2-workflow/data/test\\\",\\\"S3DataDistributionType\\\":\\\"FULLY_REPLICATED\\\"}},\\\"CompressionType\\\":\\\"NONE\\\",\\\"RecordWrapperType\\\":\\\"NONE\\\"}],\\\"OutputDataConfig\\\":{\\\"S3OutputPath\\\":\\\"s3://sagemaker-us-east-1-308961792850/training-pipeline-2020-06-06-01-22-32/models\\\"},\\\"ResourceConfig\\\":{\\\"InstanceType\\\":\\\"ml.c5.xlarge\\\",\\\"InstanceCount\\\":1.0,\\\"VolumeSizeInGB\\\":30.0},\\\"StoppingCondition\\\":{\\\"MaxRuntimeInSeconds\\\":86400.0},\\\"CreationTime\\\":1.591406808463E12,\\\"TrainingStartTime\\\":1.591406945358E12,\\\"TrainingEndTime\\\":1.591407020053E12,\\\"LastModifiedTime\\\":1.591407020053E12,\\\"SecondaryStatusTransitions\\\":[{\\\"Status\\\":\\\"Starting\\\",\\\"StartTime\\\":1.591406808463E12,\\\"EndTime\\\":1.591406945358E12,\\\"StatusMessage\\\":\\\"Preparing the instances for training\\\"},{\\\"Status\\\":\\\"Downloading\\\",\\\"StartTime\\\":1.591406945358E12,\\\"EndTime\\\":1.591406968518E12,\\\"StatusMessage\\\":\\\"Downloading input data\\\"},{\\\"Status\\\":\\\"Training\\\",\\\"StartTime\\\":1.591406968518E12,\\\"EndTime\\\":1.591407013214E12,\\\"StatusMessage\\\":\\\"Training image download completed. Training in progress.\\\"},{\\\"Status\\\":\\\"Uploading\\\",\\\"StartTime\\\":1.591407013214E12,\\\"EndTime\\\":1.591407020053E12,\\\"StatusMessage\\\":\\\"Uploading generated training model\\\"},{\\\"Status\\\":\\\"Completed\\\",\\\"StartTime\\\":1.591407020053E12,\\\"EndTime\\\":1.591407020053E12,\\\"StatusMessage\\\":\\\"Training job completed\\\"}],\\\"DebugHookConfig\\\":{\\\"S3OutputPath\\\":\\\"s3://sagemaker-us-east-1-308961792850/\\\",\\\"CollectionConfigurations\\\":[]},\\\"Tags\\\":{\\\"AWS_STEP_FUNCTIONS_EXECUTION_ARN\\\":\\\"arn:aws:states:us-east-1:308961792850:execution:training-pipeline-2020-06-06-01-22-32:training-pipeline-2020-06-06-01-26-48\\\",\\\"MANAGED_BY_AWS\\\":\\\"STARTED_BY_STEP_FUNCTIONS\\\"}}\"}}, {\"timestamp\": 1591407024.53, \"type\": \"TaskScheduled\", \"id\": 9, \"previousEventId\": 8, \"taskScheduledEventDetails\": {\"resourceType\": \"sagemaker\", \"resource\": \"createModel\", \"region\": \"us-east-1\", \"parameters\": \"{\\\"ExecutionRoleArn\\\":\\\"arn:aws:iam::308961792850:role/service-role/AmazonSageMaker-ExecutionRole-20200220T105738\\\",\\\"PrimaryContainer\\\":{\\\"Image\\\":\\\"763104351884.dkr.ecr.us-east-1.amazonaws.com/tensorflow-inference:2.1-cpu\\\",\\\"Environment\\\":{\\\"SAGEMAKER_PROGRAM\\\":null,\\\"SAGEMAKER_SUBMIT_DIRECTORY\\\":null,\\\"SAGEMAKER_ENABLE_CLOUDWATCH_METRICS\\\":\\\"false\\\",\\\"SAGEMAKER_CONTAINER_LOG_LEVEL\\\":\\\"20\\\",\\\"SAGEMAKER_REGION\\\":\\\"us-east-1\\\"},\\\"ModelDataUrl\\\":\\\"s3://sagemaker-us-east-1-308961792850/training-pipeline-2020-06-06-01-22-32/models/estimator-training-pipeline-2020-06-06-01-26-48/output/model.tar.gz\\\"},\\\"ModelName\\\":\\\"training-pipeline-2020-06-06-01-26-48\\\"}\"}}, {\"timestamp\": 1591407024.542, \"type\": \"TaskStarted\", \"id\": 10, \"previousEventId\": 9, \"taskStartedEventDetails\": {\"resourceType\": \"sagemaker\", \"resource\": \"createModel\"}}, {\"timestamp\": 1591407024.838, \"type\": \"TaskSucceeded\", \"id\": 11, \"previousEventId\": 10, \"taskSucceededEventDetails\": {\"resourceType\": \"sagemaker\", \"resource\": \"createModel\", \"output\": \"{\\\"ModelArn\\\":\\\"arn:aws:sagemaker:us-east-1:308961792850:model/training-pipeline-2020-06-06-01-26-48\\\",\\\"SdkHttpMetadata\\\":{\\\"HttpHeaders\\\":{\\\"Content-Length\\\":\\\"99\\\",\\\"Content-Type\\\":\\\"application/x-amz-json-1.1\\\",\\\"Date\\\":\\\"Sat, 06 Jun 2020 01:30:24 GMT\\\",\\\"x-amzn-RequestId\\\":\\\"25375e85-ea3b-4a5d-89b9-28499fbdcbb2\\\"},\\\"HttpStatusCode\\\":200},\\\"SdkResponseMetadata\\\":{\\\"RequestId\\\":\\\"25375e85-ea3b-4a5d-89b9-28499fbdcbb2\\\"}}\"}}, {\"timestamp\": 1591407024.838, \"type\": \"TaskStateExited\", \"id\": 12, \"previousEventId\": 11, \"stateExitedEventDetails\": {\"name\": \"Create Model\", \"output\": \"{\\\"ModelArn\\\":\\\"arn:aws:sagemaker:us-east-1:308961792850:model/training-pipeline-2020-06-06-01-26-48\\\",\\\"SdkHttpMetadata\\\":{\\\"HttpHeaders\\\":{\\\"Content-Length\\\":\\\"99\\\",\\\"Content-Type\\\":\\\"application/x-amz-json-1.1\\\",\\\"Date\\\":\\\"Sat, 06 Jun 2020 01:30:24 GMT\\\",\\\"x-amzn-RequestId\\\":\\\"25375e85-ea3b-4a5d-89b9-28499fbdcbb2\\\"},\\\"HttpStatusCode\\\":200},\\\"SdkResponseMetadata\\\":{\\\"RequestId\\\":\\\"25375e85-ea3b-4a5d-89b9-28499fbdcbb2\\\"}}\"}}, {\"timestamp\": 1591407024.845, \"type\": \"TaskStateEntered\", \"id\": 13, \"previousEventId\": 12, \"stateEnteredEventDetails\": {\"name\": \"Configure Endpoint\", \"input\": \"{\\\"ModelArn\\\":\\\"arn:aws:sagemaker:us-east-1:308961792850:model/training-pipeline-2020-06-06-01-26-48\\\",\\\"SdkHttpMetadata\\\":{\\\"HttpHeaders\\\":{\\\"Content-Length\\\":\\\"99\\\",\\\"Content-Type\\\":\\\"application/x-amz-json-1.1\\\",\\\"Date\\\":\\\"Sat, 06 Jun 2020 01:30:24 GMT\\\",\\\"x-amzn-RequestId\\\":\\\"25375e85-ea3b-4a5d-89b9-28499fbdcbb2\\\"},\\\"HttpStatusCode\\\":200},\\\"SdkResponseMetadata\\\":{\\\"RequestId\\\":\\\"25375e85-ea3b-4a5d-89b9-28499fbdcbb2\\\"}}\"}}, {\"timestamp\": 1591407024.845, \"type\": \"TaskScheduled\", \"id\": 14, \"previousEventId\": 13, \"taskScheduledEventDetails\": {\"resourceType\": \"sagemaker\", \"resource\": \"createEndpointConfig\", \"region\": \"us-east-1\", \"parameters\": \"{\\\"ProductionVariants\\\":[{\\\"InitialInstanceCount\\\":1,\\\"InstanceType\\\":\\\"ml.c5.xlarge\\\",\\\"ModelName\\\":\\\"training-pipeline-2020-06-06-01-26-48\\\",\\\"VariantName\\\":\\\"AllTraffic\\\"}],\\\"EndpointConfigName\\\":\\\"training-pipeline-2020-06-06-01-26-48\\\"}\"}}, {\"timestamp\": 1591407024.857, \"type\": \"TaskStarted\", \"id\": 15, \"previousEventId\": 14, \"taskStartedEventDetails\": {\"resourceType\": \"sagemaker\", \"resource\": \"createEndpointConfig\"}}, {\"timestamp\": 1591407024.923, \"type\": \"TaskSucceeded\", \"id\": 16, \"previousEventId\": 15, \"taskSucceededEventDetails\": {\"resourceType\": \"sagemaker\", \"resource\": \"createEndpointConfig\", \"output\": \"{\\\"EndpointConfigArn\\\":\\\"arn:aws:sagemaker:us-east-1:308961792850:endpoint-config/training-pipeline-2020-06-06-01-26-48\\\",\\\"SdkHttpMetadata\\\":{\\\"HttpHeaders\\\":{\\\"Content-Length\\\":\\\"118\\\",\\\"Content-Type\\\":\\\"application/x-amz-json-1.1\\\",\\\"Date\\\":\\\"Sat, 06 Jun 2020 01:30:24 GMT\\\",\\\"x-amzn-RequestId\\\":\\\"bf138871-890f-4681-ba34-460bf6db7746\\\"},\\\"HttpStatusCode\\\":200},\\\"SdkResponseMetadata\\\":{\\\"RequestId\\\":\\\"bf138871-890f-4681-ba34-460bf6db7746\\\"}}\"}}, {\"timestamp\": 1591407024.923, \"type\": \"TaskStateExited\", \"id\": 17, \"previousEventId\": 16, \"stateExitedEventDetails\": {\"name\": \"Configure Endpoint\", \"output\": \"{\\\"EndpointConfigArn\\\":\\\"arn:aws:sagemaker:us-east-1:308961792850:endpoint-config/training-pipeline-2020-06-06-01-26-48\\\",\\\"SdkHttpMetadata\\\":{\\\"HttpHeaders\\\":{\\\"Content-Length\\\":\\\"118\\\",\\\"Content-Type\\\":\\\"application/x-amz-json-1.1\\\",\\\"Date\\\":\\\"Sat, 06 Jun 2020 01:30:24 GMT\\\",\\\"x-amzn-RequestId\\\":\\\"bf138871-890f-4681-ba34-460bf6db7746\\\"},\\\"HttpStatusCode\\\":200},\\\"SdkResponseMetadata\\\":{\\\"RequestId\\\":\\\"bf138871-890f-4681-ba34-460bf6db7746\\\"}}\"}}, {\"timestamp\": 1591407024.969, \"type\": \"TaskStateEntered\", \"id\": 18, \"previousEventId\": 17, \"stateEnteredEventDetails\": {\"name\": \"Deploy\", \"input\": \"{\\\"EndpointConfigArn\\\":\\\"arn:aws:sagemaker:us-east-1:308961792850:endpoint-config/training-pipeline-2020-06-06-01-26-48\\\",\\\"SdkHttpMetadata\\\":{\\\"HttpHeaders\\\":{\\\"Content-Length\\\":\\\"118\\\",\\\"Content-Type\\\":\\\"application/x-amz-json-1.1\\\",\\\"Date\\\":\\\"Sat, 06 Jun 2020 01:30:24 GMT\\\",\\\"x-amzn-RequestId\\\":\\\"bf138871-890f-4681-ba34-460bf6db7746\\\"},\\\"HttpStatusCode\\\":200},\\\"SdkResponseMetadata\\\":{\\\"RequestId\\\":\\\"bf138871-890f-4681-ba34-460bf6db7746\\\"}}\"}}, {\"timestamp\": 1591407024.969, \"type\": \"TaskScheduled\", \"id\": 19, \"previousEventId\": 18, \"taskScheduledEventDetails\": {\"resourceType\": \"sagemaker\", \"resource\": \"createEndpoint\", \"region\": \"us-east-1\", \"parameters\": \"{\\\"EndpointName\\\":\\\"training-pipeline-2020-06-06-01-26-48\\\",\\\"EndpointConfigName\\\":\\\"training-pipeline-2020-06-06-01-26-48\\\"}\"}}, {\"timestamp\": 1591407024.98, \"type\": \"TaskStarted\", \"id\": 20, \"previousEventId\": 19, \"taskStartedEventDetails\": {\"resourceType\": \"sagemaker\", \"resource\": \"createEndpoint\"}}, {\"timestamp\": 1591407025.203, \"type\": \"TaskSucceeded\", \"id\": 21, \"previousEventId\": 20, \"taskSucceededEventDetails\": {\"resourceType\": \"sagemaker\", \"resource\": \"createEndpoint\", \"output\": \"{\\\"EndpointArn\\\":\\\"arn:aws:sagemaker:us-east-1:308961792850:endpoint/training-pipeline-2020-06-06-01-26-48\\\",\\\"SdkHttpMetadata\\\":{\\\"HttpHeaders\\\":{\\\"Content-Length\\\":\\\"105\\\",\\\"Content-Type\\\":\\\"application/x-amz-json-1.1\\\",\\\"Date\\\":\\\"Sat, 06 Jun 2020 01:30:24 GMT\\\",\\\"x-amzn-RequestId\\\":\\\"aa574479-8804-4d58-9b19-af612b5b9f56\\\"},\\\"HttpStatusCode\\\":200},\\\"SdkResponseMetadata\\\":{\\\"RequestId\\\":\\\"aa574479-8804-4d58-9b19-af612b5b9f56\\\"}}\"}}, {\"timestamp\": 1591407025.203, \"type\": \"TaskStateExited\", \"id\": 22, \"previousEventId\": 21, \"stateExitedEventDetails\": {\"name\": \"Deploy\", \"output\": \"{\\\"EndpointArn\\\":\\\"arn:aws:sagemaker:us-east-1:308961792850:endpoint/training-pipeline-2020-06-06-01-26-48\\\",\\\"SdkHttpMetadata\\\":{\\\"HttpHeaders\\\":{\\\"Content-Length\\\":\\\"105\\\",\\\"Content-Type\\\":\\\"application/x-amz-json-1.1\\\",\\\"Date\\\":\\\"Sat, 06 Jun 2020 01:30:24 GMT\\\",\\\"x-amzn-RequestId\\\":\\\"aa574479-8804-4d58-9b19-af612b5b9f56\\\"},\\\"HttpStatusCode\\\":200},\\\"SdkResponseMetadata\\\":{\\\"RequestId\\\":\\\"aa574479-8804-4d58-9b19-af612b5b9f56\\\"}}\"}}, {\"timestamp\": 1591407025.203, \"type\": \"ExecutionSucceeded\", \"id\": 23, \"previousEventId\": 22, \"executionSucceededEventDetails\": {\"output\": \"{\\\"EndpointArn\\\":\\\"arn:aws:sagemaker:us-east-1:308961792850:endpoint/training-pipeline-2020-06-06-01-26-48\\\",\\\"SdkHttpMetadata\\\":{\\\"HttpHeaders\\\":{\\\"Content-Length\\\":\\\"105\\\",\\\"Content-Type\\\":\\\"application/x-amz-json-1.1\\\",\\\"Date\\\":\\\"Sat, 06 Jun 2020 01:30:24 GMT\\\",\\\"x-amzn-RequestId\\\":\\\"aa574479-8804-4d58-9b19-af612b5b9f56\\\"},\\\"HttpStatusCode\\\":200},\\\"SdkResponseMetadata\\\":{\\\"RequestId\\\":\\\"aa574479-8804-4d58-9b19-af612b5b9f56\\\"}}\"}}] };\n",
       "\n",
       "    var graph = new sfn.StateMachineExecutionGraph(definition, events, elementId, options);\n",
       "    graph.render();\n",
       "});\n",
       "\n",
       "</script>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "execution.render_progress()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 노트북의 나머지 부분을 진행하기 전에:\n",
    "\n",
    "워크플로우가 **Succeeded**상태로 종료될 때까지 기다립니다. 이 작업은 수분 정도가 걸릴 것입니다. 위 `render_progress`명령셀의 결과에서 **Inspect in AWS Step Functions**링크를 클릭하면 브라우저를 통해 상태를 확인할 수 있습니다. \n",
    "\n",
    "완료된 워크플로우의 상세정보를 보기 위해 `list_events`명령을 사용할 수 있습니다. 이 명령은 워크플로우 실행과 관련된 모든 이벤트를 리스트업합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'timestamp': datetime.datetime(2020, 6, 6, 1, 30, 25, 203000, tzinfo=tzlocal()),\n",
       "  'type': 'ExecutionSucceeded',\n",
       "  'id': 23,\n",
       "  'previousEventId': 22,\n",
       "  'executionSucceededEventDetails': {'output': '{\"EndpointArn\":\"arn:aws:sagemaker:us-east-1:308961792850:endpoint/training-pipeline-2020-06-06-01-26-48\",\"SdkHttpMetadata\":{\"HttpHeaders\":{\"Content-Length\":\"105\",\"Content-Type\":\"application/x-amz-json-1.1\",\"Date\":\"Sat, 06 Jun 2020 01:30:24 GMT\",\"x-amzn-RequestId\":\"aa574479-8804-4d58-9b19-af612b5b9f56\"},\"HttpStatusCode\":200},\"SdkResponseMetadata\":{\"RequestId\":\"aa574479-8804-4d58-9b19-af612b5b9f56\"}}'}},\n",
       " {'timestamp': datetime.datetime(2020, 6, 6, 1, 30, 25, 203000, tzinfo=tzlocal()),\n",
       "  'type': 'TaskStateExited',\n",
       "  'id': 22,\n",
       "  'previousEventId': 21,\n",
       "  'stateExitedEventDetails': {'name': 'Deploy',\n",
       "   'output': '{\"EndpointArn\":\"arn:aws:sagemaker:us-east-1:308961792850:endpoint/training-pipeline-2020-06-06-01-26-48\",\"SdkHttpMetadata\":{\"HttpHeaders\":{\"Content-Length\":\"105\",\"Content-Type\":\"application/x-amz-json-1.1\",\"Date\":\"Sat, 06 Jun 2020 01:30:24 GMT\",\"x-amzn-RequestId\":\"aa574479-8804-4d58-9b19-af612b5b9f56\"},\"HttpStatusCode\":200},\"SdkResponseMetadata\":{\"RequestId\":\"aa574479-8804-4d58-9b19-af612b5b9f56\"}}'}},\n",
       " {'timestamp': datetime.datetime(2020, 6, 6, 1, 30, 25, 203000, tzinfo=tzlocal()),\n",
       "  'type': 'TaskSucceeded',\n",
       "  'id': 21,\n",
       "  'previousEventId': 20,\n",
       "  'taskSucceededEventDetails': {'resourceType': 'sagemaker',\n",
       "   'resource': 'createEndpoint',\n",
       "   'output': '{\"EndpointArn\":\"arn:aws:sagemaker:us-east-1:308961792850:endpoint/training-pipeline-2020-06-06-01-26-48\",\"SdkHttpMetadata\":{\"HttpHeaders\":{\"Content-Length\":\"105\",\"Content-Type\":\"application/x-amz-json-1.1\",\"Date\":\"Sat, 06 Jun 2020 01:30:24 GMT\",\"x-amzn-RequestId\":\"aa574479-8804-4d58-9b19-af612b5b9f56\"},\"HttpStatusCode\":200},\"SdkResponseMetadata\":{\"RequestId\":\"aa574479-8804-4d58-9b19-af612b5b9f56\"}}'}},\n",
       " {'timestamp': datetime.datetime(2020, 6, 6, 1, 30, 24, 980000, tzinfo=tzlocal()),\n",
       "  'type': 'TaskStarted',\n",
       "  'id': 20,\n",
       "  'previousEventId': 19,\n",
       "  'taskStartedEventDetails': {'resourceType': 'sagemaker',\n",
       "   'resource': 'createEndpoint'}},\n",
       " {'timestamp': datetime.datetime(2020, 6, 6, 1, 30, 24, 969000, tzinfo=tzlocal()),\n",
       "  'type': 'TaskScheduled',\n",
       "  'id': 19,\n",
       "  'previousEventId': 18,\n",
       "  'taskScheduledEventDetails': {'resourceType': 'sagemaker',\n",
       "   'resource': 'createEndpoint',\n",
       "   'region': 'us-east-1',\n",
       "   'parameters': '{\"EndpointName\":\"training-pipeline-2020-06-06-01-26-48\",\"EndpointConfigName\":\"training-pipeline-2020-06-06-01-26-48\"}'}},\n",
       " {'timestamp': datetime.datetime(2020, 6, 6, 1, 30, 24, 969000, tzinfo=tzlocal()),\n",
       "  'type': 'TaskStateEntered',\n",
       "  'id': 18,\n",
       "  'previousEventId': 17,\n",
       "  'stateEnteredEventDetails': {'name': 'Deploy',\n",
       "   'input': '{\"EndpointConfigArn\":\"arn:aws:sagemaker:us-east-1:308961792850:endpoint-config/training-pipeline-2020-06-06-01-26-48\",\"SdkHttpMetadata\":{\"HttpHeaders\":{\"Content-Length\":\"118\",\"Content-Type\":\"application/x-amz-json-1.1\",\"Date\":\"Sat, 06 Jun 2020 01:30:24 GMT\",\"x-amzn-RequestId\":\"bf138871-890f-4681-ba34-460bf6db7746\"},\"HttpStatusCode\":200},\"SdkResponseMetadata\":{\"RequestId\":\"bf138871-890f-4681-ba34-460bf6db7746\"}}'}},\n",
       " {'timestamp': datetime.datetime(2020, 6, 6, 1, 30, 24, 923000, tzinfo=tzlocal()),\n",
       "  'type': 'TaskStateExited',\n",
       "  'id': 17,\n",
       "  'previousEventId': 16,\n",
       "  'stateExitedEventDetails': {'name': 'Configure Endpoint',\n",
       "   'output': '{\"EndpointConfigArn\":\"arn:aws:sagemaker:us-east-1:308961792850:endpoint-config/training-pipeline-2020-06-06-01-26-48\",\"SdkHttpMetadata\":{\"HttpHeaders\":{\"Content-Length\":\"118\",\"Content-Type\":\"application/x-amz-json-1.1\",\"Date\":\"Sat, 06 Jun 2020 01:30:24 GMT\",\"x-amzn-RequestId\":\"bf138871-890f-4681-ba34-460bf6db7746\"},\"HttpStatusCode\":200},\"SdkResponseMetadata\":{\"RequestId\":\"bf138871-890f-4681-ba34-460bf6db7746\"}}'}},\n",
       " {'timestamp': datetime.datetime(2020, 6, 6, 1, 30, 24, 923000, tzinfo=tzlocal()),\n",
       "  'type': 'TaskSucceeded',\n",
       "  'id': 16,\n",
       "  'previousEventId': 15,\n",
       "  'taskSucceededEventDetails': {'resourceType': 'sagemaker',\n",
       "   'resource': 'createEndpointConfig',\n",
       "   'output': '{\"EndpointConfigArn\":\"arn:aws:sagemaker:us-east-1:308961792850:endpoint-config/training-pipeline-2020-06-06-01-26-48\",\"SdkHttpMetadata\":{\"HttpHeaders\":{\"Content-Length\":\"118\",\"Content-Type\":\"application/x-amz-json-1.1\",\"Date\":\"Sat, 06 Jun 2020 01:30:24 GMT\",\"x-amzn-RequestId\":\"bf138871-890f-4681-ba34-460bf6db7746\"},\"HttpStatusCode\":200},\"SdkResponseMetadata\":{\"RequestId\":\"bf138871-890f-4681-ba34-460bf6db7746\"}}'}},\n",
       " {'timestamp': datetime.datetime(2020, 6, 6, 1, 30, 24, 857000, tzinfo=tzlocal()),\n",
       "  'type': 'TaskStarted',\n",
       "  'id': 15,\n",
       "  'previousEventId': 14,\n",
       "  'taskStartedEventDetails': {'resourceType': 'sagemaker',\n",
       "   'resource': 'createEndpointConfig'}},\n",
       " {'timestamp': datetime.datetime(2020, 6, 6, 1, 30, 24, 845000, tzinfo=tzlocal()),\n",
       "  'type': 'TaskScheduled',\n",
       "  'id': 14,\n",
       "  'previousEventId': 13,\n",
       "  'taskScheduledEventDetails': {'resourceType': 'sagemaker',\n",
       "   'resource': 'createEndpointConfig',\n",
       "   'region': 'us-east-1',\n",
       "   'parameters': '{\"ProductionVariants\":[{\"InitialInstanceCount\":1,\"InstanceType\":\"ml.c5.xlarge\",\"ModelName\":\"training-pipeline-2020-06-06-01-26-48\",\"VariantName\":\"AllTraffic\"}],\"EndpointConfigName\":\"training-pipeline-2020-06-06-01-26-48\"}'}},\n",
       " {'timestamp': datetime.datetime(2020, 6, 6, 1, 30, 24, 845000, tzinfo=tzlocal()),\n",
       "  'type': 'TaskStateEntered',\n",
       "  'id': 13,\n",
       "  'previousEventId': 12,\n",
       "  'stateEnteredEventDetails': {'name': 'Configure Endpoint',\n",
       "   'input': '{\"ModelArn\":\"arn:aws:sagemaker:us-east-1:308961792850:model/training-pipeline-2020-06-06-01-26-48\",\"SdkHttpMetadata\":{\"HttpHeaders\":{\"Content-Length\":\"99\",\"Content-Type\":\"application/x-amz-json-1.1\",\"Date\":\"Sat, 06 Jun 2020 01:30:24 GMT\",\"x-amzn-RequestId\":\"25375e85-ea3b-4a5d-89b9-28499fbdcbb2\"},\"HttpStatusCode\":200},\"SdkResponseMetadata\":{\"RequestId\":\"25375e85-ea3b-4a5d-89b9-28499fbdcbb2\"}}'}},\n",
       " {'timestamp': datetime.datetime(2020, 6, 6, 1, 30, 24, 838000, tzinfo=tzlocal()),\n",
       "  'type': 'TaskStateExited',\n",
       "  'id': 12,\n",
       "  'previousEventId': 11,\n",
       "  'stateExitedEventDetails': {'name': 'Create Model',\n",
       "   'output': '{\"ModelArn\":\"arn:aws:sagemaker:us-east-1:308961792850:model/training-pipeline-2020-06-06-01-26-48\",\"SdkHttpMetadata\":{\"HttpHeaders\":{\"Content-Length\":\"99\",\"Content-Type\":\"application/x-amz-json-1.1\",\"Date\":\"Sat, 06 Jun 2020 01:30:24 GMT\",\"x-amzn-RequestId\":\"25375e85-ea3b-4a5d-89b9-28499fbdcbb2\"},\"HttpStatusCode\":200},\"SdkResponseMetadata\":{\"RequestId\":\"25375e85-ea3b-4a5d-89b9-28499fbdcbb2\"}}'}},\n",
       " {'timestamp': datetime.datetime(2020, 6, 6, 1, 30, 24, 838000, tzinfo=tzlocal()),\n",
       "  'type': 'TaskSucceeded',\n",
       "  'id': 11,\n",
       "  'previousEventId': 10,\n",
       "  'taskSucceededEventDetails': {'resourceType': 'sagemaker',\n",
       "   'resource': 'createModel',\n",
       "   'output': '{\"ModelArn\":\"arn:aws:sagemaker:us-east-1:308961792850:model/training-pipeline-2020-06-06-01-26-48\",\"SdkHttpMetadata\":{\"HttpHeaders\":{\"Content-Length\":\"99\",\"Content-Type\":\"application/x-amz-json-1.1\",\"Date\":\"Sat, 06 Jun 2020 01:30:24 GMT\",\"x-amzn-RequestId\":\"25375e85-ea3b-4a5d-89b9-28499fbdcbb2\"},\"HttpStatusCode\":200},\"SdkResponseMetadata\":{\"RequestId\":\"25375e85-ea3b-4a5d-89b9-28499fbdcbb2\"}}'}},\n",
       " {'timestamp': datetime.datetime(2020, 6, 6, 1, 30, 24, 542000, tzinfo=tzlocal()),\n",
       "  'type': 'TaskStarted',\n",
       "  'id': 10,\n",
       "  'previousEventId': 9,\n",
       "  'taskStartedEventDetails': {'resourceType': 'sagemaker',\n",
       "   'resource': 'createModel'}},\n",
       " {'timestamp': datetime.datetime(2020, 6, 6, 1, 30, 24, 530000, tzinfo=tzlocal()),\n",
       "  'type': 'TaskScheduled',\n",
       "  'id': 9,\n",
       "  'previousEventId': 8,\n",
       "  'taskScheduledEventDetails': {'resourceType': 'sagemaker',\n",
       "   'resource': 'createModel',\n",
       "   'region': 'us-east-1',\n",
       "   'parameters': '{\"ExecutionRoleArn\":\"arn:aws:iam::308961792850:role/service-role/AmazonSageMaker-ExecutionRole-20200220T105738\",\"PrimaryContainer\":{\"Image\":\"763104351884.dkr.ecr.us-east-1.amazonaws.com/tensorflow-inference:2.1-cpu\",\"Environment\":{\"SAGEMAKER_PROGRAM\":null,\"SAGEMAKER_SUBMIT_DIRECTORY\":null,\"SAGEMAKER_ENABLE_CLOUDWATCH_METRICS\":\"false\",\"SAGEMAKER_CONTAINER_LOG_LEVEL\":\"20\",\"SAGEMAKER_REGION\":\"us-east-1\"},\"ModelDataUrl\":\"s3://sagemaker-us-east-1-308961792850/training-pipeline-2020-06-06-01-22-32/models/estimator-training-pipeline-2020-06-06-01-26-48/output/model.tar.gz\"},\"ModelName\":\"training-pipeline-2020-06-06-01-26-48\"}'}},\n",
       " {'timestamp': datetime.datetime(2020, 6, 6, 1, 30, 24, 530000, tzinfo=tzlocal()),\n",
       "  'type': 'TaskStateEntered',\n",
       "  'id': 8,\n",
       "  'previousEventId': 7,\n",
       "  'stateEnteredEventDetails': {'name': 'Create Model',\n",
       "   'input': '{\"TrainingJobName\":\"estimator-training-pipeline-2020-06-06-01-26-48\",\"TrainingJobArn\":\"arn:aws:sagemaker:us-east-1:308961792850:training-job/estimator-training-pipeline-2020-06-06-01-26-48\",\"ModelArtifacts\":{\"S3ModelArtifacts\":\"s3://sagemaker-us-east-1-308961792850/training-pipeline-2020-06-06-01-22-32/models/estimator-training-pipeline-2020-06-06-01-26-48/output/model.tar.gz\"},\"TrainingJobStatus\":\"Completed\",\"SecondaryStatus\":\"Completed\",\"HyperParameters\":{\"sagemaker_container_log_level\":\"20\",\"batch_size\":\"128\",\"sagemaker_program\":\"\\\\\"train.py\\\\\"\",\"sagemaker_enable_cloudwatch_metrics\":\"false\",\"sagemaker_region\":\"\\\\\"us-east-1\\\\\"\",\"model_dir\":\"\\\\\"/opt/ml/model\\\\\"\",\"sagemaker_job_name\":\"\\\\\"training-pipeline-2020-06-06-01-22-32/estimator-source\\\\\"\",\"epochs\":\"30\",\"learning_rate\":\"0.01\",\"sagemaker_submit_directory\":\"\\\\\"s3://sagemaker-us-east-1-308961792850/training-pipeline-2020-06-06-01-22-32/estimator-source/source/sourcedir.tar.gz\\\\\"\"},\"AlgorithmSpecification\":{\"TrainingImage\":\"763104351884.dkr.ecr.us-east-1.amazonaws.com/tensorflow-training:2.1-cpu-py3\",\"TrainingInputMode\":\"FILE\"},\"RoleArn\":\"arn:aws:iam::308961792850:role/service-role/AmazonSageMaker-ExecutionRole-20200220T105738\",\"InputDataConfig\":[{\"ChannelName\":\"train\",\"DataSource\":{\"S3DataSource\":{\"S3DataType\":\"S3_PREFIX\",\"S3Uri\":\"s3://sagemaker-us-east-1-308961792850/tf-2-workflow/data/train\",\"S3DataDistributionType\":\"FULLY_REPLICATED\"}},\"CompressionType\":\"NONE\",\"RecordWrapperType\":\"NONE\"},{\"ChannelName\":\"test\",\"DataSource\":{\"S3DataSource\":{\"S3DataType\":\"S3_PREFIX\",\"S3Uri\":\"s3://sagemaker-us-east-1-308961792850/tf-2-workflow/data/test\",\"S3DataDistributionType\":\"FULLY_REPLICATED\"}},\"CompressionType\":\"NONE\",\"RecordWrapperType\":\"NONE\"}],\"OutputDataConfig\":{\"S3OutputPath\":\"s3://sagemaker-us-east-1-308961792850/training-pipeline-2020-06-06-01-22-32/models\"},\"ResourceConfig\":{\"InstanceType\":\"ml.c5.xlarge\",\"InstanceCount\":1.0,\"VolumeSizeInGB\":30.0},\"StoppingCondition\":{\"MaxRuntimeInSeconds\":86400.0},\"CreationTime\":1.591406808463E12,\"TrainingStartTime\":1.591406945358E12,\"TrainingEndTime\":1.591407020053E12,\"LastModifiedTime\":1.591407020053E12,\"SecondaryStatusTransitions\":[{\"Status\":\"Starting\",\"StartTime\":1.591406808463E12,\"EndTime\":1.591406945358E12,\"StatusMessage\":\"Preparing the instances for training\"},{\"Status\":\"Downloading\",\"StartTime\":1.591406945358E12,\"EndTime\":1.591406968518E12,\"StatusMessage\":\"Downloading input data\"},{\"Status\":\"Training\",\"StartTime\":1.591406968518E12,\"EndTime\":1.591407013214E12,\"StatusMessage\":\"Training image download completed. Training in progress.\"},{\"Status\":\"Uploading\",\"StartTime\":1.591407013214E12,\"EndTime\":1.591407020053E12,\"StatusMessage\":\"Uploading generated training model\"},{\"Status\":\"Completed\",\"StartTime\":1.591407020053E12,\"EndTime\":1.591407020053E12,\"StatusMessage\":\"Training job completed\"}],\"DebugHookConfig\":{\"S3OutputPath\":\"s3://sagemaker-us-east-1-308961792850/\",\"CollectionConfigurations\":[]},\"Tags\":{\"AWS_STEP_FUNCTIONS_EXECUTION_ARN\":\"arn:aws:states:us-east-1:308961792850:execution:training-pipeline-2020-06-06-01-22-32:training-pipeline-2020-06-06-01-26-48\",\"MANAGED_BY_AWS\":\"STARTED_BY_STEP_FUNCTIONS\"}}'}},\n",
       " {'timestamp': datetime.datetime(2020, 6, 6, 1, 30, 24, 519000, tzinfo=tzlocal()),\n",
       "  'type': 'TaskStateExited',\n",
       "  'id': 7,\n",
       "  'previousEventId': 6,\n",
       "  'stateExitedEventDetails': {'name': 'Training',\n",
       "   'output': '{\"TrainingJobName\":\"estimator-training-pipeline-2020-06-06-01-26-48\",\"TrainingJobArn\":\"arn:aws:sagemaker:us-east-1:308961792850:training-job/estimator-training-pipeline-2020-06-06-01-26-48\",\"ModelArtifacts\":{\"S3ModelArtifacts\":\"s3://sagemaker-us-east-1-308961792850/training-pipeline-2020-06-06-01-22-32/models/estimator-training-pipeline-2020-06-06-01-26-48/output/model.tar.gz\"},\"TrainingJobStatus\":\"Completed\",\"SecondaryStatus\":\"Completed\",\"HyperParameters\":{\"sagemaker_container_log_level\":\"20\",\"batch_size\":\"128\",\"sagemaker_program\":\"\\\\\"train.py\\\\\"\",\"sagemaker_enable_cloudwatch_metrics\":\"false\",\"sagemaker_region\":\"\\\\\"us-east-1\\\\\"\",\"model_dir\":\"\\\\\"/opt/ml/model\\\\\"\",\"sagemaker_job_name\":\"\\\\\"training-pipeline-2020-06-06-01-22-32/estimator-source\\\\\"\",\"epochs\":\"30\",\"learning_rate\":\"0.01\",\"sagemaker_submit_directory\":\"\\\\\"s3://sagemaker-us-east-1-308961792850/training-pipeline-2020-06-06-01-22-32/estimator-source/source/sourcedir.tar.gz\\\\\"\"},\"AlgorithmSpecification\":{\"TrainingImage\":\"763104351884.dkr.ecr.us-east-1.amazonaws.com/tensorflow-training:2.1-cpu-py3\",\"TrainingInputMode\":\"FILE\"},\"RoleArn\":\"arn:aws:iam::308961792850:role/service-role/AmazonSageMaker-ExecutionRole-20200220T105738\",\"InputDataConfig\":[{\"ChannelName\":\"train\",\"DataSource\":{\"S3DataSource\":{\"S3DataType\":\"S3_PREFIX\",\"S3Uri\":\"s3://sagemaker-us-east-1-308961792850/tf-2-workflow/data/train\",\"S3DataDistributionType\":\"FULLY_REPLICATED\"}},\"CompressionType\":\"NONE\",\"RecordWrapperType\":\"NONE\"},{\"ChannelName\":\"test\",\"DataSource\":{\"S3DataSource\":{\"S3DataType\":\"S3_PREFIX\",\"S3Uri\":\"s3://sagemaker-us-east-1-308961792850/tf-2-workflow/data/test\",\"S3DataDistributionType\":\"FULLY_REPLICATED\"}},\"CompressionType\":\"NONE\",\"RecordWrapperType\":\"NONE\"}],\"OutputDataConfig\":{\"S3OutputPath\":\"s3://sagemaker-us-east-1-308961792850/training-pipeline-2020-06-06-01-22-32/models\"},\"ResourceConfig\":{\"InstanceType\":\"ml.c5.xlarge\",\"InstanceCount\":1.0,\"VolumeSizeInGB\":30.0},\"StoppingCondition\":{\"MaxRuntimeInSeconds\":86400.0},\"CreationTime\":1.591406808463E12,\"TrainingStartTime\":1.591406945358E12,\"TrainingEndTime\":1.591407020053E12,\"LastModifiedTime\":1.591407020053E12,\"SecondaryStatusTransitions\":[{\"Status\":\"Starting\",\"StartTime\":1.591406808463E12,\"EndTime\":1.591406945358E12,\"StatusMessage\":\"Preparing the instances for training\"},{\"Status\":\"Downloading\",\"StartTime\":1.591406945358E12,\"EndTime\":1.591406968518E12,\"StatusMessage\":\"Downloading input data\"},{\"Status\":\"Training\",\"StartTime\":1.591406968518E12,\"EndTime\":1.591407013214E12,\"StatusMessage\":\"Training image download completed. Training in progress.\"},{\"Status\":\"Uploading\",\"StartTime\":1.591407013214E12,\"EndTime\":1.591407020053E12,\"StatusMessage\":\"Uploading generated training model\"},{\"Status\":\"Completed\",\"StartTime\":1.591407020053E12,\"EndTime\":1.591407020053E12,\"StatusMessage\":\"Training job completed\"}],\"DebugHookConfig\":{\"S3OutputPath\":\"s3://sagemaker-us-east-1-308961792850/\",\"CollectionConfigurations\":[]},\"Tags\":{\"AWS_STEP_FUNCTIONS_EXECUTION_ARN\":\"arn:aws:states:us-east-1:308961792850:execution:training-pipeline-2020-06-06-01-22-32:training-pipeline-2020-06-06-01-26-48\",\"MANAGED_BY_AWS\":\"STARTED_BY_STEP_FUNCTIONS\"}}'}},\n",
       " {'timestamp': datetime.datetime(2020, 6, 6, 1, 30, 24, 519000, tzinfo=tzlocal()),\n",
       "  'type': 'TaskSucceeded',\n",
       "  'id': 6,\n",
       "  'previousEventId': 5,\n",
       "  'taskSucceededEventDetails': {'resourceType': 'sagemaker',\n",
       "   'resource': 'createTrainingJob.sync',\n",
       "   'output': '{\"TrainingJobName\":\"estimator-training-pipeline-2020-06-06-01-26-48\",\"TrainingJobArn\":\"arn:aws:sagemaker:us-east-1:308961792850:training-job/estimator-training-pipeline-2020-06-06-01-26-48\",\"ModelArtifacts\":{\"S3ModelArtifacts\":\"s3://sagemaker-us-east-1-308961792850/training-pipeline-2020-06-06-01-22-32/models/estimator-training-pipeline-2020-06-06-01-26-48/output/model.tar.gz\"},\"TrainingJobStatus\":\"Completed\",\"SecondaryStatus\":\"Completed\",\"HyperParameters\":{\"sagemaker_container_log_level\":\"20\",\"batch_size\":\"128\",\"sagemaker_program\":\"\\\\\"train.py\\\\\"\",\"sagemaker_enable_cloudwatch_metrics\":\"false\",\"sagemaker_region\":\"\\\\\"us-east-1\\\\\"\",\"model_dir\":\"\\\\\"/opt/ml/model\\\\\"\",\"sagemaker_job_name\":\"\\\\\"training-pipeline-2020-06-06-01-22-32/estimator-source\\\\\"\",\"epochs\":\"30\",\"learning_rate\":\"0.01\",\"sagemaker_submit_directory\":\"\\\\\"s3://sagemaker-us-east-1-308961792850/training-pipeline-2020-06-06-01-22-32/estimator-source/source/sourcedir.tar.gz\\\\\"\"},\"AlgorithmSpecification\":{\"TrainingImage\":\"763104351884.dkr.ecr.us-east-1.amazonaws.com/tensorflow-training:2.1-cpu-py3\",\"TrainingInputMode\":\"FILE\"},\"RoleArn\":\"arn:aws:iam::308961792850:role/service-role/AmazonSageMaker-ExecutionRole-20200220T105738\",\"InputDataConfig\":[{\"ChannelName\":\"train\",\"DataSource\":{\"S3DataSource\":{\"S3DataType\":\"S3_PREFIX\",\"S3Uri\":\"s3://sagemaker-us-east-1-308961792850/tf-2-workflow/data/train\",\"S3DataDistributionType\":\"FULLY_REPLICATED\"}},\"CompressionType\":\"NONE\",\"RecordWrapperType\":\"NONE\"},{\"ChannelName\":\"test\",\"DataSource\":{\"S3DataSource\":{\"S3DataType\":\"S3_PREFIX\",\"S3Uri\":\"s3://sagemaker-us-east-1-308961792850/tf-2-workflow/data/test\",\"S3DataDistributionType\":\"FULLY_REPLICATED\"}},\"CompressionType\":\"NONE\",\"RecordWrapperType\":\"NONE\"}],\"OutputDataConfig\":{\"S3OutputPath\":\"s3://sagemaker-us-east-1-308961792850/training-pipeline-2020-06-06-01-22-32/models\"},\"ResourceConfig\":{\"InstanceType\":\"ml.c5.xlarge\",\"InstanceCount\":1.0,\"VolumeSizeInGB\":30.0},\"StoppingCondition\":{\"MaxRuntimeInSeconds\":86400.0},\"CreationTime\":1.591406808463E12,\"TrainingStartTime\":1.591406945358E12,\"TrainingEndTime\":1.591407020053E12,\"LastModifiedTime\":1.591407020053E12,\"SecondaryStatusTransitions\":[{\"Status\":\"Starting\",\"StartTime\":1.591406808463E12,\"EndTime\":1.591406945358E12,\"StatusMessage\":\"Preparing the instances for training\"},{\"Status\":\"Downloading\",\"StartTime\":1.591406945358E12,\"EndTime\":1.591406968518E12,\"StatusMessage\":\"Downloading input data\"},{\"Status\":\"Training\",\"StartTime\":1.591406968518E12,\"EndTime\":1.591407013214E12,\"StatusMessage\":\"Training image download completed. Training in progress.\"},{\"Status\":\"Uploading\",\"StartTime\":1.591407013214E12,\"EndTime\":1.591407020053E12,\"StatusMessage\":\"Uploading generated training model\"},{\"Status\":\"Completed\",\"StartTime\":1.591407020053E12,\"EndTime\":1.591407020053E12,\"StatusMessage\":\"Training job completed\"}],\"DebugHookConfig\":{\"S3OutputPath\":\"s3://sagemaker-us-east-1-308961792850/\",\"CollectionConfigurations\":[]},\"Tags\":{\"AWS_STEP_FUNCTIONS_EXECUTION_ARN\":\"arn:aws:states:us-east-1:308961792850:execution:training-pipeline-2020-06-06-01-22-32:training-pipeline-2020-06-06-01-26-48\",\"MANAGED_BY_AWS\":\"STARTED_BY_STEP_FUNCTIONS\"}}'}},\n",
       " {'timestamp': datetime.datetime(2020, 6, 6, 1, 26, 48, 491000, tzinfo=tzlocal()),\n",
       "  'type': 'TaskSubmitted',\n",
       "  'id': 5,\n",
       "  'previousEventId': 4,\n",
       "  'taskSubmittedEventDetails': {'resourceType': 'sagemaker',\n",
       "   'resource': 'createTrainingJob.sync',\n",
       "   'output': '{\"SdkHttpMetadata\":{\"HttpHeaders\":{\"Content-Length\":\"122\",\"Content-Type\":\"application/x-amz-json-1.1\",\"Date\":\"Sat, 06 Jun 2020 01:26:48 GMT\",\"x-amzn-RequestId\":\"bb7fcadf-625a-48fc-a4d5-4fbaf8538e61\"},\"HttpStatusCode\":200},\"SdkResponseMetadata\":{\"RequestId\":\"bb7fcadf-625a-48fc-a4d5-4fbaf8538e61\"},\"TrainingJobArn\":\"arn:aws:sagemaker:us-east-1:308961792850:training-job/estimator-training-pipeline-2020-06-06-01-26-48\"}'}},\n",
       " {'timestamp': datetime.datetime(2020, 6, 6, 1, 26, 48, 225000, tzinfo=tzlocal()),\n",
       "  'type': 'TaskStarted',\n",
       "  'id': 4,\n",
       "  'previousEventId': 3,\n",
       "  'taskStartedEventDetails': {'resourceType': 'sagemaker',\n",
       "   'resource': 'createTrainingJob.sync'}},\n",
       " {'timestamp': datetime.datetime(2020, 6, 6, 1, 26, 48, 164000, tzinfo=tzlocal()),\n",
       "  'type': 'TaskScheduled',\n",
       "  'id': 3,\n",
       "  'previousEventId': 2,\n",
       "  'taskScheduledEventDetails': {'resourceType': 'sagemaker',\n",
       "   'resource': 'createTrainingJob.sync',\n",
       "   'region': 'us-east-1',\n",
       "   'parameters': '{\"HyperParameters\":{\"epochs\":\"30\",\"batch_size\":\"128\",\"learning_rate\":\"0.01\",\"sagemaker_submit_directory\":\"\\\\\"s3://sagemaker-us-east-1-308961792850/training-pipeline-2020-06-06-01-22-32/estimator-source/source/sourcedir.tar.gz\\\\\"\",\"sagemaker_program\":\"\\\\\"train.py\\\\\"\",\"sagemaker_enable_cloudwatch_metrics\":\"false\",\"sagemaker_container_log_level\":\"20\",\"sagemaker_job_name\":\"\\\\\"training-pipeline-2020-06-06-01-22-32/estimator-source\\\\\"\",\"sagemaker_region\":\"\\\\\"us-east-1\\\\\"\",\"model_dir\":\"\\\\\"/opt/ml/model\\\\\"\"},\"DebugHookConfig\":{\"S3OutputPath\":\"s3://sagemaker-us-east-1-308961792850/\",\"CollectionConfigurations\":[]},\"AlgorithmSpecification\":{\"TrainingImage\":\"763104351884.dkr.ecr.us-east-1.amazonaws.com/tensorflow-training:2.1-cpu-py3\",\"TrainingInputMode\":\"File\"},\"StoppingCondition\":{\"MaxRuntimeInSeconds\":86400},\"TrainingJobName\":\"estimator-training-pipeline-2020-06-06-01-26-48\",\"OutputDataConfig\":{\"S3OutputPath\":\"s3://sagemaker-us-east-1-308961792850/training-pipeline-2020-06-06-01-22-32/models\"},\"ResourceConfig\":{\"InstanceCount\":1,\"InstanceType\":\"ml.c5.xlarge\",\"VolumeSizeInGB\":30},\"InputDataConfig\":[{\"DataSource\":{\"S3DataSource\":{\"S3DataType\":\"S3Prefix\",\"S3Uri\":\"s3://sagemaker-us-east-1-308961792850/tf-2-workflow/data/train\",\"S3DataDistributionType\":\"FullyReplicated\"}},\"ChannelName\":\"train\"},{\"DataSource\":{\"S3DataSource\":{\"S3DataType\":\"S3Prefix\",\"S3Uri\":\"s3://sagemaker-us-east-1-308961792850/tf-2-workflow/data/test\",\"S3DataDistributionType\":\"FullyReplicated\"}},\"ChannelName\":\"test\"}],\"RoleArn\":\"arn:aws:iam::308961792850:role/service-role/AmazonSageMaker-ExecutionRole-20200220T105738\",\"Tags\":[{\"Key\":\"MANAGED_BY_AWS\",\"Value\":\"STARTED_BY_STEP_FUNCTIONS\"}]}'}},\n",
       " {'timestamp': datetime.datetime(2020, 6, 6, 1, 26, 48, 164000, tzinfo=tzlocal()),\n",
       "  'type': 'TaskStateEntered',\n",
       "  'id': 2,\n",
       "  'previousEventId': 0,\n",
       "  'stateEnteredEventDetails': {'name': 'Training',\n",
       "   'input': '{\\n    \"Training\": {\\n        \"AlgorithmSpecification\": {\\n            \"TrainingImage\": \"763104351884.dkr.ecr.us-east-1.amazonaws.com/tensorflow-training:2.1-cpu-py3\",\\n            \"TrainingInputMode\": \"File\"\\n        },\\n        \"OutputDataConfig\": {\\n            \"S3OutputPath\": \"s3://sagemaker-us-east-1-308961792850/training-pipeline-2020-06-06-01-22-32/models\"\\n        },\\n        \"StoppingCondition\": {\\n            \"MaxRuntimeInSeconds\": 86400\\n        },\\n        \"ResourceConfig\": {\\n            \"InstanceCount\": 1,\\n            \"InstanceType\": \"ml.c5.xlarge\",\\n            \"VolumeSizeInGB\": 30\\n        },\\n        \"RoleArn\": \"arn:aws:iam::308961792850:role/service-role/AmazonSageMaker-ExecutionRole-20200220T105738\",\\n        \"InputDataConfig\": [\\n            {\\n                \"DataSource\": {\\n                    \"S3DataSource\": {\\n                        \"S3DataType\": \"S3Prefix\",\\n                        \"S3Uri\": \"s3://sagemaker-us-east-1-308961792850/tf-2-workflow/data/train\",\\n                        \"S3DataDistributionType\": \"FullyReplicated\"\\n                    }\\n                },\\n                \"ChannelName\": \"train\"\\n            },\\n            {\\n                \"DataSource\": {\\n                    \"S3DataSource\": {\\n                        \"S3DataType\": \"S3Prefix\",\\n                        \"S3Uri\": \"s3://sagemaker-us-east-1-308961792850/tf-2-workflow/data/test\",\\n                        \"S3DataDistributionType\": \"FullyReplicated\"\\n                    }\\n                },\\n                \"ChannelName\": \"test\"\\n            }\\n        ],\\n        \"HyperParameters\": {\\n            \"epochs\": \"30\",\\n            \"batch_size\": \"128\",\\n            \"learning_rate\": \"0.01\",\\n            \"sagemaker_submit_directory\": \"\\\\\"s3://sagemaker-us-east-1-308961792850/training-pipeline-2020-06-06-01-22-32/estimator-source/source/sourcedir.tar.gz\\\\\"\",\\n            \"sagemaker_program\": \"\\\\\"train.py\\\\\"\",\\n            \"sagemaker_enable_cloudwatch_metrics\": \"false\",\\n            \"sagemaker_container_log_level\": \"20\",\\n            \"sagemaker_job_name\": \"\\\\\"training-pipeline-2020-06-06-01-22-32/estimator-source\\\\\"\",\\n            \"sagemaker_region\": \"\\\\\"us-east-1\\\\\"\",\\n            \"model_dir\": \"\\\\\"/opt/ml/model\\\\\"\"\\n        },\\n        \"TrainingJobName\": \"estimator-training-pipeline-2020-06-06-01-26-48\",\\n        \"DebugHookConfig\": {\\n            \"S3OutputPath\": \"s3://sagemaker-us-east-1-308961792850/\",\\n            \"CollectionConfigurations\": []\\n        }\\n    },\\n    \"Create Model\": {\\n        \"ModelName\": \"training-pipeline-2020-06-06-01-26-48\",\\n        \"PrimaryContainer\": {\\n            \"Image\": \"763104351884.dkr.ecr.us-east-1.amazonaws.com/tensorflow-inference:2.1-cpu\",\\n            \"Environment\": {\\n                \"SAGEMAKER_PROGRAM\": null,\\n                \"SAGEMAKER_SUBMIT_DIRECTORY\": null,\\n                \"SAGEMAKER_ENABLE_CLOUDWATCH_METRICS\": \"false\",\\n                \"SAGEMAKER_CONTAINER_LOG_LEVEL\": \"20\",\\n                \"SAGEMAKER_REGION\": \"us-east-1\"\\n            },\\n            \"ModelDataUrl\": \"s3://sagemaker-us-east-1-308961792850/training-pipeline-2020-06-06-01-22-32/models/estimator-training-pipeline-2020-06-06-01-26-48/output/model.tar.gz\"\\n        },\\n        \"ExecutionRoleArn\": \"arn:aws:iam::308961792850:role/service-role/AmazonSageMaker-ExecutionRole-20200220T105738\"\\n    },\\n    \"Configure Endpoint\": {\\n        \"EndpointConfigName\": \"training-pipeline-2020-06-06-01-26-48\",\\n        \"ProductionVariants\": [\\n            {\\n                \"InitialInstanceCount\": 1,\\n                \"InstanceType\": \"ml.c5.xlarge\",\\n                \"ModelName\": \"training-pipeline-2020-06-06-01-26-48\",\\n                \"VariantName\": \"AllTraffic\"\\n            }\\n        ]\\n    },\\n    \"Deploy\": {\\n        \"EndpointConfigName\": \"training-pipeline-2020-06-06-01-26-48\",\\n        \"EndpointName\": \"training-pipeline-2020-06-06-01-26-48\"\\n    }\\n}'}},\n",
       " {'timestamp': datetime.datetime(2020, 6, 6, 1, 26, 48, 125000, tzinfo=tzlocal()),\n",
       "  'type': 'ExecutionStarted',\n",
       "  'id': 1,\n",
       "  'previousEventId': 0,\n",
       "  'executionStartedEventDetails': {'input': '{\\n    \"Training\": {\\n        \"AlgorithmSpecification\": {\\n            \"TrainingImage\": \"763104351884.dkr.ecr.us-east-1.amazonaws.com/tensorflow-training:2.1-cpu-py3\",\\n            \"TrainingInputMode\": \"File\"\\n        },\\n        \"OutputDataConfig\": {\\n            \"S3OutputPath\": \"s3://sagemaker-us-east-1-308961792850/training-pipeline-2020-06-06-01-22-32/models\"\\n        },\\n        \"StoppingCondition\": {\\n            \"MaxRuntimeInSeconds\": 86400\\n        },\\n        \"ResourceConfig\": {\\n            \"InstanceCount\": 1,\\n            \"InstanceType\": \"ml.c5.xlarge\",\\n            \"VolumeSizeInGB\": 30\\n        },\\n        \"RoleArn\": \"arn:aws:iam::308961792850:role/service-role/AmazonSageMaker-ExecutionRole-20200220T105738\",\\n        \"InputDataConfig\": [\\n            {\\n                \"DataSource\": {\\n                    \"S3DataSource\": {\\n                        \"S3DataType\": \"S3Prefix\",\\n                        \"S3Uri\": \"s3://sagemaker-us-east-1-308961792850/tf-2-workflow/data/train\",\\n                        \"S3DataDistributionType\": \"FullyReplicated\"\\n                    }\\n                },\\n                \"ChannelName\": \"train\"\\n            },\\n            {\\n                \"DataSource\": {\\n                    \"S3DataSource\": {\\n                        \"S3DataType\": \"S3Prefix\",\\n                        \"S3Uri\": \"s3://sagemaker-us-east-1-308961792850/tf-2-workflow/data/test\",\\n                        \"S3DataDistributionType\": \"FullyReplicated\"\\n                    }\\n                },\\n                \"ChannelName\": \"test\"\\n            }\\n        ],\\n        \"HyperParameters\": {\\n            \"epochs\": \"30\",\\n            \"batch_size\": \"128\",\\n            \"learning_rate\": \"0.01\",\\n            \"sagemaker_submit_directory\": \"\\\\\"s3://sagemaker-us-east-1-308961792850/training-pipeline-2020-06-06-01-22-32/estimator-source/source/sourcedir.tar.gz\\\\\"\",\\n            \"sagemaker_program\": \"\\\\\"train.py\\\\\"\",\\n            \"sagemaker_enable_cloudwatch_metrics\": \"false\",\\n            \"sagemaker_container_log_level\": \"20\",\\n            \"sagemaker_job_name\": \"\\\\\"training-pipeline-2020-06-06-01-22-32/estimator-source\\\\\"\",\\n            \"sagemaker_region\": \"\\\\\"us-east-1\\\\\"\",\\n            \"model_dir\": \"\\\\\"/opt/ml/model\\\\\"\"\\n        },\\n        \"TrainingJobName\": \"estimator-training-pipeline-2020-06-06-01-26-48\",\\n        \"DebugHookConfig\": {\\n            \"S3OutputPath\": \"s3://sagemaker-us-east-1-308961792850/\",\\n            \"CollectionConfigurations\": []\\n        }\\n    },\\n    \"Create Model\": {\\n        \"ModelName\": \"training-pipeline-2020-06-06-01-26-48\",\\n        \"PrimaryContainer\": {\\n            \"Image\": \"763104351884.dkr.ecr.us-east-1.amazonaws.com/tensorflow-inference:2.1-cpu\",\\n            \"Environment\": {\\n                \"SAGEMAKER_PROGRAM\": null,\\n                \"SAGEMAKER_SUBMIT_DIRECTORY\": null,\\n                \"SAGEMAKER_ENABLE_CLOUDWATCH_METRICS\": \"false\",\\n                \"SAGEMAKER_CONTAINER_LOG_LEVEL\": \"20\",\\n                \"SAGEMAKER_REGION\": \"us-east-1\"\\n            },\\n            \"ModelDataUrl\": \"s3://sagemaker-us-east-1-308961792850/training-pipeline-2020-06-06-01-22-32/models/estimator-training-pipeline-2020-06-06-01-26-48/output/model.tar.gz\"\\n        },\\n        \"ExecutionRoleArn\": \"arn:aws:iam::308961792850:role/service-role/AmazonSageMaker-ExecutionRole-20200220T105738\"\\n    },\\n    \"Configure Endpoint\": {\\n        \"EndpointConfigName\": \"training-pipeline-2020-06-06-01-26-48\",\\n        \"ProductionVariants\": [\\n            {\\n                \"InitialInstanceCount\": 1,\\n                \"InstanceType\": \"ml.c5.xlarge\",\\n                \"ModelName\": \"training-pipeline-2020-06-06-01-26-48\",\\n                \"VariantName\": \"AllTraffic\"\\n            }\\n        ]\\n    },\\n    \"Deploy\": {\\n        \"EndpointConfigName\": \"training-pipeline-2020-06-06-01-26-48\",\\n        \"EndpointName\": \"training-pipeline-2020-06-06-01-26-48\"\\n    }\\n}',\n",
       "   'roleArn': 'arn:aws:iam::308961792850:role/StepFunctionsWorkflowExecutionRole'}}]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "execution.list_events(reverse_order=True, html=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this list of events, we can extract the name of the endpoint that was set up by the workflow.  \n",
    "결과로 나오느 이벤트 목록에서 워크플로우의 엔드포인트 이름을 찾을 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-06-06-01-26-48\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "endpoint_name_suffix = re.search('endpoint\\Wtraining\\Wpipeline\\W([a-zA-Z0-9\\W]+?)\"', str(execution.list_events())).group(1)\n",
    "print(endpoint_name_suffix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "엔드포인트 이름을 알게 되면, 이 enpoint와 연결된 TensorFlowPredictor 오브젝트를 생성할 수 있습니다. 이 오브젝트는 다음 코드셀의 예시처럼 예측을 제공합니다.\n",
    "\n",
    "#### 다음 코드 셀을 실행하기 전에:\n",
    "\n",
    "[SageMaker 콘솔](https://console.aws.amazon.com/sagemaker/)로 이동하여 **엔드포인트(Endpoints**를 선택하고 엔드포인트의 상태가 **InService** 상태인지 확인합니다. 만약 **Creating**상태라면 상태가 바뀔 때까지 기다립니다. 이 단계는 수 분이 걸릴 수 있습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions: \t[12.7 17.7 25.2 17.7 25.2 25.2 25.2 25.2 25.2 12.7]\n",
      "target values: \t[ 7.2 18.8 19.  27.  22.2 24.5 31.2 22.9 20.5 23.2]\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.tensorflow import TensorFlowPredictor\n",
    "\n",
    "workflow_predictor = TensorFlowPredictor('training-pipeline-' + endpoint_name_suffix)\n",
    "\n",
    "results = workflow_predictor.predict(x_test[:10])['predictions'] \n",
    "flat_list = [float('%.1f'%(item)) for sublist in results for item in sublist]\n",
    "print('predictions: \\t{}'.format(np.array(flat_list)))\n",
    "print('target values: \\t{}'.format(y_test[:10].round(decimals=1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the AWS Step Functions Data Science SDK, there are many other workflows you can create to automate your machine learning tasks.  For example, you could create a workflow to automate model retraining on a periodic basis.  Such a workflow could include a test of model quality after training, with subsequent branches for failing (no model deployment) and passing the quality test (model is deployed).  Other possible workflow steps include Automatic Model Tuning, data preprocessing with AWS Glue, and more.  \n",
    "\n",
    "\n",
    "\n",
    "For a detailed example of a retraining workflow, see the AWS ML Blog post [Automating model retraining and deployment using the AWS Step Functions Data Science SDK for Amazon SageMaker](https://aws.amazon.com/blogs/machine-learning/automating-model-retraining-and-deployment-using-the-aws-step-functions-data-science-sdk-for-amazon-sagemaker/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 리소스 정리 <a class=\"anchor\" id=\"Cleanup\">\n",
    "\n",
    "방금 우리는 워크플로우를 통해 모델과 엔드파인트를 SageMaker에 배포하였습니다. 사용하지 않는 엔드포인트에 대한 추가 과금이 청구되지 않도록 엔드포인트를 삭제합니다. [SageMaker 콘솔](https://console.aws.amazon.com/sagemaker/) 로 이동하여 왼쪽 패털에서 **엔드포인트(Endpoints)**를 선택하고 리스트에서 사용하지 않는 엔드포인트를 선택하고 삭제합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 확장 <a class=\"anchor\" id=\"Extensions\">\n",
    "\n",
    "본 노트북에서 다음을 다루었습니다.: 데이터 변환을 위한 SageMaker Processing, 학습과 추론에 대한 로컬모드 프로토타이핑, 자동 모델 튜닝(하이퍼파라미터 튜닝), SageMaker 호스팅 환경에서 학습과 추론. 이들은 대부분의 SageMaker에서 딥러닝 워크플로우에서 모두 핵심이 되는 요소들입니다. 추가로 우리는 프로젝트에서 프로토타이핑이 끝난 후, AWS Step Functions Data Science SDK를 이용하여 워크플로우 생성하고 실행하는 부분을 살펴보았습니다.\n",
    "    \n",
    "지금까지 살펴본 기능 외에도, SageMaker에는 여러분의 프로젝트에 적용 가능한 다른 많은 기능들이 있습니다. 예를 들어 딥러닝 모델의 학습시 발생하는 공통적인 문제들을 다루기 위해 제공되는 **SageMaker 디버거(Debugger)** 기능이 있으며 모델이 운영환경에 적용되었을 때 발생하는 공통적인 문제들을 관리하기 위한 **SageMaker Model Monitor** 와 같은 기능들이 유용할 수 있습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
